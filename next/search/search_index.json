{"config":{"lang":["en"],"separator":"[\\s\\-]+","pipeline":["stopWordFilter"],"fields":{"title":{"boost":1000.0},"text":{"boost":1.0},"tags":{"boost":1000000.0}}},"docs":[{"location":"","title":"Home","text":""},{"location":"#home","title":"Home","text":""},{"location":"#what-is-k2s","title":"What is K2s?","text":"<p>K2s is a Kubernetes distribution which packages different open-source components into one small and easy to use solution focusing on running mixed Windows-based &amp; Linux-based workloads in Kubernetes. </p> <p>This solution is installable on Windows hosts.</p> <p>The name K2s comes from the fact that we start with the default setting of 2 Kubernetes nodes (Windows &amp; Linux) and it relates to K8s as synonym for Kubernetes.</p>"},{"location":"#why-k2s","title":"Why K2s?","text":"<p>The problems that K2s solves are the following:</p> <ul> <li>It provides the option to construct a K8s cluster by reusing the Windows host as a node. This eliminates the need for an extra Windows license in the case of a mixed Windows &amp; Linux cluster.</li> <li>Offline support is available for all use cases, eliminating the requirement for an internet connection.</li> <li>It offers an easy path for migrating bare metal Windows applications to K8s workloads.</li> <li>It maintains a low footprint by utilizing a single virtual machine for Linux workloads (Hyper-V or WSL).</li> <li>It is built 100% on open-source technology, requiring no additional licenses.</li> </ul>"},{"location":"#who-uses-k2s","title":"Who uses K2s?","text":"<p>K2s started as an internal project of Siemens Healthineers AG under a different name and is now used across different business units.</p> Siemens Healthineers AG <p>See also Siemens Healthineers on GitHub.</p>"},{"location":"#quick-start","title":"Quick Start","text":"<p>Get started here.</p>"},{"location":"#features","title":"Features","text":"<p>K2s includes the following features:</p> <ul> <li>Support of mixed Windows and Linux Kubernetes workloads</li> <li>Support for multiple Windows versions (e.g. 10, 11 and Server OS versions, see Supported OS Versions)</li> <li>Multiple network cards support, including support for LAN and WI-FI network interfaces</li> <li>Offline support by being able to operate the K8s cluster and workloads without internet connectivity</li> <li>Building a Container Image for building and testing Windows and Linux containers</li> <li>Rich Set of Addons which can be used optionally for additional functionality </li> <li>K2s supports different Hosting Variants</li> <li>Template-based setup of the different variants through configuration files</li> <li>Main configuration through central configuration file</li> <li>HTTP proxy support in entire functionality</li> <li>Debugging helpers for analyzing network connectivity</li> <li>Status information on cluster availability</li> <li>Helpers for setting up the K8s cluster for on-premises bare metal nodes and in the cloud using Azure Kubernetes Service</li> <li>Improved overall DNS support and extension possibilities with custom DNS servers</li> <li>Overall HTTP(S) extension support for intranet resources or custom locations </li> <li>Acceptance tests for ensuring full functionality of the cluster</li> </ul>"},{"location":"#security","title":"Security","text":""},{"location":"#reporting-a-vulnerability","title":"Reporting a Vulnerability","text":"<p>The K2s project treats security vulnerabilities seriously, so we strive to take action quickly when required.</p> <p>The project requests that security issues be disclosed in a responsible manner to allow adequate time to respond. If a security issue or vulnerability has been found, please disclose the details to our dedicated email address: dieter.krotz@siemens-healthineers.com</p> <p>Please include as much information as possible with the report. The following details assist with analysis efforts:</p> <ul> <li>Description of the vulnerability</li> <li>Affected component (version, commit, branch, etc.)</li> <li>Affected code (file path, line numbers, etc.)</li> <li>Exploit code</li> </ul>"},{"location":"#security-team","title":"Security Team","text":"<p>The security team currently consists of the K2s maintainers.</p>"},{"location":"dev-guide/hosting-variants-features-matrix/","title":"Hosting Variants Features Matrix","text":""},{"location":"dev-guide/hosting-variants-features-matrix/#hosting-variants-features-matrix","title":"Hosting Variants Features Matrix","text":"<p>See also Hosting Variants.</p> Hosting Variant L2Bridge DNSProxy HttpProxy VFPRules Host \u2714 \u2714 \u2714 \u2714 Development-Only \u2718 \u2718 \u2714 \u2718 Linux-only \u2718 \u2718 \u2718 \u2718 Host (WSL) \u2714 \u2714 \u2714 \u2714 Development-Only (WSL) \u2718 \u2718 \u2714 \u2718 Linux-only (WSL) not supported not supported not supported not supported"},{"location":"dev-guide/hosting-variants-features-matrix/#l2bridge","title":"L2Bridge","text":"<p>Creation of L2Bridge is essential for communication between Pods across Linux and Windows nodes. In principle, a network adapter named <code>cbr0</code> is created to facilitate communication across nodes.</p>"},{"location":"dev-guide/hosting-variants-features-matrix/#dnsproxy","title":"DNSProxy","text":"<p>Acts as internal DNS server on Windows node. Status can be checked with cmd <code>nssm status dnsproxy</code>.</p>"},{"location":"dev-guide/hosting-variants-features-matrix/#httpproxy","title":"HttpProxy","text":"<p>Internal proxy running on Windows node. Status can be checked with cmd <code>nssm status httpproxy</code>.</p> <p>In order to access resources on the internet the following proxy settings need to be used:</p> <ul> <li>Host: Proxy <code>http://172.19.1.1:8181</code> needs to be used inside Linux Pods and Windows Pods. The Linux node needs the proxy as well.</li> <li>Linux-only: No proxy needs to be used. Internet access is possible through NAT.</li> </ul> <p>Example</p> Bash Session<pre><code>curl www.example.com --proxy http://172.19.1.1:8181\n</code></pre>"},{"location":"dev-guide/hosting-variants-features-matrix/#vfprules","title":"VFPRules","text":"<p>Dynamic rules added in <code>cbr0</code> switch for Windows containers networking.</p>"},{"location":"dev-guide/training/","title":"Training","text":""},{"location":"dev-guide/training/#training","title":"Training","text":""},{"location":"dev-guide/training/#introductions","title":"Introductions","text":"Title Link Duration Kubernetes Comic Kubernetes Comic 5 min Docker &amp; Kubernetes: The Big Picture Pluralsight Getting Started with Kubernetes Pluralsight Visual Studio Code Pluralsight"},{"location":"dev-guide/training/#go-programming-language","title":"Go Programming Language","text":"Title Link Duration Go-Lang: Quick Start A Tour of Go Go: The Big Picture Pluralsight Go: Getting started Pluralsight An simple example of Go-Package Documentation pkg.go.dev/io/fs"},{"location":"dev-guide/training/#kubernetes-advanced","title":"Kubernetes Advanced","text":"Title Link Duration Understanding YAML Manifests Objects In Kubernetes Kubernetes for Developers: Core Concepts Pluralsight 4h 34 Kubernetes for Developers: Deploying your Code Pluralsight 4h 34"},{"location":"dev-guide/training/#error-handling","title":"Error Handling","text":"Title Link Duration Go Logging How to collect, standardize, and centralize Golang logs Structured logging Structured logging Log Entry LogEntry A Practical Guide to Kubernetes Logging A Practical Guide to Kubernetes Logging"},{"location":"dev-guide/training/#testing","title":"Testing","text":"Title Link Duration Mocking an http Service Mocking HTTP Requests in Golang 30 min"},{"location":"dev-guide/training/#http2","title":"HTTP/2","text":"Title Link Duration The Many Benefits of HTTP/2 The Many Benefits of HTTP/2 Introduction to HTTP2 (Google) Introduction to HTTP/2"},{"location":"dev-guide/training/#misc","title":"Misc.","text":"Title Link Duration Redis Pluralsight GitHub Pluralsight An overview of Http An overview of HTTP Git-Handbook Pluralsight Visualizing Git Pluralsight"},{"location":"dev-guide/contributing/","title":"Index","text":""},{"location":"dev-guide/contributing/#contributing","title":"Contributing","text":""},{"location":"dev-guide/contributing/#contributor-license-agreement","title":"Contributor License Agreement","text":"<p>There are two versions of the Contributor License Agreement (CLA).  The contributor should be able to chose the right one: </p> <ul> <li>contribution by his/her employer (typically a legal entity) CLA Corporate Contributor</li> <li>contribution by an individual CLA Individual Contributor </li> </ul> <p>The CLA is drafted for re-use for any contributions the (same) contributor makes, so that it needs to be signed only once. This CLA does not enable Siemens Healthineers to use or process personal data. The contributor must not contribute personal data according to this CLA.</p>"},{"location":"dev-guide/contributing/#contributing-with-code","title":"Contributing with code","text":"<p>The code is mainly written in Go and PowerShell. See PowerShell Development for more information.</p> <p>The codebase structure looks like the following:</p> <pre><code>\u251c\u2500\u2500 addons      --&gt; Addon(s)-specific configuration and PowerShell scripts\n\u251c\u2500\u2500 bin         --&gt; Binaries (either committed to this repo or dropped as build target)\n\u251c\u2500\u2500 build\n\u251c\u2500\u2500 cfg         --&gt; Configuration files\n\u251c\u2500\u2500 docs        --&gt; Main documentation\n\u251c\u2500\u2500 k2s         --&gt; Go-based sources\n\u251c\u2500\u2500 lib         --&gt; PowerShell scripts\n\u251c\u2500\u2500 LICENSES\n\u251c\u2500\u2500 smallsetup  --&gt; [legacy] PowerShell scripts; to be migrated to \"lib\"\n\u251c\u2500\u2500 test        --&gt; Main test script(s)\n\u251c\u2500\u2500 ...\n\u251c\u2500\u2500 README.md\n\u251c\u2500\u2500 k2s.exe\n\u251c\u2500\u2500 VERSION\n\u2514\u2500\u2500 ...\n</code></pre> <ol> <li>Clone the Git Repository</li> <li>Make your changes locally, adhering to the Licensing Obligations</li> <li>Build Locally</li> <li>Create Automated Tests and execute them successfully</li> <li>Update the Documentation</li> <li>Submit your Changes</li> </ol>"},{"location":"dev-guide/contributing/automated-testing/","title":"Automated Testing","text":""},{"location":"dev-guide/contributing/automated-testing/#automated-testing","title":"Automated Testing","text":""},{"location":"dev-guide/contributing/automated-testing/#automate-everything","title":"Automate Everything","text":"<p>The ultimate goal is to automate every test case and type, i.e.:</p> <ul> <li>Unit tests</li> <li>Integration Tests</li> <li>e2e tests / system tests / acceptance tests / executable specifications (BDD-style, see also K2s Acceptance Testing)</li> </ul> <p>Info</p> <p>Acceptance tests might require a running K2s cluster.</p>"},{"location":"dev-guide/contributing/automated-testing/#prerequisites","title":"Prerequisites","text":"<p>Install Pester and Install Ginkgo.</p> <p>Tip</p> <p>When running the Main Script: execute_all_tests.ps1 for the first time, those prerequisites are installed automatically in the correct version.</p>"},{"location":"dev-guide/contributing/automated-testing/#main-script-execute_all_testsps1","title":"Main Script: execute_all_tests.ps1","text":"<p>The main entry point for automated testing is the script <code>execute_all_tests.ps1</code>, whether being executed locally or in CI/CD workflows. It is not mandatory, but recommended to use this script instead of running Pester or Ginkgo commands directly due to the following features of the <code>execute_all_tests.ps1</code> script:</p> <ul> <li>Run all test suites in this repository (PowerShell- or Go-based tests)</li> <li>Automatic installation of the required testing frameworks on-the-fly when they do not exist in the required version (i.e. Pester and Ginkgo)</li> <li>Tags/labels filtering that applies both to PowerShell and Go</li> <li>Options to exclude either PowerShell or Go tests</li> <li>Unified test execution report</li> </ul> <p>Example</p> PowerShell<pre><code>&lt;repo&gt;\\test\\execute_all_tests.ps1 -Tags unit -ExcludeGoTests\n</code></pre> <p>The preceding example would execute all PowerShell-based tests tagged with <code>unit</code>.</p> <p>Tip</p> <p>Inspect the execute_all_tests.ps1 script for further parameter details and descriptions. See Commonly Used Tags for commonly used labels/tags.</p>"},{"location":"dev-guide/contributing/automated-testing/#automated-testing-with-pester","title":"Automated Testing with Pester","text":"<p>Note</p> <p>For a quick start and command overview, see Pester Quick Start.</p>"},{"location":"dev-guide/contributing/automated-testing/#install-pester","title":"Install Pester","text":"<p>Info</p> <p>Pester comes pre-installed on Win 10 or later.</p> <p>To check the installed version, run: PowerShell<pre><code>Import-Module Pester -Passthru\n</code></pre></p> <p>This output will be similar to: Output<pre><code>ModuleType Version    Name    ExportedCommands\n---------- -------    ----    ----------------\nScript     3.4.0      Pester  {AfterAll, AfterEach, Assert-MockCalled, Assert-VerifiableMocks...}\n</code></pre></p> <p>Tip</p> <p>It is highly recommended to update Pester to the latest version to have a consistent set of test APIs.</p>"},{"location":"dev-guide/contributing/automated-testing/#update-pester","title":"Update Pester","text":"<p>If Pester was not installed explicitly yet (i.e., the version shipped with Windows is installed), run: PowerShell<pre><code>Install-Module Pester -Force -SkipPublisherCheck\n</code></pre></p> <p>For subsequent updates, run: PowerShell<pre><code>Update-Module -Name Pester\n</code></pre></p>"},{"location":"dev-guide/contributing/automated-testing/#run-pester","title":"Run Pester","text":"<p>To start test discovery and execution, run: PowerShell<pre><code>Invoke-Pester .\\&lt;test file&gt;.tests.ps1\n</code></pre></p> <p>Info</p> <p>Pester discovers test files via naming convention *.[T|t]ests.ps1</p> <p>To see detailed output, run: PowerShell<pre><code>Invoke-Pester -Output Detailed .\\&lt;test file&gt;.Tests.ps1\n</code></pre> To include/exclude tests by tags, run: PowerShell<pre><code>Invoke-Pester -Tag \"acceptance\" -ExcludeTag \"slow\", \"linuxOnly\" .\\&lt;test file&gt;.Tests.ps1\n</code></pre></p>"},{"location":"dev-guide/contributing/automated-testing/#code-coverage","title":"Code Coverage","text":"<p>To calculate the code coverage of a test run, additionally specify the file(s) under test: PowerShell<pre><code>Invoke-Pester .\\&lt;test file&gt;.Tests.ps1 -CodeCoverage .\\&lt;file-under-test&gt;.ps1\n</code></pre></p> <p>To export the code coverage results as JaCoCo XML file, specify the output file: PowerShell<pre><code>Invoke-Pester .\\&lt;test file&gt;.Tests.ps1 -CodeCoverage .\\&lt;file-under-test&gt;.ps1 -CodeCoverageOutputFile &lt;some dir&gt;\\coverage.xml\n</code></pre></p> <p>Note</p> <p>See Pester Code Coverage for more options.</p>"},{"location":"dev-guide/contributing/automated-testing/#log-output-redirection","title":"Log Output Redirection","text":"<p>When executing K2s scripts inside Pester test functions, it is recommended to execute these scripts in a separate PowerShell session, so that the called scripts still log to the K2s log files due to the current logging implementation.</p>"},{"location":"dev-guide/contributing/automated-testing/#dont","title":"Don't","text":"PowerShell<pre><code># ...\n$enableScript = \"$PSScriptRoot\\Enable.ps1\"\n# ...\nIt 'does not log to log file :-(' {\n    $output = $(&amp;$enableScript -ShowLogs) *&gt;&amp;1 # output redirect, but no log file entries\n    # ...\n}\n# ...\n</code></pre>"},{"location":"dev-guide/contributing/automated-testing/#do","title":"Do","text":"PowerShell<pre><code># ...\n$enableScript = \"$PSScriptRoot\\Enable.ps1\"\n# ...\nIt 'logs to log file :-)' {\n    $output = powershell -Command \"$enableScript -ShowLogs\" *&gt;&amp;1 # output redirect and log file entries\n    # ...\n}\n# ...\n</code></pre>"},{"location":"dev-guide/contributing/automated-testing/#suppress-code-analysis","title":"Suppress Code Analysis","text":"<p>Pester requires a certain test code structure that can lead to code analyzer warnings, e.g. in this case: PowerShell<pre><code>BeforeAll {\n    $module = \"$PSScriptRoot\\setupinfo.module.psm1\"\n\n    $moduleName = (Import-Module $module -PassThru -Force).Name\n}\n</code></pre> The analyzer would complain:</p> <p>Quote</p> <p>The variable 'moduleName' is assigned but never used. PSScriptAnalyzer(PSUseDeclaredVarsMoreThanAssignments)</p> <p>To mitigate this, suppress this warning like the following: PowerShell<pre><code>BeforeAll {\n    $module = \"$PSScriptRoot\\setupinfo.module.psm1\"\n\n    [Diagnostics.CodeAnalysis.SuppressMessageAttribute('UseDeclaredVarsMoreThanAssignments', '', Justification = 'Pester Test')]\n    $moduleName = (Import-Module $module -PassThru -Force).Name\n}\n</code></pre></p>"},{"location":"dev-guide/contributing/automated-testing/#automated-testing-with-ginkgogomega","title":"Automated Testing with Ginkgo/Gomega","text":""},{"location":"dev-guide/contributing/automated-testing/#log-output-redirection_1","title":"Log Output Redirection","text":"<p>For diagnostic logging, k2s CLI uses slog. To redirect the log output to Ginkgo, set the Ginkgo logger as follows (Ginkgo uses logr internally): Go<pre><code>var _ = BeforeSuite(func() {\n    slog.SetDefault(slog.New(logr.ToSlogHandler(GinkgoLogr)))\n})\n</code></pre></p> <p>This enables control over slog output, i.e. the output can be enabled when running Ginkgo in verbose mode (<code>ginkog -v</code>) and be omitted in non-verbose mode.</p>"},{"location":"dev-guide/contributing/automated-testing/#k2s-acceptance-testing","title":"K2s Acceptance Testing","text":"<p>Info</p> <p>The acceptance tests focus on testing K2s from a user's point of view in an automated, repeatable and reproduceable fashion. They are intended to cover all available features across the various Supported OS Versions. They are not intended to cover all the edge and corner cases, though (Unit Tests might be a better fit there).</p> <p>To mark acceptance tests as such and provide additional information about test prerequisites (e.g. a running K2s cluster, internet connectivity, etc.), use Tags/Labels.</p>"},{"location":"dev-guide/contributing/automated-testing/#tech-stack","title":"Tech Stack","text":"<p>The tech stack mostly comprises the Go testing package, Ginkgo/Gomega and the K2s Testing Framework to write acceptance tests in an efficient way without having to write boilerplate code repeatedly. The levels of abstraction are depicted in the following:</p> <pre><code>flowchart TD\n    A(K2s Testing Framework) --&gt; |utilizes|B(Ginkgo/Gomega)\n    B --&gt; |utilizes|C(Go Testing Package)</code></pre>"},{"location":"dev-guide/contributing/automated-testing/#implementing-testsspecs","title":"Implementing Tests/Specs","text":"<p>See K2s Acceptance Tests/Specs.</p>"},{"location":"dev-guide/contributing/automated-testing/#executing-testsspecs","title":"Executing Tests/Specs","text":"<p>Multiple options exist to run Go-based test specs:</p> <ul> <li>Main Script: execute_all_tests.ps1 - Recommended, provides most flexibility</li> <li>Running Ginkgo:     Bash Session<pre><code>ginkgo &lt;dir-with-test-specs&gt;\n</code></pre></li> <li>Running <code>go test</code>:     Bash Session<pre><code>cd &lt;dir-with-test-specs&gt;\ngo test \n</code></pre></li> </ul> <p>Ginkgo and go test</p> <p>Use <code>-v</code> flag to enable verbose test execution output.</p> <p>Use <code>-r</code> or <code>./...</code> to scan for and execute tests recursively starting in the given directory.</p> <p>Optimizing Test Execution Speed</p> <p>When executing Go-based tests, the packages containing the test specs will get built right before test execution. This compilation is rather time-consuming compared to the actual test runs, especially when executing short-running unit tests.</p> <p>To optimize the overall execution speed, the packages containing test specs can be build before hand, either through <code>ginkgo build</code> or <code>go test -c</code>.</p>"},{"location":"dev-guide/contributing/building-locally/","title":"Building Locally","text":""},{"location":"dev-guide/contributing/building-locally/#building-locally","title":"Building Locally","text":""},{"location":"dev-guide/contributing/building-locally/#workspace-prerequisites","title":"Workspace Prerequisites","text":"<p>All the prerequisites mentioned in Installation Prerequisites must be fulfilled.</p> <ul> <li>Install Go for Windows.</li> </ul>"},{"location":"dev-guide/contributing/building-locally/#build-go-projects","title":"Build Go projects","text":"<p>Building Go based projects is done through BuildGoExe.ps1</p> <p>Tip</p> <p><code>bgo.cmd</code> is a shortcut command to invoke the script <code>BuildGoExe.ps1</code>. If you have not installed K2s yet, then your <code>PATH</code> is not updated with the required locations. In this case, look for bgo.cmd and invoke the build command.</p> <p>In the below example, <code>c:\\ws\\k2s</code> is the root of the Git repo: Bash Session<pre><code>where bgo\nC:\\ws\\k2s\\bin\\bgo.cmd\n</code></pre></p> <p>Building <code>httpproxy</code> Go project: Bash Session<pre><code>C:\\ws\\k2s\\bin\\bgo -ProjectDir \"C:\\ws\\k2s\\k2s\\cmd\\httpproxy\\\" -ExeOutDir \"c:\\ws\\k2s\\bin\"\n</code></pre></p> <p>Info</p> <p>The <code>k2s</code> CLI can be built without any parameters:</p> Bash Session<pre><code>C:\\ws\\k2s\\bin\\bgo\n</code></pre> <p>To build all Go executables: Bash Session<pre><code>C:\\ws\\k2s\\bin\\bgo -BuildAll\n</code></pre></p> <p>If K2s is installed then just simply execute the command without the full path: Bash Session<pre><code>bgo -ProjectDir \"C:\\ws\\k2s\\k2s\\cmd\\httpproxy\\\" -ExeOutDir \"c:\\ws\\k2s\\bin\"\nbgo -BuildAll\n</code></pre></p>"},{"location":"dev-guide/contributing/cla-corporate-contributor/","title":"Corporate Contributors","text":""},{"location":"dev-guide/contributing/cla-corporate-contributor/#siemens-healthineers-contribution-license-agreement-for-corporate-contributors","title":"Siemens Healthineers Contribution License Agreement for Corporate Contributors","text":"<p>Thank you for your interest in contributing to open source software projects made available by Siemens Healthcare GmbH or an entity owned or controlled directly or indirectly by Siemens Healthineers AG (\u201cSiemens Healthineers\u201d). When you sign this Contribution License Agreement (CLA), you give Siemens Healthineers the legal permission to use and distribute your contribution. You do not surrender ownership of your contribution, and you do not give up any of your rights to use your contribution elsewhere. This CLA (\u201cAgreement\u201d) is agreed to by the party signing below (\u201cYou\u201d), and conveys certain license rights to Siemens Healthineers for Your contributions to Siemens Healthineers open source projects. Please note that the choice of license for the Project is solely with Siemens Healthineers and Siemens Healthineers cannot accept any contributions under different licenses. This Agreement is effective as of the signature date below.</p> <ol> <li> <p>Definitions. \u201cCode\u201d means the computer software code, whether in human-readable or machine-executable form, that is delivered by You to Siemens Healthineers under this Agreement. \u201cProject\u201d means any of the projects owned or managed by Siemens Healthineers in which software is offered under an open source license approved by the Open Source Initiative (OSI). \u201cSubmit\u201d is the act of uploading, submitting, transmitting, or distributing code or other content to any Project, including but not limited to communication on electronic mailing lists, source code control systems, and issue tracking systems that are managed by, or on behalf of, the Project for the purpose of discussing and improving that Project. \u201cSubmission\u201d means the Code and/or any other copyrightable material Submitted by You, including any associated comments and/or documentation, specifications, materials, feedback, information or other works of authorship.</p> </li> <li> <p>Your Submission. You must agree to the terms of this Agreement before making a Submission to any Project. This Agreement covers any and all Submissions that You, now or in the future (except as described in Section 4 below), Submit to any Project.</p> </li> <li> <p>Originality of Work. You represent that each of Your Submissions is entirely Your original work. Should You wish to Submit materials that are not Your original work , You shall ensure that any co-owner provides his consent to the content of this Agreement by co-signing this Agreement.</p> </li> <li> <p>Your Employer. References to \u201cemployer\u201d in this Agreement include Your employer or anyone else for whom You are acting in making Your Submission, e.g. as a contractor, vendor, or agent. If Your Submission is made in the course of Your work for an employer or Your employer has intellectual property rights in Your Submission by contract or applicable law, You must secure permission from Your employer to make the Submission before signing this Agreement. In that case, the term \u201cYou\u201d in this Agreement will refer to You and the employer collectively. If You change employers in the future and desire to Submit additional Submissions for the new employer, then You agree to sign a new Agreement and secure permission from the new employer before Submitting those Submissions.</p> </li> <li> <p>Licenses. a.  Copyright License. You grant Siemens Healthineers, and those who receive the Submission directly or indirectly from Siemens Healthineers, a perpetual, worldwide, non-exclusive, royalty-free, irrevocable license in the Submission to reproduce, prepare derivative works of, publicly display, publicly perform, make available to the public by wire or wireless means, and distribute the Submission and such derivative works, and to sublicense or transfer any or all of the foregoing rights to third-parties. b.  Patent License. You grant Siemens Healthineers, and those who receive the Submission directly or indirectly from Siemens Healthineers, a perpetual, worldwide, non-exclusive, sublicensable, royalty-free, irrevocable (except as stated in this section) and transferable license under Your patent claims that are necessarily infringed by the Submission or the combination of the Submission with the Project to which it was Submitted to make, have made, use, offer to sell, sell and import or otherwise dispose of the Submission alone or with this Project and/or any successor Project. c.  Other Rights Reserved. Each party reserves all rights not expressly granted in this Agreement. No additional licenses or rights whatsoever (including, without limitation, any implied licenses) are granted by implication, exhaustion, estoppel or otherwise.</p> </li> <li> <p>Representations and Warranties. You represent that You are legally entitled to grant the above licenses. You represent that each of Your Submissions is entirely Your original work (except as You may have disclosed under Section 3). You represent that You have secured permission from Your employer to make the Submission in cases where Your Submission is made in the course of Your work for Your employer or Your employer has intellectual property rights in Your Submission by contract or applicable law. You shall not Submit any personal data, i.e. any data subject to applicable data protection legislation, other than appropriate copyright notices as a part of Your Submission. If You are signing this Agreement on behalf of Your employer, You represent and warrant that You have the necessary authority to bind the listed employer to the obligations contained in this Agreement. You are not expected to provide support for Your Submission, unless You choose to do so. UNLESS REQUIRED BY APPLICABLE LAW OR AGREED TO IN WRITING, AND EXCEPT FOR THE WARRANTIES EXPRESSLY STATED IN SECTIONS 3, 4, AND 6, THE SUBMISSION UNDER THIS AGREEMENT IS PROVIDED WITHOUT WARRANTY OF ANY KIND, INCLUDING, BUT NOT LIMITED TO, ANY WARRANTY OF NONINFRINGEMENT, MERCHANTABILITY, OR FITNESS FOR A PARTICULAR PURPOSE.</p> </li> <li> <p>Notice to Siemens Healthineers. You agree to notify Siemens Healthineers in writing of any facts or circumstances of which You later become aware that would make Your representations in this Agreement inaccurate in any respect.</p> </li> <li> <p>Information about Submissions. You agree that contributions to Projects and information about contributions may be maintained indefinitely and disclosed publicly, including Your name and other information that You submit with Your Submission.</p> </li> <li> <p>Entire Agreement/Assignment. This Agreement is the entire agreement between the parties, and supersedes any and all prior agreements, understandings or communications, written or oral, between the parties relating to the subject matter hereof. This Agreement and all of its rights, obligations and licenses hereunder may be assigned by Siemens Healthineers.</p> </li> </ol> <p>By signing, You accept and agree to the terms of this Agreement for Your present and future Submissions to Siemens Healthineers. Siemens Healthineers\u2019 acceptance is hereby declared and valid upon uploading the unchanged and signed document by You. </p> ______ I am making Submissions in the course of work for my employer (or my employer has intellectual property rights in my Submissions by contract or applicable law). I have permission from my employer to make Submissions and enter into this Agreement on behalf of my employer who will confirm his approval by countersigning this Agreement below. The defined term \u201cYou\u201d includes me and my employer. Name of author (In case of multiple authors employed by same employer, you may add any contributor. Authors employed by a separate employer are not permitted to contribute under this CLA) Corporate title Date Signature of author GitHub/GitLab user Email Address Company name (employer) Name and corporate title of signatories Date Signature on behalf of company"},{"location":"dev-guide/contributing/cla-individual-contributor/","title":"Individual Contributors","text":""},{"location":"dev-guide/contributing/cla-individual-contributor/#siemens-healthineers-contribution-license-agreement-for-individual-contributors","title":"Siemens Healthineers Contribution License Agreement for Individual Contributors","text":"<p>Thank you for your interest in contributing to open source software projects made available by Siemens Healthcare GmbH or an entity owned or controlled directly or indirectly by Siemens Healthineers AG (\u201cSiemens Healthineers\u201d). When you sign this Contribution License Agreement (CLA), you give Siemens Healthineers the legal permission to use and distribute your contribution. You do not surrender ownership of your contribution, and you do not give up any of your rights to use your contribution elsewhere. This CLA (\u201cAgreement\u201d) is agreed to by the party signing below (\u201cYou\u201d), and conveys certain license rights to Siemens Healthineers for Your contributions to Siemens Healthineers open source projects. Please note that the choice of license for the Project is solely with Siemens Healthineers and Siemens Healthineers cannot accept any contributions under different licenses. This Agreement is effective as of the signature date below.</p> <ol> <li> <p>Definitions. \u201cCode\u201d means the computer software code, whether in human-readable or machine-executable form, that is delivered by You to Siemens Healthineers under this Agreement. \u201cProject\u201d means any of the projects owned or managed by Siemens Healthineers in which software is offered under an open source license approved by the Open Source Initiative (OSI). \u201cSubmit\u201d is the act of uploading, submitting, transmitting, or distributing code or other content to any Project, including but not limited to communication on electronic mailing lists, source code control systems, and issue tracking systems that are managed by, or on behalf of, the Project for the purpose of discussing and improving that Project. \u201cSubmission\u201d means the Code and/or any other copyrightable material Submitted by You, including any associated comments and/or documentation, specifications, materials, feedback, information or other works of authorship.</p> </li> <li> <p>Your Submission. You must agree to the terms of this Agreement before making a Submission to any Project. This Agreement covers any and all Submissions that You, now or in the future (except as described in Section 4 below), Submit to any Project.</p> </li> <li> <p>Originality of Work. You represent that each of Your Submissions is entirely Your original work. Should You wish to Submit materials that are not Your original work , You shall ensure that any co-owner provides his consent to the content of this Agreement by co-signing this Agreement.</p> </li> <li> <p>Licenses. a.  Copyright License. You grant Siemens Healthineers, and those who receive the Submission directly or indirectly from Siemens Healthineers, a perpetual, worldwide, non-exclusive, royalty-free, irrevocable license in the Submission to reproduce, prepare derivative works of, publicly display, publicly perform, make available to the public by wire or wireless means, and distribute the Submission and such derivative works, and to sublicense or transfer any or all of the foregoing rights to third-parties. b.  Patent License. You grant Siemens Healthineers, and those who receive the Submission directly or indirectly from Siemens Healthineers, a perpetual, worldwide, non-exclusive, sublicensable, royalty-free, irrevocable (except as stated in this section) and transferable license under Your patent claims that are necessarily infringed by the Submission or the combination of the Submission with the Project to which it was Submitted to make, have made, use, offer to sell, sell and import or otherwise dispose of the Submission alone or with this Project and/or any successor Project. c.  Other Rights Reserved. Each party reserves all rights not expressly granted in this Agreement. No additional licenses or rights whatsoever (including, without limitation, any implied licenses) are granted by implication, exhaustion, estoppel or otherwise.</p> </li> <li> <p>Representations and Warranties. You represent that You are legally entitled to grant the above licenses. You represent that each of Your Submissions is entirely Your original work (except as You may have disclosed under Section 3). You represent that You have not assigned nor licensed intellectual property rights in Your Submission to an employer, contractor or otherwise. You are not expected to provide support for Your Submission, unless You choose to do so. You shall not Submit any personal data, i.e. any data subject to applicable data protection legislation, other than appropriate copyright notices as a part of Your Submission. UNLESS REQUIRED BY APPLICABLE LAW OR AGREED TO IN WRITING, AND EXCEPT FOR THE WARRANTIES EXPRESSLY STATED IN SECTIONS 3, 4, AND 6, THE SUBMISSION UNDER THIS AGREEMENT IS PROVIDED WITHOUT WARRANTY OF ANY KIND, INCLUDING, BUT NOT LIMITED TO, ANY WARRANTY OF NONINFRINGEMENT, MERCHANTABILITY, OR FITNESS FOR A PARTICULAR PURPOSE.</p> </li> <li> <p>Notice to Siemens Healthineers. You agree to notify Siemens Healthineers in writing of any facts or circumstances of which You later become aware that would make Your representations in this Agreement inaccurate in any respect.</p> </li> <li> <p>Information about Submissions. You agree that contributions to Projects and information about contributions may be maintained indefinitely and disclosed publicly, including Your name and other information that You submit with Your Submission.</p> </li> <li> <p>Entire Agreement/Assignment. This Agreement is the entire agreement between the parties, and supersedes any and all prior agreements, understandings or communications, written or oral, between the parties relating to the subject matter hereof. This Agreement and all of its rights, obligations and licenses hereunder may be assigned by Siemens Healthineers.</p> </li> </ol> <p>By signing, You accept and agree to the terms of this Agreement for Your present and future Submissions to Siemens Healthineers. Siemens Healthineers\u2019 acceptance is hereby declared and valid upon uploading the unchanged and signed document by You.</p> ______ I have sole ownership of intellectual property rights to my Submissions and I am not making Submissions in the course of work for my employer. Name of author (In case of multiple authors, you may add any contributor.) Date Signature of author GitHub/GitLab user Email Address"},{"location":"dev-guide/contributing/licensing/","title":"Licensing","text":""},{"location":"dev-guide/contributing/licensing/#licensing","title":"Licensing","text":"<p>Warning</p> <p>All files, whether own code or 3rd-party code (i.e. PowerShell/Go snippets or configuration files like yaml manifests, etc.), have to be clearly marked with the respective license.</p> <p>The currently supported/used 3rd-party licenses can be found in the LICENSES folder.</p> <p>Warning</p> <p>This repository follows the REUSE Specification \u2013 Version 3.0, meaning that a valid license configuration must exist for every file, either as comment or as separate *.license file.</p> <p>The CI runs will check all files against the REUSE specification, but you can pre-check your local repo using the reuse tool.</p>"},{"location":"dev-guide/contributing/powershell-dev/","title":"PowerShell Development","text":""},{"location":"dev-guide/contributing/powershell-dev/#powershell-development","title":"PowerShell Development","text":""},{"location":"dev-guide/contributing/powershell-dev/#strings","title":"Strings","text":"<p>PowerShell takes us a lot of thinking off when it comes to strings.</p> <p>For example just using</p> PowerShell<pre><code>$myPath\\theFile.yaml\n</code></pre> <p>will be interpreted as a string in the end. When using double quotes like</p> PowerShell<pre><code>\"$myPath\\theFile.yaml\"\n</code></pre> <p>we are then telling PowerShell that it is a string (PowerShell doesn't have to do its best guess). And if our string must contain double quotes, then</p> PowerShell<pre><code>\"`\"$myPath\\theFile.yaml`\"\"\n</code></pre> <p>(in the latter case, PowerShell interprets a string out of it) has to be used.</p>"},{"location":"dev-guide/contributing/powershell-dev/#paths","title":"Paths","text":"<p>Since a path can contain empty spaces extra attention has to be paid, specially when calling an external Windows tool with a path as argument.</p> <p>The rule of thumb is the following:</p> <ul> <li>If a path value is used as argument in a call to an external tool --&gt; add double quotes to the path value</li> </ul> <p>Example</p> PowerShell<pre><code>\u00a0\u00a0\u00a0 &amp;$global:BinPath\\kubectl.exe delete -f \"$myPath\\theFile.yaml\"\n</code></pre> <ul> <li>else --&gt; nothing to do, PowerShell takes care of it</li> </ul> <p>For some tools this is not strictly necessary, but doing so we are on the safe side, it proves that we have reflected on this and also helps the next developer that is confronted with the code (many times just ourselves...)</p>"},{"location":"dev-guide/contributing/powershell-dev/#escaping","title":"Escaping","text":"<p>Escaping has been changed in PowerShell Core (PS version &gt; 5) which is required for newer PowerShell Core versions. The following example shows how quotes needs to be escaped when executing a Linux remote command:</p> PowerShell<pre><code>if ($PSVersionTable.PSVersion.Major -gt 5) {\n    ExecCmdMaster \"echo Acquire::http::Proxy \\\"\"$Proxy\\\"\"\\; | sudo tee -a /etc/apt/apt.conf.d/proxy.conf\" -UsePwd\n} else {\n    ExecCmdMaster \"echo Acquire::http::Proxy \\\\\\\"\"$Proxy\\\\\\\"\"\\; | sudo tee -a /etc/apt/apt.conf.d/proxy.conf\" -UsePwd\n}\n</code></pre>"},{"location":"dev-guide/contributing/powershell-dev/#markers","title":"Markers","text":"<p>Passing markers from PowerShell to the CLI will result in appropriate user messages. The following example shows how during installation, if some pre-requisite checks fail then marker <code>[PREREQ-FAILED]</code> is sent through error stream which results in only warning message to user without going to corrupted install state.</p> PowerShell<pre><code>if ( $MasterVMMemory -lt 2GB ) {\n    Write-Log 'k2s needs minimal 2GB main memory, you have passed a lower value!' -Error\n    throw '[PREREQ-FAILED] Master node memory passed too low'\n}\n</code></pre> <p>Following markers are in use:</p> <ul> <li><code>[PREREQ-FAILED]</code> : Used in installation step, does not lead to corrupted state, uninstall is not necessary, cleanup of setup.json is performed.</li> </ul>"},{"location":"dev-guide/contributing/powershell-dev/#testing","title":"Testing","text":"<p>See Automated Testing with Pester.</p>"},{"location":"dev-guide/contributing/submitting-changes/","title":"Submitting Changes","text":""},{"location":"dev-guide/contributing/submitting-changes/#submitting-changes","title":"Submitting Changes","text":"<p>The following guidelines apply to submitting changes to K2s:</p> <ul> <li>Only commit changes when a corresponding issue exists and the maintainers have agreed that this issue is going to be realized (see K2s Issues)</li> <li>Reference the issue in commit messages, e.g. for a refactoring issue with ID 42, create a message like <code>#42 refactor(addons): obsolete code path removed</code>. </li> </ul> <p>Info</p> <p>This example also uses Conventional Commits, which is not mandatory, but recommended.</p> <ul> <li>Since K2s is open source, we utilize the GitHub's Pull Requests workflow:<ul> <li>Fork this repository (applies to all non-maintainers)</li> <li>Create a separate branch, commit to that branch and push your changes</li> <li>Create a PR in GitHub to this repository. This will trigger at least short-running automated tests.</li> <li>The PR will be reviewed by the maintainers. If re-work is needed, the preceding steps will be iterated. If the changes are acceptable, the PR will be merged to main.</li> </ul> </li> <li>Sign your commits (see Commit Signing)</li> <li>Run as many automated tests as possible, but at least the unit tests: <code>&lt;repo&gt;\\test\\execute_all_tests.ps1 -Tags unit</code> (see also Main Script: execute_all_tests.ps1). Depending on the area of changes, consider running the appropriate e2e tests as well.</li> </ul>"},{"location":"dev-guide/contributing/submitting-changes/#commit-signing","title":"Commit Signing","text":"<p>Signing commits increases trust in your contributions. Verified commit signatures will be display in GitHub like this:</p> Verified Commit <p>Further readings: Displaying verification statuses for all of your commits</p> <p>Tip</p> <p>If you use Visual Studio Code in conjunction with the GitHub Pull Requests Extension and you are logged in into GitHub with that extension, your commits might get signed automatically already.</p> <p>To setup code signing manually, follow these steps:</p> <ul> <li>If you do not have a GPG key yet, see Generating a new GPG key.</li> </ul> <p>Info</p> <p>Since you are most likely running on Windows, you can use the Git bash for <code>gpg</code> commands</p> <ul> <li> <p>If you have a GPG key in place, sign your commits. According to Signing commits, the following options exist:</p> <ul> <li>sign every commit with <code>git commit -S -m \"YOUR_COMMIT_MESSAGE\"</code></li> <li>enable GPG signature for the whole local repo with <code>git config commit.gpgsign true</code></li> <li>enable GPG signature for all local repos with <code>git config --global commit.gpgsign true</code></li> </ul> <p>Tip</p> <p>To avoid entering the passphrase for the GPG key too often, you can increase the expiration time, e.g. on Windows using Gpg4win (see How do I install and use gpg-agent on Windows?). Alternatively, these settings can also be modified in this file: <code>C:\\Users\\&lt;user&gt;\\AppData\\Roaming\\gnupg\\gpg-agent.conf</code></p> </li> </ul> <p>See Managing commit signature verification for more information.</p>"},{"location":"dev-guide/contributing/tags-labels/","title":"Tags/Labels","text":""},{"location":"dev-guide/contributing/tags-labels/#tagslabels","title":"Tags/Labels","text":"<p>To control which tests or test types shall be executed in which context/environment, tags/labels can be utilized.</p> <p>Note</p> <p>Tags and labels can be used synonymously. See Pester Tag Documentation for information about tagging/labelling Pester tests. See Ginkgo Spec Labels Documentation for information about tagging/labelling Ginkgo tests.</p>"},{"location":"dev-guide/contributing/tags-labels/#pester-example","title":"Pester Example","text":"<p>Define one or more tags at any level of a test container: PowerShell<pre><code># ...\nDescribe 'Get-Status' -Tag 'unit', 'addon' {\n    # ...\n}\n# ...\n</code></pre> Execute tests with tag unit: PowerShell<pre><code>Invoke-Pester &lt;dir-with-test-files&gt; -Tag unit\n</code></pre></p>"},{"location":"dev-guide/contributing/tags-labels/#ginkgo-example","title":"Ginkgo Example","text":"<p>Define one or more labels at any level of a test node, here for a whole test suite: Go<pre><code>// ...\nfunc TestHttpproxyUnitTests(t *testing.T) {\n    RegisterFailHandler(Fail)\n    RunSpecs(t, \"httpproxy Unit Tests\", Label(\"unit\", \"ci\"))\n}\n// ...\n</code></pre> Execute tests with tag unit: Bash Session<pre><code>ginkgo --label-filter=\"unit\" &lt;dir-with-test-suites&gt;\n</code></pre></p>"},{"location":"dev-guide/contributing/tags-labels/#commonly-used-tags","title":"Commonly Used Tags","text":"Name Description acceptance end-to-end test/executable spec in production-like scenario integration test requiring certain external resources/systems to be reachable or additional software to be installed unit test can be executed in isolation, all dependencies to the environment are mocked ci test that is fast-running and therefore applicable to CI runs; applies most likely to all unit tests addon test is addon-related and does not test K2s core functionality internet-required test requires internet connectivity, e.g. for package downloads invasive test changes either state of the host system or K2s installation read-only test does not change state of the host system or K2s installation; optional, since read-only tests should be the default setup-required test requires K2s to be installed; currently, the tests determine the setup type in the test runs no-setup K2s must not be installed on the system to test pre-installation behavior setup=\\&lt;setup name&gt; K2s setup type must match, e.g. setup=k2s system-running test requires K2s to be started/running system-stopped test requires K2s to be stopped"},{"location":"dev-guide/contributing/updating-documentation/","title":"Updating Documentation","text":""},{"location":"dev-guide/contributing/updating-documentation/#updating-documentation","title":"Updating Documentation","text":"<p>The documentation is written in Markdown, this website is generated based on this Markdown content using Material for MkDocs and the documentation versioning is done with mike.</p> <p>This website is hosted on GitHub Pages based on the <code>gh-pages</code> branch (i.e. the default GitHub Pages branch).</p>"},{"location":"dev-guide/contributing/updating-documentation/#updating-based-on-main-branch","title":"Updating based on <code>main</code> Branch","text":"<p>To update the current documentation based on the <code>main</code> branch: </p> <ol> <li>Install Material for MkDocs</li> <li>Run inside the local repo/installation folder of K2s:    Bash Session<pre><code>mkdocs serve\n</code></pre></li> <li>Open http://127.0.0.1:8000/K2s/ in your web browser to see your local changes being applied on-the-fly</li> <li>Submit your changes</li> <li>Wait for the automatically triggered workflow  to finish</li> <li> Your changes are now published to https://siemens-healthineers.github.io/K2s/next</li> </ol> <p>Note</p> <p>Since <code>mkdocs serve</code> does not take versioning into account, the following warning will appear in the console output:   <code>\"GET /versions.json HTTP/1.1\" code 404</code>   This warning can safely be ignored. To test different documentation versions locally, see Documentation Versioning.</p>"},{"location":"dev-guide/contributing/updating-documentation/#documentation-versioning","title":"Documentation Versioning","text":"<p>To provide different versions of the generated documentation (e.g. a version per release and a current one matching the contents of the <code>main</code> branch), to tool mike can be utilized like described in the following:</p> <p>If not done already, install mike: Bash Session<pre><code>pip install mike\n</code></pre></p> <p>To inspect all existing documentation versions on the <code>gh-pages</code> branch, run: Bash Session<pre><code>mike list\n</code></pre></p> <p>To add a new version, run: Bash Session<pre><code>mike deploy &lt;version&gt; [&lt;alias&gt;]\n</code></pre></p> <p>Example</p> <p>To create a new version <code>v1.2.3</code> with the tag <code>latest</code>, run:   Bash Session<pre><code>mike deploy v1.2.3 latest\n</code></pre>   This will create a local commit to the <code>gh-pages</code> branch that still has to be pushed to origin.</p> <p>Alternatively, mike can also create a new version and push the changes in one call with the <code>-p</code> or <code>--pull</code> parameter:   Bash Session<pre><code>mike deploy v1.2.3 latest -p\n</code></pre></p> <p>To set a default version the user is redirected to when browsing the root URL: Bash Session<pre><code>mike set-default &lt;version&gt;|&lt;alias&gt;\n</code></pre></p> <p>Example</p> <p>To set the default version to the one with the tag <code>latest</code>, run:   Bash Session<pre><code>mike set-default latest\n</code></pre></p> <p>To delete a version, run: Bash Session<pre><code>mike delete &lt;version&gt;\n</code></pre></p> <p>To preview documentation versioning, run: Bash Session<pre><code>mike serve\n</code></pre></p> <p>Tip</p> <p><code>mike serve</code> is similar to <code>mkdocs serve</code>, but additionally takes versioning into account. On the other hand, mike's local dev server is extremely slow compared to mkdocs's built-in dev server so the recommendation is to use <code>mkdocs serve</code> for previewing changes to the documentation and <code>mike serve</code> for previewing changes to the versions.</p>"},{"location":"dev-guide/contributing/linux-development/linux-development/","title":"Linux development","text":""},{"location":"dev-guide/contributing/linux-development/linux-development/#remote-linux-development-via-ssh-and-vs-code","title":"Remote Linux Development via SSH and VS Code","text":""},{"location":"dev-guide/contributing/linux-development/linux-development/#1-create-ssh-config-file","title":"1. Create SSH Config File","text":"<ul> <li>On your Windows machine, open the file <code>C:\\Users\\&lt;YourUsername&gt;\\.ssh\\config</code> (create it if it doesn\u2019t exist).</li> <li>Add the following entry, adjusting paths and IP as needed: </li> <li>HostName is the IP address of your Linux VM created after K2s installation.</li> <li>User is the username you set up during K2s installation (default is <code>remote</code>)</li> <li>After K2s is successfully installed, <code>id_rsa</code> file is created in <code>C:\\Users\\&lt;YourUsername&gt;\\.ssh\\K2s\\id_rsa</code> and is the private key used to connect to the Linux VM.</li> <li>Replace <code>&lt;YourUsername&gt;</code> with your actual Windows username.</li> </ul>"},{"location":"dev-guide/contributing/linux-development/linux-development/#2-install-remote-ssh-extension-in-vs-code","title":"2. Install Remote-SSH Extension in VS Code","text":"<ul> <li>Open Visual Studio Code.</li> <li>Go to Extensions (<code>Ctrl+Shift+X</code>), search for <code>Remote - SSH</code>, and install it. </li> </ul>"},{"location":"dev-guide/contributing/linux-development/linux-development/#3-connect-to-kubemaster","title":"3. Connect to KubeMaster","text":"<ul> <li>Press <code>F1</code> in VS Code, type <code>Remote-SSH: Connect to Host...</code>, and select <code>KubeMaster</code>.  </li> <li>VS Code will open a new window connected to your Linux VM. </li> </ul>"},{"location":"dev-guide/contributing/linux-development/linux-development/#4-example-clone-a-repository-on-linux-and-develop-from-windows-using-vs-code","title":"4. Example: Clone a Repository on Linux and Develop from Windows Using VS Code","text":"<ul> <li>In the remote VS Code window, open the terminal (`Ctrl+``).</li> <li>Run: check if internet is working by using following command - curl -vvv https://google.com</li> <li>If above curl command doesnt return 200 response, you need to set proxy in the terminal using following command <ul> <li>export http_proxy=http://172.19.1.1:8181 export https_proxy=https://172.19.1.1:8181 - But this is temporary and will be lost when you close the terminal.</li> <li>To make it permanent, you need to add proxy to ~/.bashrc file.     </li> <li>Add proxy to /etc/apt/apt.conf.d/proxy.conf \u2192 so apt update and apt install work.     </li> </ul> </li> <li>To clone a repository, run the following commands (replace <code>&lt;repo-url&gt;</code> with your repository URL):</li> <li>Install Git if its not already present in linux vm<ul> <li>bash</li> <li>sudo apt update</li> <li>sudo apt install git</li> <li>git --version</li> </ul> </li> <li>Set your git user name and email<ul> <li>git config --global user.name \"Your Name\"</li> <li>git config --global user.email \"Your email\"</li> </ul> </li> <li>Goto any folder in terminal and Clone a repository for example git clone https://github.com/Siemens-Healthineers/K2s .</li> <li>While cloning, Git may prompt for authentication. You can authenticate using your GitHub username and a personal access token (PAT), or follow the on-screen instructions for other supported authentication methods (such as browser-based login or OAuth).</li> <li>After cloning, Open the cloned repo folder in VS Code (<code>File &gt; Open Folder...</code>).</li> </ul>"},{"location":"includes/glossary/","title":"Glossary","text":""},{"location":"op-manual/adding-k2s-users/","title":"Adding K2s Users","text":""},{"location":"op-manual/adding-k2s-users/#adding-k2s-users","title":"Adding K2s Users","text":"<p>A K2s user is a Windows user that:</p> <ul> <li>has administrative access to the K8s nodes (authN/authZ)</li> <li>can call the K8s API (authN only, see Authorizing Users to Call K8s API Endpoints)</li> </ul> <p>When K2s is being installed, the Windows user executing the installation routine will be granted administrator access to the control-plane (via SSH) and worker nodes. In addition, this user will be configured as K8s cluster admin (authN via cert).</p> <p>Note</p> <p>K8s provides different ways to authenticate users (authN). K2s uses X509 client certificates.</p> <p>How to enable other Windows users on the same host machine to interact with K2s will be shown in the following.</p>"},{"location":"op-manual/adding-k2s-users/#granting-access-to-k2s","title":"Granting Access to K2s","text":"<p>Note</p> <p>A Windows user must have a local profile on the host machine in order to be granted access to K2s.</p> <p>Additionally, a Windows user must have administrator privileges to interact with K2s (see Prerequisites).</p> <p>To grant a specific Windows user access to K2s, run as K2s admin: Bash Session<pre><code>k2s system users add -u &lt;username&gt;\n</code></pre></p> <p>See <code>k2s system users add -h</code> for more options.</p> <p>Windows Username</p> <p>Typically the Windows username can be specified without the domain.</p> <p>Note</p> <p>The Windows account <code>NT AUTHORITY\\SYSTEM</code> (<code>SID S-1-5-18</code>) is a special case since it is not a user account. Nevertheless, you can specify the system account's name or <code>SID</code> to grant the system account access to K2s.</p> <p>Examples how to specify the Windows system account: Bash Session<pre><code>k2s system users add -u system\n\nk2s system users add -u \"NT AUTHORITY\\SYSTEM\"\n\nk2s system users add -i S-1-5-18\n</code></pre></p> Full Example With Detailed Steps <p>Given that the Windows user <code>desktop1234\\john</code> exists on the host and has a local profile/home directory, the K2s admin runs <code>k2s system users add -u john</code> which triggers the following steps:</p> <ul> <li>Creating an SSH key pair for John in <code>c:\\users\\john\\.ssh\\k2s\\</code> on the host. The admin must confirm overwriting existing key pairs. Since the SSH key pair was initially created by the admin's Windows account, the file security inheritance must be disabled, the Administrators group granted full file access (so that the K2s admin can revoke/delete John's access later) and the admin user must be removed from the ACL, otherwise SSH would complain about too open access permissions when John tries to use his SSH key. John's public SSH key contains the K2s-specific username as comment, i.e. <code>k2s-desktop1234-john</code>, so that removing entries only targets SSH fingerprints that have been created by K2s. As of now, none of the SSH keys being created by K2s are password-protected.</li> <li>Adding control-plane's SSH fingerprint to <code>c:\\users\\john\\.ssh\\known_hosts</code> file on the host. It removes previous control-plane fingerprint if existing.</li> <li>Adding John's SSH fingerprint to <code>~/.ssh/authorized_keys</code> on the control-plane. It removes John's previous fingerprint if existing.</li> <li>Creating <code>c:\\users\\john\\.kube\\config</code> if not existing, copying the K2s cluster configuration from admin's <code>kubeconfig</code>.</li> <li>Signing a new certificate for username <code>k2s-desktop1234-john</code> and group <code>k2s-users</code> using K8s's CA cert on the control-plane.</li> <li>Copying the new certificate to the host, embedding the certificate data for <code>k2s-desktop1234-john</code> in <code>c:\\users\\john\\.kube\\config</code> and deleting the cert files.</li> <li>Adding a new K8s context for <code>k2s-desktop1234-john</code> to <code>c:\\users\\john\\.kube\\config</code>, verifying the K8s authentication and switching back to previously active context if there was any.</li> </ul> <p>John has access to the control-plane now (authN/authZ) as well as to the K8s API (authN). To authorize John (authZ) on the K8s cluster, see Authorizing Users to Call K8s API Endpoints.</p>"},{"location":"op-manual/adding-k2s-users/#access-verification","title":"Access Verification","text":""},{"location":"op-manual/adding-k2s-users/#control-plane-node","title":"Control-Plane Node","text":"<p>The new user can verify the SSH access to the control-plane by running:</p> Bash Session<pre><code>ssh -o StrictHostKeyChecking=no -i \"~/.ssh\\k2s\\id_rsa\" \"remote@172.19.1.100\"\n</code></pre> <p>where <code>172.19.1.100</code> is the IP address of the control-plane and <code>remote</code> the Linux user with admin privileges.</p>"},{"location":"op-manual/adding-k2s-users/#k8s-api","title":"K8s API","text":"<p>As the new user, run:</p> Bash Session<pre><code>kubectl auth whoami -o jsonpath=\"{.status.userInfo}\"\n</code></pre> <p>The response should look similar to: JSON<pre><code>{\"groups\":[\"k2s-users\",\"system:authenticated\"],\"username\":\"k2s-DESKTOP-user1234\"}\n</code></pre></p> <p>This response proves that K8s verified the user cert presented in the current <code>kubeconfig</code> and extracted the username and group successfully.</p> <p>Tip</p> <p>To run this check for a different Windows user, e.g. as admin for a new K2s user, specify the <code>kubeconfig</code> explicitly:</p> Bash Session<pre><code>kubectl auth whoami -o jsonpath=\"{.status.userInfo} --kubeconfig path\\to\\other\\users\\kube\\config\"\n</code></pre>"},{"location":"op-manual/adding-k2s-users/#authorizing-users-to-call-k8s-api-endpoints","title":"Authorizing Users to Call K8s API Endpoints","text":"<p>Since K8s authorization is highly dependent on use cases and can get very complex, K2s does not provide built-in K8s authZ besides the cluster admin permissions.</p> <p>A common approach to K8s authZ is RBAC Authorization.</p> <p>Grant Permissions to Start K2s</p> <p>This example shows how to grant the new K2s user John from the previous example RBAC-based permissions to start the K2s cluster and inspect its status.</p> <p>To create a role for displaying nodes' status and taint nodes at startup, run:</p> Bash Session<pre><code>kubectl create clusterrole EditNodesRole --verb=\"get,list,watch,patch\" --resource=\"nodes\"\n</code></pre> <p>To create a role for displaying Pod status, run:</p> Bash Session<pre><code>kubectl create clusterrole ViewPodsRole --verb=\"get,list,watch\" --resource=\"pods\"\n</code></pre> <p> It is common practice to define roles cluster-wide (i.e. <code>clusterrole</code>) and to use them in a narrower scope/context (i.e. <code>rolebinding</code>). They can be seen as globally available templates with local instances.</p> <p>To assign John the <code>EditNodesRole</code> role, run:</p> Bash Session<pre><code>kubectl create clusterrolebinding EditNodesBinding --clusterrole=EditNodesRole --user=k2s-desktop1234-john\n</code></pre> <p> Instead of assigning a role to specific users, roles can also be assigned to groups, e.g. the <code>k2s-users</code> group. The downside would be, that roles cannot be removed from specific users if e.g. an admin wants to revoke access to K2s.</p> <p>To assign John the <code>ViewPodsRole</code> role in <code>kube-system</code> and <code>kube-flannel</code> namespaces, run:</p> Bash Session<pre><code>kubectl create rolebinding ViewPodsBinding --clusterrole=ViewPodsRole --user=k2s-desktop1234-john -n \"kube-system\"\nkubectl create rolebinding ViewPodsBinding --clusterrole=ViewPodsRole --user=k2s-desktop1234-john -n \"kube-flannel\"\n</code></pre> <p> In contrast to the role <code>EditNodesRole</code> which applies to the whole cluster, the role <code>ViewPodsRole</code> is only applied in <code>kube-system</code> and <code>kube-flannel</code> namespaces, therefore scoped to a narrow context.</p>"},{"location":"op-manual/adding-k2s-users/#revoking-access","title":"Revoking Access","text":"<p>There is no automated or bullet-proof way to revoke access to K2s (or removing a K2s user respectively). The manual best-effort steps will be described in the following.</p>"},{"location":"op-manual/adding-k2s-users/#control-plane","title":"Control-plane","text":"<ul> <li>[Essential] On control-plane, remove SSH key fingerprint from <code>~/.ssh/authorized_keys</code> for the specific user (entry should contain username with <code>k2s-</code> prefix).</li> <li>[Cleanup] Remove SSH key pair folder <code>&lt;home-dir&gt;\\.ssh\\k2s\\</code>.</li> <li>[Cleanup] Remove control-plane fingerprint from <code>&lt;home-dir&gt;\\.ssh\\known_hosts</code>, normally starting with the control-plane's IP address <code>172.19.1.100</code>.</li> </ul>"},{"location":"op-manual/adding-k2s-users/#k8s-api_1","title":"K8s API","text":""},{"location":"op-manual/adding-k2s-users/#authn","title":"AuthN","text":"<p>K8s offers no mechanism to revoke user certificates. As long as the user holds the certificate (assuming it did not expire yet), the user can authenticate himself to K8s. Without permissions, though, the user can only call unrestricted API endpoints like <code>kubectl version</code>.</p> <ul> <li>Assuming the user is unharmful and did not create a copy of his certificate, his credentials including the certificate data can be removed from the <code>&lt;home-dir&gt;\\.kube\\config</code> file. The <code>k2s-</code> prefix uniquely identifies the user.</li> <li>Additionally, the K2s cluster config and corresponding context can be removed. If no more clusters are configured, the whole <code>kubeconfig</code> file can be removed.</li> </ul>"},{"location":"op-manual/adding-k2s-users/#authz","title":"AuthZ","text":"<p>Remove all <code>rolebinding</code> and <code>clusterrolebinding</code> K8s resources associated with the user, e.g. undo the example steps in Authorizing Users to Call K8s API Endpoints.</p>"},{"location":"op-manual/adding-k2s-users/#caveats","title":"Caveats","text":"<ul> <li>Without external IAM, K8s does not provide user management or means to revoke access when cert authN is being used. As long as a user presents a valid cert, he is authenticated to K8s.</li> <li>When K8s' CA cert expires, all derived user certs have to be re-generated and all <code>kubeconfig</code> files must be updated with the new cluster config and user credentials.</li> <li>K2s does not provide RBAC for control-plane access, all Windows users use the same Linux admin account.</li> <li>There is no info available yet, which k2s CLI command requires which K8s permissions (RBAC), e.g. for stopping the K2s cluster, SSH access to the control-plane is sufficient, whereas for starting the cluster, the K8s permissions to patch a node's config is required (see example in Authorizing Users to Call K8s API Endpoints).</li> <li>The SSH keys created by K2s are not password-protected.</li> </ul>"},{"location":"op-manual/checking-k2s-status/","title":"Checking K2s Status","text":""},{"location":"op-manual/checking-k2s-status/#checking-k2s-status","title":"Checking K2s Status","text":"<p>To check K2s's health status (including K8s's health), run: Bash Session<pre><code>k2s status\n</code></pre></p> <p>To display additional status details, run: Bash Session<pre><code>&lt;repo&gt;k2s status -o wide\n</code></pre></p> <p>Alternatively, the <code>ks</code> shortcut can be executed (see CLI Shortcuts).</p> Output of \"k2s status -o wide\""},{"location":"op-manual/code-signing/","title":"Code signing","text":""},{"location":"op-manual/code-signing/#k2s-code-signing","title":"K2s Code Signing","text":"<p>This document describes the K2s code signing functionality that ensures all executables and PowerShell scripts are signed with a trusted certificate.</p>"},{"location":"op-manual/code-signing/#overview","title":"Overview","text":"<p>K2s includes comprehensive code signing capabilities to meet enterprise security requirements:</p> <ul> <li>PowerShell Scripts: All <code>.ps1</code>, <code>.psm1</code> files are signed with Authenticode signatures</li> <li>Executables: All <code>.exe</code>, <code>.dll</code> files are signed with code signing certificates</li> <li>Installer Packages: All <code>.msi</code> files are signed with code signing certificates</li> <li>Automated Packaging: Create complete signed packages via <code>k2s system package</code></li> <li>CI/CD Integration: Automated signing in GitHub Actions workflows</li> </ul> <p>Note: CMD and BAT files cannot be Authenticode signed as they are plain text files and are excluded from the signing process.</p> <p>Important: Certificate operations require administrator privileges as certificates are stored in the LocalMachine certificate store for enterprise-wide deployment.</p>"},{"location":"op-manual/code-signing/#quick-start","title":"Quick Start","text":""},{"location":"op-manual/code-signing/#create-a-signed-package","title":"Create a Signed Package","text":"PowerShell<pre><code># Create package with existing certificate\nk2s system package --target-dir \"C:\\tmp\" --name \"k2s-signed.zip\" --certificate \"mycert.pfx\" --password \"mycertpassword\"\n\n# Create package for offline installation with code signing\nk2s system package --target-dir \"C:\\tmp\" --name \"k2s-offline-signed.zip\" --for-offline-installation --certificate \"mycert.pfx\" --password \"mycertpassword\"\n</code></pre>"},{"location":"op-manual/code-signing/#install-certificate-for-trust","title":"Install Certificate for Trust","text":"PowerShell<pre><code># Import certificate from package using standard PowerShell cmdlets (requires administrator privileges)\nImport-PfxCertificate -FilePath k2s-signing.pfx -CertStoreLocation Cert:\\LocalMachine\\My\nImport-Certificate -FilePath k2s-signing.pfx -CertStoreLocation Cert:\\LocalMachine\\TrustedPublisher\n</code></pre>"},{"location":"op-manual/code-signing/#create-self-signed-certificate-for-testing","title":"Create Self-Signed Certificate for Testing","text":"<p>For development and testing purposes, you can create a self-signed code signing certificate. Important: Self-signed certificates must be installed to the Trusted Root store to avoid trust warnings.</p> PowerShell<pre><code># Create a self-signed code signing certificate (requires administrator privileges)\n$cert = New-SelfSignedCertificate -Subject \"CN=K2s Test Code Signing\" `\n    -Type CodeSigningCert `\n    -KeyUsage DigitalSignature `\n    -KeyAlgorithm RSA `\n    -KeyLength 2048 `\n    -NotAfter (Get-Date).AddYears(5) `\n    -CertStoreLocation Cert:\\LocalMachine\\My `\n    -KeyExportPolicy Exportable\n\n# Export to PFX file with password\n$password = ConvertTo-SecureString \"TestPassword123\" -AsPlainText -Force\nExport-PfxCertificate -Cert $cert -FilePath \"k2s-test-signing.pfx\" -Password $password\n\n# Export the public certificate for trust installation\nExport-Certificate -Cert $cert -FilePath \"k2s-test-signing.cer\"\n\n# Install to Trusted Root Certification Authorities (makes the certificate trusted)\nImport-Certificate -FilePath \"k2s-test-signing.cer\" -CertStoreLocation Cert:\\LocalMachine\\Root\n\n# Install to TrustedPublisher store for PowerShell script execution\nImport-Certificate -FilePath \"k2s-test-signing.cer\" -CertStoreLocation Cert:\\LocalMachine\\TrustedPublisher\n\n# Test the certificate with K2s package creation\nk2s system package --target-dir \"C:\\tmp\" --name \"k2s-test-signed.zip\" --certificate \"k2s-test-signing.pfx\" --password \"TestPassword123\"\n</code></pre> <p>Why install to Trusted Root? Self-signed certificates are not trusted by default. Installing the certificate to <code>Cert:\\LocalMachine\\Root</code> makes Windows trust the certificate, preventing \"certificate chain terminated in a root certificate which is not trusted\" errors during code signing verification.</p>"},{"location":"op-manual/code-signing/#command-reference","title":"Command Reference","text":""},{"location":"op-manual/code-signing/#k2s-system-package","title":"<code>k2s system package</code>","text":"<p>Creates a complete K2s package with all components signed.</p> <p>Required Options:</p> <ul> <li><code>--target-dir, -d</code>: Target directory for the package</li> <li><code>--name, -n</code>: The name of the zip package (must have .zip extension)</li> </ul> <p>Code Signing Options:</p> <ul> <li><code>--certificate, -c</code>: Path to code signing certificate (.pfx file)</li> <li><code>--password, -w</code>: Password for the certificate file</li> </ul> <p>Additional Options:</p> <ul> <li><code>--for-offline-installation</code>: Creates a package for offline installation</li> <li><code>--proxy, -p</code>: HTTP proxy if available</li> <li><code>--master-cpus</code>: Number of CPUs allocated to master VM</li> <li><code>--master-memory</code>: Amount of RAM to allocate to master VM (minimum 2GB)</li> <li><code>--master-disk</code>: Disk size allocated to the master VM (minimum 10GB)</li> <li><code>--k8s-bins</code>: Path to directory of locally built Kubernetes binaries</li> </ul> <p>Examples:</p> Bash<pre><code># Basic package creation\nk2s system package --target-dir \"C:\\tmp\" --name \"k2s-package.zip\"\n\n# Package for offline installation\nk2s system package --target-dir \"C:\\tmp\" --name \"k2s-offline.zip\" --for-offline-installation\n\n# Signed package with existing certificate\nk2s system package --target-dir \"C:\\tmp\" --name \"k2s-signed.zip\" --certificate \"./certs/my-cert.pfx\" --password \"certpassword\"\n\n# Signed offline package with all options\nk2s system package --target-dir \"C:\\tmp\" --name \"k2s-complete.zip\" --for-offline-installation --certificate \"./certs/my-cert.pfx\" --password \"certpassword\" --proxy \"http://proxy:8080\"\n</code></pre> <p>Note: When using code signing, both <code>--certificate</code> and <code>--password</code> must be provided together.</p>"},{"location":"op-manual/code-signing/#powershell-module-reference","title":"PowerShell Module Reference","text":"<p>The <code>k2s.signing.module</code> provides low-level signing functionality. Note: All certificate operations require administrator privileges.</p>"},{"location":"op-manual/code-signing/#certificate-management","title":"Certificate Management","text":"PowerShell<pre><code># List K2s certificates (requires administrator privileges) - Use standard PowerShell cmdlets\nGet-ChildItem -Path Cert:\\LocalMachine\\My | Where-Object { $_.Subject -like \"*K2s*\" }\n</code></pre>"},{"location":"op-manual/code-signing/#signing-operations","title":"Signing Operations","text":"PowerShell<pre><code># Sign all files (executables and scripts) in directory using certificate file\nSet-K2sFileSignature -SourcePath \"C:\\k2s\" -CertificatePath \"cert.pfx\" -Password $securePassword\n</code></pre>"},{"location":"op-manual/code-signing/#certificate-requirements","title":"Certificate Requirements","text":""},{"location":"op-manual/code-signing/#self-signed-certificates","title":"Self-Signed Certificates","text":"<p>The built-in certificate creation uses:</p> <ul> <li>Algorithm: RSA 2048-bit</li> <li>Key Usage: Digital Signature</li> <li>Validity: 10 years (configurable)</li> <li>Type: Code Signing Certificate</li> </ul>"},{"location":"op-manual/code-signing/#external-certificates","title":"External Certificates","text":"<p>For production use, you can provide:</p> <ul> <li>Commercial certificates from trusted CAs (Digicert, GlobalSign, etc.)</li> <li>Enterprise certificates from internal CAs</li> <li>Hardware Security Module (HSM) certificates</li> </ul> <p>Requirements:</p> <ul> <li>Must support code signing (<code>Enhanced Key Usage: 1.3.6.1.5.5.7.3.3</code>)</li> <li>Must be in PKCS#12 (.pfx) format with private key</li> <li>Must be password-protected</li> </ul>"},{"location":"op-manual/code-signing/#security-considerations","title":"Security Considerations","text":""},{"location":"op-manual/code-signing/#certificate-storage","title":"Certificate Storage","text":"<ul> <li>Development: Self-signed certificates stored in <code>LocalMachine\\My</code> (requires administrator privileges)</li> <li>Production: Use HSM or secure certificate storage</li> <li>CI/CD: Certificates stored as encrypted secrets</li> </ul>"},{"location":"op-manual/code-signing/#trust-validation","title":"Trust Validation","text":"<p>The signing process installs certificates in:</p> <ul> <li><code>LocalMachine\\My</code>: For signing operations</li> <li><code>LocalMachine\\TrustedPublisher</code>: For script execution</li> <li><code>LocalMachine\\Root</code>: For trust chain validation</li> </ul>"},{"location":"op-manual/code-signing/#execution-policy","title":"Execution Policy","text":"<p>Signed scripts work with these PowerShell execution policies:</p> <ul> <li><code>RemoteSigned</code>: Allows locally created and signed scripts</li> <li><code>AllSigned</code>: Requires all scripts to be signed</li> <li><code>Restricted</code>: Blocks all script execution</li> </ul>"},{"location":"op-manual/code-signing/#cicd-integration","title":"CI/CD Integration","text":""},{"location":"op-manual/code-signing/#github-actions","title":"GitHub Actions","text":"<p>The included workflow (<code>.github/workflows/code-signing.yml</code>) provides:</p> <ul> <li>Automatic signing on commits to main/develop</li> <li>Certificate management via GitHub Secrets</li> <li>Signed release packages for tagged versions</li> <li>Signature verification in CI pipeline</li> </ul>"},{"location":"op-manual/code-signing/#setup-github-secrets","title":"Setup GitHub Secrets","text":"<p>For automated signing, configure these secrets:</p> Text Only<pre><code>K2S_SIGNING_CERT_BASE64    # Base64-encoded .pfx certificate\nK2S_SIGNING_CERT_PASSWORD  # Certificate password\n</code></pre>"},{"location":"op-manual/code-signing/#manual-certificate-creation","title":"Manual Certificate Creation","text":"<p>To create certificates for CI/CD, use standard PowerShell cmdlets:</p> PowerShell<pre><code># Create certificate using standard PowerShell\n$cert = New-SelfSignedCertificate -Subject \"CN=K2s Code Signing Certificate\" `\n    -Type CodeSigningCert `\n    -KeyUsage DigitalSignature `\n    -KeyAlgorithm RSA `\n    -KeyLength 2048 `\n    -NotAfter (Get-Date).AddYears(10) `\n    -CertStoreLocation Cert:\\LocalMachine\\My\n\n# Export to PFX file\n$password = ConvertTo-SecureString \"YourPassword\" -AsPlainText -Force\nExport-PfxCertificate -Cert $cert -FilePath \"k2s-ci.pfx\" -Password $password\n\n# Convert to base64 for GitHub Secrets\n$bytes = [System.IO.File]::ReadAllBytes(\"k2s-ci.pfx\")\n$base64 = [Convert]::ToBase64String($bytes)\nWrite-Output $base64\n</code></pre>"},{"location":"op-manual/code-signing/#verification","title":"Verification","text":""},{"location":"op-manual/code-signing/#verify-powershell-scripts","title":"Verify PowerShell Scripts","text":"PowerShell<pre><code># Check script signature\n$sig = Get-AuthenticodeSignature -FilePath \"script.ps1\"\nWrite-Host \"Status: $($sig.Status)\"\nWrite-Host \"Signer: $($sig.SignerCertificate.Subject)\"\n</code></pre>"},{"location":"op-manual/code-signing/#verify-executables","title":"Verify Executables","text":"Text Only<pre><code># Using signtool (Windows SDK required)\nsigntool verify /v /pa app.exe\n\n# Check certificate details\nsigntool verify /v /pa /all app.exe\n</code></pre>"},{"location":"op-manual/code-signing/#package-verification","title":"Package Verification","text":"<p>Signed packages include a <code>package-manifest.json</code> with:</p> <ul> <li>Package creation timestamp</li> <li>Certificate information</li> <li>Count of signed files</li> <li>Verification checksums</li> </ul>"},{"location":"op-manual/code-signing/#troubleshooting","title":"Troubleshooting","text":""},{"location":"op-manual/code-signing/#common-issues","title":"Common Issues","text":"<p>\"Execution policy does not allow this script\"</p> <ul> <li>Solution: Install certificate using standard PowerShell cmdlets (<code>Import-PfxCertificate</code>, <code>Import-Certificate</code>)</li> <li>Alternative: Set execution policy to <code>RemoteSigned</code></li> </ul> <p>\"Certificate not found for signing\"</p> <ul> <li>Solution: Verify certificate is in <code>LocalMachine\\My</code> store (requires administrator privileges)</li> <li>Check thumbprint matches signing command</li> </ul> <p>\"Signtool not found\"</p> <ul> <li>Solution: Install Windows SDK or Visual Studio Build Tools</li> <li>Alternative: Use Windows ADK</li> </ul>"},{"location":"op-manual/code-signing/#debug-signing-issues","title":"Debug Signing Issues","text":"PowerShell<pre><code># List available certificates (requires administrator privileges)\nGet-ChildItem Cert:\\LocalMachine\\My | Where-Object { $_.KeyUsage -band [System.Security.Cryptography.X509Certificates.X509KeyUsageFlags]::DigitalSignature }\n\n# Test certificate\n$cert = Get-ChildItem Cert:\\LocalMachine\\My\\THUMBPRINT\nTest-Certificate -Cert $cert -Policy SSL\n\n# Validate script signature\n$sig = Get-AuthenticodeSignature -FilePath \"script.ps1\"\n$sig | Format-List *\n</code></pre>"},{"location":"op-manual/code-signing/#best-practices","title":"Best Practices","text":""},{"location":"op-manual/code-signing/#development","title":"Development","text":"<ul> <li>Use self-signed certificates for local development</li> <li>Include certificate import in setup scripts</li> <li>Test with <code>AllSigned</code> execution policy</li> </ul>"},{"location":"op-manual/code-signing/#production","title":"Production","text":"<ul> <li>Use commercial or enterprise CA certificates</li> <li>Implement certificate rotation procedures</li> <li>Monitor certificate expiration dates</li> <li>Use HSM for private key protection</li> </ul>"},{"location":"op-manual/code-signing/#distribution","title":"Distribution","text":"<ul> <li>Include certificates in installation packages</li> <li>Document certificate import procedures</li> <li>Provide verification instructions</li> <li>Maintain certificate trust chains</li> </ul>"},{"location":"op-manual/code-signing/#related-documentation","title":"Related Documentation","text":"<ul> <li>PowerShell Execution Policies</li> <li>Authenticode Signing</li> <li>Code Signing Best Practices</li> </ul>"},{"location":"op-manual/code-signing/#development-and-testing","title":"Development and Testing","text":""},{"location":"op-manual/code-signing/#unit-testing","title":"Unit Testing","text":"<p>The K2s signing module includes comprehensive unit tests that demonstrate best practices for testing PowerShell modules with external dependencies:</p> <p>Location: <code>lib\\modules\\k2s\\k2s.signing.module\\k2s.signing.module.unit.tests.ps1</code></p> <p>Key Features:</p> <ul> <li>Zero Side Effects: Tests use mocks and don't create certificates or modify system state</li> <li>Fast Execution: Complete test suite runs in ~1-2 seconds</li> <li>Comprehensive Coverage: Tests all signing functions and edge cases</li> <li>Mock Strategy: Uses module-level mocking with PSObject-based certificate mocks</li> </ul> <p>Running Tests:</p> PowerShell<pre><code># Run signing module unit tests\nInvoke-Pester .\\lib\\modules\\k2s\\k2s.signing.module\\k2s.signing.module.unit.tests.ps1\n\n# Run with detailed output\nInvoke-Pester -Output Detailed .\\lib\\modules\\k2s\\k2s.signing.module\\k2s.signing.module.unit.tests.ps1\n</code></pre> <p>The unit tests serve as both validation and documentation of proper mocking techniques for external dependencies like certificate operations, file system access, and external tool execution.</p> <p>For detailed information about PowerShell module unit testing best practices, see Automated Testing with Pester.</p>"},{"location":"op-manual/configuring-httpproxy-service/","title":"Configuring HTTPProxy Service","text":""},{"location":"op-manual/configuring-httpproxy-service/#configuring-httpproxy-service","title":"Configuring HTTPProxy Service","text":"<p>The HTTPProxy service is a proxy server that can be used to provide external network access to virtual machines running in Hyper-V without setting up a NAT network. </p> <p>During K2s installation, HTTPProxy is deployed as a Windows Service.</p> <p>By default, HTTPProxy service listens for requests on ALL available interfaces at port <code>8181</code>.</p> <p>The logs for HTTPProxy service are in directory <code>&lt;installation-drive&gt;\\var\\log\\httpproxy</code>. For example, if K2s is installed in directory <code>D:\\k2s</code> then HTTPProxy service logs will be available in directory <code>D:\\var\\log\\httpproxy</code>.</p>"},{"location":"op-manual/configuring-httpproxy-service/#customizing-httpproxy-listen-port","title":"Customizing HTTPProxy Listen Port","text":"<p>HTTPProxy can be started on a different port using the <code>addr</code> parameter. For example, if we want to start HTTPProxy service on Windows 10 Hyper-V host at port <code>30000</code>, then the it can be achieved as follows: Bash Session<pre><code>httpproxy --addr \":30000\"\n</code></pre> To edit the Windows service deployed by K2s, you can use NSSM to modify the parameters with which the service is started by adding <code>--addr \":30000\"</code> as shown below:</p> <p></p>"},{"location":"op-manual/configuring-httpproxy-service/#configuring-forward-proxy","title":"Configuring Forward Proxy","text":"<p>In some cases, the Windows 10 host itself receives internet connection via an internet proxy. In these cases, the HTTPProxy service must forward the requests to this internet proxy.</p> <p>This can be achieved by using the <code>--forward-proxy</code> parameter as shown below: Bash Session<pre><code>httpproxy --forward-proxy http://someproxyhost:8080\n</code></pre> In the above example, the internet proxy is available on URL <code>http://someproxyhost:8080</code>. In this case, the outgoing requests are forwarded to the internet through HTTPProxy via the the internet proxy.</p> <p>Using the NSSM UI, it can be achieved as shown below:</p> <p></p>"},{"location":"op-manual/configuring-httpproxy-service/#configuring-no_proxy-with-forward-proxy","title":"Configuring <code>NO_PROXY</code> with Forward Proxy","text":"<p>In some case, when the Windows 10 host receives internet connection via an internet proxy, certain requests are not meant to be forwarded to the internet. For example, we would want to pull a container image from a container registry hosted over the intranet. In these cases, the environment variable <code>NO_PROXY</code> can be appropriately configured on the host or in the NSSM UI.</p> <p>For example, we want to pull images from a container registry <code>registry.internal.com</code> we can configure the <code>NO_PROXY</code> variable as follows: <pre><code>NO_PROXY=registry.internal.com\n</code></pre> Multiple hosts or domain names can be specified in <code>NO_PROXY</code> separated by a comma as shown below: <pre><code>NO_PROXY=172.16.12.3,registry1.internal.com,registry2.internal.com,.internal.io\n</code></pre> In the above example, <code>.internal.io</code> is used to represent domain <code>internal.io</code>. Similarly, we can also configure IP addresses in <code>NO_PROXY</code>. However, adding Network CIDRs or subnets is not supported.</p> <p>The <code>NO_PROXY</code> environment variable can be configured as a system environment variable or as a process environment variable. For HTTPProxy Windows service, we can set the <code>NO_PROXY</code> as a process environment variable in the Environment tab of the NSSM's Edit UI as shown below:</p> <p></p>"},{"location":"op-manual/configuring-httpproxy-service/#configuring-listen-interfaces","title":"Configuring Listen Interfaces","text":"<p>In some cases, HTTPProxy should be used to provide internet access to only certain networks. In this case, we can specify the Network CIDRs of the interfaces for which HTTPProxy must provide internet access.</p> <p>For example, if HTTPProxy must provide internet access to network with CIDR <code>192.19.1.0/24</code> and <code>192.20.0.0/16</code>, then we can start the HTTPProxy service with the following parameters: <pre><code>httpproxy --allowed-cidr 192.19.1.0/24 --allowed-cidr 192.20.0.0/16\n</code></pre> In this case, only the virtual machines, running in the two configured networks, would have internet access. </p> <p>In the NSSM UI, we can add additional interfaces using <code>--allowed-cidr</code> to the service parameters:</p> <p></p>"},{"location":"op-manual/creating-offline-package/","title":"Creating Offline Package","text":""},{"location":"op-manual/creating-offline-package/#creating-offline-package","title":"Creating Offline Package","text":""},{"location":"op-manual/creating-offline-package/#k2s-offline-package","title":"K2s Offline Package","text":"<p>K2s provides support for creating an offline installation package<sup>1</sup>.</p> <p>No K2s cluster must be installed in order to create an offline package.</p> <p>To inspect various parameter options, run: Bash Session<pre><code>&lt;repo&gt;\\k2s.exe system package -h\n</code></pre></p> <p>To create a fully offline-capable install package, set the <code>--for-offline-installation</code> flag: Bash Session<pre><code>&lt;repo&gt;\\k2s.exe system package -d &lt;path-to-output-packe&gt;.zip --for-offline-installation\n</code></pre></p> <p>When running the aforementioned command and no K2s variant has been installed on the current system yet, the Development-Only Variant will be installed in order to create an offline package (which requires an internet connection). If all dependencies are already available locally due to prior installation of K2s, the offline package creation does not require internet connection.</p> Offline Package Creation Diagram <pre><code>graph TD\n    CallScript[\"'c\\k\\smallsetup\\helpers\\Buildk2sZipPackage.ps1\\n [-Proxy myProxy]\\n -TargetDirectory myExistingDirectory\\n -ZipPackageFileName myZipPackage.zip\\n [-ForOfflineInstallation]'\"] --&gt; if_for_offline{for offline\\n installation?}\n    if_for_offline --&gt;|no| AddBaseImageToExclusionList(\"Include c\\k\\bin\\Kubemaster-Base.vhdx to exclusion list\")\n    if_for_offline --&gt;|yes| if_baseImage_available{\"c\\k\\bin\\Kubemaster-Base.vhdx\\n exists?\"}\n    if_baseImage_available --&gt;|yes| GetFilesAndDirectories\n    if_baseImage_available --&gt;|no| BuildAndProvisionKubemasterBaseImage\n    AddBaseImageToExclusionList --&gt; GetFilesAndDirectories\n    BuildAndProvisionKubemasterBaseImage(\"Build and provision base image\") --&gt; GetFilesAndDirectories\n    GetFilesAndDirectories(\"Get a list with all files and directories\") --&gt; FilterByExclusionList\n    FilterByExclusionList(\"Remove files and directories from list according to exclusion list\") --&gt; CreateZipPackage\n    CreateZipPackage(\"Create zip package\") --&gt; PopulateZipPackage(\"Populate zip package with directories and files\")</code></pre> <p>Note</p> <p>Omitting the <code>--for-offline-installation</code> flag will effectively bundle only repository source files similar to the K2s Releases.</p>"},{"location":"op-manual/creating-offline-package/#addons-offline-package","title":"Addons Offline Package","text":"<p>To enable addons without an internet connection being available, the required binaries can be exported to an offline package as well.</p>"},{"location":"op-manual/creating-offline-package/#addons-export","title":"Addons Export","text":"<p>To inspect all export options, run: Bash Session<pre><code>k2s addons export -h\n</code></pre></p> <p>Either specify one or more addons to export: Bash Session<pre><code>k2s addons export registry -d &lt;export-output-directory&gt;\n</code></pre></p> <p>Or export all addons: Bash Session<pre><code>k2s addons export -d &lt;export-output-directory&gt;\n</code></pre></p>"},{"location":"op-manual/creating-offline-package/#addons-import","title":"Addons Import","text":"<p>To inspect all export options, run: Bash Session<pre><code>k2s addons import -h\n</code></pre></p> <p>Either specify one or more addons to import from the offline package: Bash Session<pre><code>k2s addons import registry -z &lt;directory-containing-addons-archive&gt;\\addons.zip\n</code></pre></p> <p>Or import all addons from the offline package: Bash Session<pre><code>k2s addons import -z &lt;directory-containing-addons-archive&gt;\\addons.zip\n</code></pre></p> <p>Note</p> <p>Importing a specific addon from the offline package does obviously not work when this package does not contain the specified addon.</p> <p>After importing an addon, it can be enabled without internet connection being available.</p>"},{"location":"op-manual/creating-offline-package/#delta-packages","title":"Delta Packages","text":"<p>For bandwidth-efficient upgrades, K2s supports creating delta packages that contain only the files changed between two versions. This significantly reduces package size for minor and patch upgrades.</p> <p>See Delta Packages for detailed documentation on creating and applying delta packages.</p> <ol> <li> <p>Creating of and installing from an offline package is currently supported for Host Variant and Development-Only only.\u00a0\u21a9</p> </li> </ol>"},{"location":"op-manual/delta-packages/","title":"Delta Packages","text":""},{"location":"op-manual/delta-packages/#delta-packages","title":"Delta Packages","text":"<p>Delta packages provide a bandwidth-efficient way to upgrade K2s installations by including only the files that have changed between two versions, rather than redistributing the entire package.</p>"},{"location":"op-manual/delta-packages/#overview","title":"Overview","text":"<p>A delta package contains:</p> <ul> <li>Changed files: Files that differ between the source and target versions</li> <li>Wholesale directories: Complete directories that must be replaced entirely (e.g., <code>bin/</code>, <code>addons/</code>)</li> <li>Delta manifest: A JSON file describing the changes and metadata</li> <li>Debian package changes (optional): Linux package differences for the KubeMaster VM</li> <li>Apply script: A PowerShell script to apply the delta to an existing installation</li> </ul>"},{"location":"op-manual/delta-packages/#delta-package-vs-full-package","title":"Delta Package vs Full Package","text":"Aspect Full Package Delta Package Size 2-4 GB typically 50-1000 MB typically Contains All K2s files Only changed files Requires Nothing Specific source version Use case Fresh installs, major upgrades Minor/patch upgrades"},{"location":"op-manual/delta-packages/#creating-a-delta-package","title":"Creating a Delta Package","text":""},{"location":"op-manual/delta-packages/#prerequisites","title":"Prerequisites","text":"<ul> <li>Two K2s offline packages (source and target versions)</li> <li>PowerShell 5.1 or later</li> <li>Sufficient disk space for extraction (3x package size recommended)</li> </ul>"},{"location":"op-manual/delta-packages/#basic-usage","title":"Basic Usage","text":"Bash Session<pre><code>k2s system package --delta-package `\n    -d C:\\packages `\n    -n k2s-delta-v1.4.0-to-v1.5.0.zip `\n    --package-version-from C:\\packages\\k2s-v1.4.0.zip `\n    --package-version-to C:\\packages\\k2s-v1.5.0.zip\n</code></pre> <p>\ud83d\udcdd Experimental Feature: Delta package creation is currently marked as experimental. The feature is fully functional but the CLI interface may evolve in future releases.</p>"},{"location":"op-manual/delta-packages/#parameters","title":"Parameters","text":"Flag Required Description <code>--delta-package</code> Yes Enables delta package creation mode <code>-d, --target-dir</code> Yes Target directory for the output package <code>-n, --name</code> Yes Name of the output delta package ZIP file <code>--package-version-from</code> Yes Path to the older (source) K2s package ZIP <code>--package-version-to</code> Yes Path to the newer (target) K2s package ZIP <code>-c, --certificate</code> No Path to code signing certificate (.pfx file) <code>-w, --password</code> No Password for the code signing certificate <code>-o, --output</code> No Show log output in terminal"},{"location":"op-manual/delta-packages/#example-with-code-signing","title":"Example with Code Signing","text":"Bash Session<pre><code>k2s system package --delta-package `\n    -d C:\\packages `\n    -n k2s-delta-v1.4.0-to-v1.5.0.zip `\n    --package-version-from C:\\packages\\k2s-v1.4.0.zip `\n    --package-version-to C:\\packages\\k2s-v1.5.0.zip `\n    -c path\\to\\cert.pfx `\n    -w mycertpassword\n</code></pre>"},{"location":"op-manual/delta-packages/#delta-package-contents","title":"Delta Package Contents","text":"<p>After creation, the delta package contains:</p> Text Only<pre><code>k2s-delta-v1.4.0-to-v1.5.0.zip\n\u251c\u2500\u2500 delta-manifest.json          # Metadata and file lists\n\u251c\u2500\u2500 Apply-Delta.ps1              # Application script\n\u251c\u2500\u2500 bin/                         # Changed binaries (wholesale)\n\u251c\u2500\u2500 addons/                      # Changed addon files (wholesale)\n\u251c\u2500\u2500 lib/                         # Changed library files\n\u251c\u2500\u2500 smallsetup/                  # Changed setup scripts\n\u251c\u2500\u2500 scripts/                     # Delta application scripts\n\u2502   \u251c\u2500\u2500 apply-debian-delta.sh   # Linux package update script\n\u2502   \u2514\u2500\u2500 verify-debian-delta.sh  # Linux package verification\n\u2514\u2500\u2500 debian-delta/                # (Optional) Debian package changes\n    \u251c\u2500\u2500 added-packages.txt\n    \u251c\u2500\u2500 removed-packages.txt\n    \u251c\u2500\u2500 changed-packages.txt\n    \u2514\u2500\u2500 packages/                # Downloaded .deb files\n</code></pre>"},{"location":"op-manual/delta-packages/#delta-manifest-structure","title":"Delta Manifest Structure","text":"<p>The <code>delta-manifest.json</code> file describes the changes between versions. A typical manifest includes:</p> JSON<pre><code>{\n  \"sourceVersion\": \"1.4.0\",\n  \"targetVersion\": \"1.5.0\",\n  \"createdAt\": \"2025-02-03T10:30:00Z\",\n  \"filesAdded\": [\"lib/new-module.psm1\"],\n  \"filesModified\": [\"lib/existing-module.psm1\"],\n  \"filesRemoved\": [\"lib/deprecated-module.psm1\"],\n  \"wholesaleDirectories\": [\"bin\", \"addons\"],\n  \"debianDelta\": {\n    \"added\": [\"new-package\"],\n    \"removed\": [\"old-package\"],\n    \"changed\": [\"updated-package\"]\n  },\n  \"imageDiff\": {\n    \"added\": [\"new-image:tag\"],\n    \"removed\": [\"old-image:tag\"]\n  }\n}\n</code></pre>"},{"location":"op-manual/delta-packages/#applying-a-delta-package","title":"Applying a Delta Package","text":""},{"location":"op-manual/delta-packages/#prerequisites_1","title":"Prerequisites","text":"<ul> <li>An existing K2s installation matching the delta's source version</li> <li>Administrator privileges</li> <li>The delta package ZIP file</li> </ul>"},{"location":"op-manual/delta-packages/#application-steps","title":"Application Steps","text":"<ol> <li> <p>Extract the delta package to a temporary location:    PowerShell<pre><code>Expand-Archive -Path \"k2s-delta-v1.4.0-to-v1.5.0.zip\" -DestinationPath \"C:\\temp\\delta\"\n</code></pre></p> </li> <li> <p>Run the upgrade from the extracted delta folder:    Bash Session<pre><code>cd C:\\temp\\delta\nk2s system upgrade\n</code></pre></p> </li> <li> <p>Verify the installation:    Bash Session<pre><code>k2s system status\n</code></pre></p> </li> </ol>"},{"location":"op-manual/delta-packages/#best-practices","title":"Best Practices","text":""},{"location":"op-manual/delta-packages/#when-to-use-delta-packages","title":"When to Use Delta Packages","text":"<p>\u2705 Recommended for:</p> <ul> <li>Minor version upgrades (e.g., 1.4.0 \u2192 1.5.0)</li> <li>Patch releases (e.g., 1.4.0 \u2192 1.4.1)</li> <li>Bandwidth-constrained environments</li> <li>Large-scale deployments with many nodes</li> </ul> <p>\u274c Not recommended for:</p> <ul> <li>Major version upgrades (e.g., 1.x \u2192 2.x)</li> <li>Fresh installations</li> <li>Upgrades spanning multiple minor versions</li> </ul>"},{"location":"op-manual/delta-packages/#version-compatibility","title":"Version Compatibility","text":"<p>\u26a0\ufe0f Version Matching: Delta packages are version-specific. A delta from v1.4.0 to v1.5.0 can only be applied to installations running exactly v1.4.0.</p> <p>To upgrade across multiple versions, either:</p> <ol> <li>Create sequential delta packages (v1.4.0 \u2192 v1.4.1 \u2192 v1.5.0)</li> <li>Use a full package for the final version</li> </ol>"},{"location":"op-manual/delta-packages/#troubleshooting","title":"Troubleshooting","text":""},{"location":"op-manual/delta-packages/#common-issues","title":"Common Issues","text":""},{"location":"op-manual/delta-packages/#version-mismatch-error","title":"Version Mismatch Error","text":"Text Only<pre><code>Error: Source version mismatch. Expected 1.4.0, found 1.3.0\n</code></pre> <p>Solution: Ensure your current installation matches the delta's source version, or use <code>-Force</code> (with caution).</p>"},{"location":"op-manual/delta-packages/#missing-files-after-apply","title":"Missing Files After Apply","text":"<p>Check the delta manifest to verify which files were expected:</p> PowerShell<pre><code>Get-Content delta-manifest.json | ConvertFrom-Json | Select-Object -ExpandProperty filesAdded\n</code></pre>"},{"location":"op-manual/delta-packages/#debian-delta-failures","title":"Debian Delta Failures","text":"<p>If Linux package updates fail:</p> <ol> <li>Check network connectivity in the VM</li> <li>Verify the <code>.deb</code> files exist in <code>debian-delta/packages/</code></li> <li>Run verification script to identify missing packages</li> </ol>"},{"location":"op-manual/delta-packages/#logs","title":"Logs","text":"<p>Delta package creation logs are written to:</p> <ul> <li>Console output (with <code>-o</code> or <code>--output</code> flag)</li> <li>K2s log directory: <code>C:\\var\\log\\k2s\\</code></li> </ul> <p>For more detailed logging, use the verbosity flag: Bash Session<pre><code>k2s system package --delta-package ... -o -v debug\n</code></pre></p>"},{"location":"op-manual/delta-packages/#integration-with-cicd","title":"Integration with CI/CD","text":""},{"location":"op-manual/delta-packages/#automated-delta-generation","title":"Automated Delta Generation","text":"YAML<pre><code># Example GitHub Actions workflow snippet\n- name: Generate Delta Package\n  run: |\n    k2s system package --delta-package `\n      -d ${{ env.OUTPUT_DIR }} `\n      -n \"k2s-delta-${{ env.PREV_VERSION }}-to-${{ env.NEW_VERSION }}.zip\" `\n      --package-version-from \"${{ env.PREV_PACKAGE }}\" `\n      --package-version-to \"${{ env.NEW_PACKAGE }}\" `\n      -o\n</code></pre>"},{"location":"op-manual/delta-packages/#artifact-publishing","title":"Artifact Publishing","text":"<p>Delta packages can be published alongside full releases:</p> Text Only<pre><code>releases/\n\u251c\u2500\u2500 k2s-v1.5.0.zip                    # Full package\n\u251c\u2500\u2500 k2s-delta-v1.4.0-to-v1.5.0.zip   # Delta from previous minor\n\u2514\u2500\u2500 k2s-delta-v1.4.1-to-v1.5.0.zip   # Delta from previous patch\n</code></pre>"},{"location":"op-manual/delta-packages/#see-also","title":"See Also","text":"<ul> <li>Creating Offline Package - Full offline package creation</li> <li>Upgrading K2s - Standard upgrade procedures</li> <li>Sign K2s Package - Code signing for packages</li> </ul>"},{"location":"op-manual/extending-k2s-cluster/","title":"Extending K2s cluster","text":""},{"location":"op-manual/extending-k2s-cluster/#experimental-extending-a-k2s-cluster","title":"[EXPERIMENTAL] Extending a K2s Cluster","text":"<p>This guide explains how to extend a K2s cluster by adding physical hosts or virtual machines to an existing K2s setup.</p>"},{"location":"op-manual/extending-k2s-cluster/#prerequisites","title":"Prerequisites","text":"<ol> <li>K2s Installed Machine:</li> <li>Ensure the existing machine with K2s installed is accessible.</li> <li> <p>Confirm that the K2s cluster is running and healthy.</p> </li> <li> <p>New Host or VM Requirements:</p> </li> <li>Install a compatible operating system (Linux or Windows, based on your cluster requirements).</li> <li>Install an SSH service on the new machine and ensure port 22 is enabled for connectivity.</li> <li>Ensure network connectivity with the K2s node.</li> <li>IP Address Requirements:<ul> <li>The IP address of the new machine must be in the same subnet as the K2s setup (e.g., <code>172.94.91.0/24</code>).</li> </ul> </li> </ol>"},{"location":"op-manual/extending-k2s-cluster/#known-limitations","title":"Known Limitations","text":"<ul> <li>Adding a new node works only if there is an internet connection on the new node. (Offline support is in progress.)</li> <li>Adding a new physical host is currently supported only on Debian and Ubuntu Linux distributions.</li> </ul>"},{"location":"op-manual/extending-k2s-cluster/#steps-to-add-a-physical-host-or-vm","title":"Steps to Add a Physical Host or VM","text":""},{"location":"op-manual/extending-k2s-cluster/#1-copy-the-public-ssh-key-to-the-new-node","title":"1. Copy the public SSH Key to the new node","text":"<p>When K2s is installed, an SSH public key is available under the directory <code>%USERPROFILE%\\.ssh\\k2s\\id_rsa.pub</code>. This key must be copied to the physical host or VM to establish communication and initiate the installation.</p>"},{"location":"op-manual/extending-k2s-cluster/#manually","title":"Manually","text":"<p>Copy the file from <code>%USERPROFILE%\\.ssh\\k2s\\id_rsa.pub</code> to any location on the machine <code>e.g. /tmp/ on Linux host</code> .</p>"},{"location":"op-manual/extending-k2s-cluster/#using-scp-and-password","title":"Using <code>scp</code> and password","text":""},{"location":"op-manual/extending-k2s-cluster/#linux-new-node","title":"Linux New Node","text":"Text Only<pre><code>scp -o StrictHostKeyChecking=no %USERPROFILE%\\.ssh\\k2s\\id_rsa.pub  &lt;usernameOfNode&gt;@&lt;IpAddressOfNode&gt;:/tmp/temp_k2s.pub\n</code></pre>"},{"location":"op-manual/extending-k2s-cluster/#windows-new-node","title":"Windows New Node","text":"Text Only<pre><code>scp -o StrictHostKeyChecking=no %USERPROFILE%\\.ssh\\k2s\\id_rsa.pub  &lt;usernameOfNode&gt;@&lt;IpAddressOfNode&gt;:c:\\\\temp\\\\temp_k2s.pub\n</code></pre> <p>scp</p> <p>Typically the password will be requested for the user to complete scp operation.</p>"},{"location":"op-manual/extending-k2s-cluster/#2-add-copied-public-ssh-key-to-the-authorized-users-key-file-of-ssh-service","title":"2. Add copied public SSH Key to the Authorized Users Key File of SSH Service","text":"<p>This operation ensures that the new node can be connected over SSH from K2s setup.</p>"},{"location":"op-manual/extending-k2s-cluster/#on-linux-new-node","title":"On Linux New Node","text":"Text Only<pre><code>cat /tmp/temp_k2s.pub &gt;&gt; ~/.ssh/authorized_keys &amp;&amp; cat ~/.ssh/authorized_keys\n</code></pre>"},{"location":"op-manual/extending-k2s-cluster/#on-windows-new-node","title":"On Windows New Node","text":"PowerShell<pre><code>$rootPublicKey = 'c:\\temp\\temp_k2s.pub'\n$authorizedkeypath = 'C:\\ProgramData\\ssh\\administrators_authorized_keys'\n\nWrite-Output 'Adding public key for SSH connection'\n\nif ((Test-Path $authorizedkeypath -PathType Leaf)) {\n    Write-Output \"$authorizedkeypath already exists! overwriting new key\"\n\n    Set-Content $authorizedkeypath -Value $rootPublicKey\n}\nelse {\n    New-Item $authorizedkeypath -ItemType File -Value $rootPublicKey\n\n    $acl = Get-Acl C:\\ProgramData\\ssh\\administrators_authorized_keys\n    $acl.SetAccessRuleProtection($true, $false)\n    $administratorsRule = New-Object system.security.accesscontrol.filesystemaccessrule('Administrators', 'FullControl', 'Allow')\n    $systemRule = New-Object system.security.accesscontrol.filesystemaccessrule('SYSTEM', 'FullControl', 'Allow')\n    $acl.SetAccessRule($administratorsRule)\n    $acl.SetAccessRule($systemRule)\n    $acl | Set-Acl\n}\n</code></pre>"},{"location":"op-manual/extending-k2s-cluster/#3-add-new-node-with-k2s-cli","title":"3. Add new node with K2s CLI","text":"Text Only<pre><code>k2s node add --ip-addr &lt;IPAddressOfNewNode&gt; --username &lt;UserNameForRemoteConnection&gt;\n</code></pre>"},{"location":"op-manual/extending-k2s-cluster/#4-check-new-node-status","title":"4. Check new node status","text":"Text Only<pre><code>k2s status -o wide\n</code></pre>"},{"location":"op-manual/external-dns/","title":"External DNS","text":""},{"location":"op-manual/external-dns/#external-dns","title":"External DNS","text":"<p>ExternalDNS synchronizes ingress endpoints with a DNS provider. In a Cloud environment, the DNS provider would be an external DNS. For K2s, we re-use the CoreDNS and configure ExternalDNS to sync all hosts it finds in the ingresses to the same DNS which is used to resolve the internal k8s svc host names.</p>"},{"location":"op-manual/external-dns/#overview","title":"Overview","text":"<p>Here is how DNS resolution work on K2s:</p> <p></p>"},{"location":"op-manual/external-dns/#coredns","title":"CoreDNS","text":"<p>CoreDNS is a DNS server part of the core kubernetes system. It monitors kubernetes services and pods, the relevant part of the default configuration is:</p> YAML<pre><code>k get cm coredns -n kube-system -o yaml\n...\n        kubernetes cluster.local in-addr.arpa ip6.arpa {\n           pods insecure\n           fallthrough in-addr.arpa ip6.arpa\n           ttl 30\n        }\n...\n</code></pre> <p>During the installation phase of K2s, we extend CodeDNS with the <code>etcd</code> CoreDNS plugin and we adjust the configuration like this:</p> YAML<pre><code>        kubernetes cluster.local in-addr.arpa ip6.arpa {\n           pods insecure\n           fallthrough\n           ttl 30\n        }\n        etcd cluster.local {\n            path /skydns\n            endpoint https://172.19.1.100:2379\n            tls /etc/kubernetes/pki/etcd-client/tls.crt /etc/kubernetes/pki/etcd-client/tls.key /etc/kubernetes/pki/etcd-ca/tls.crt\n        }\n</code></pre> <p>Observe the modified fallthrough in the kubernetes plugin, which gives a chance to the etcd plugin to serve the zone <code>cluster.local</code> as well. The etcd plugin will serve all entries it finds in the <code>etcd</code> database under the prefix <code>/skydns</code>,  in SkyDNS Format (done by ExternalDNS - see below).</p> <p>In this configuration, we use the same etcd instance used by kubernetes. For this, we import the etcd certificates as secrets and mount them to the CoreDNS deployment:</p> YAML<pre><code>k get deployment coredns -n kube-system -o yaml\n...\n        volumeMounts:\n        - mountPath: /etc/kubernetes/pki/etcd-ca\n          name: etcd-ca-cert\n        - mountPath: /etc/kubernetes/pki/etcd-client\n          name: etcd-client-cert\n...\n      volumes:\n      - name: etcd-ca-cert\n        secret:\n          secretName: etcd-ca\n      - name: etcd-client-cert\n        secret:\n          secretName: etcd-client-for-core-dns\n...\n</code></pre>"},{"location":"op-manual/external-dns/#externaldns","title":"ExternalDNS","text":"<p>Both K2s ingress implementations `nginx' and 'traefik' will install ExternalDNS, which will observe all ingresses and populate the etcd /skydns path with DNS entries  corresponding to the identified endpoints.</p> <p>The External DNS Deployment uses the same credentials as CoreDNS to access the cluster etcd database.</p> <p>See [addons/common/manifests/external-dns]</p>"},{"location":"op-manual/external-dns/#etcd","title":"etcd","text":"<p>As already mentioned, we use the kubernetes cluster etcd instance to store the DNS entries corresponding to the ingresses. The etcd certificates are generated during cluster installation and located under:</p> Text Only<pre><code>/etc/kubernetes/pki/etcd/*\n</code></pre> <p>At installation time, when we prepare the Linux VM, we also import these certificates as kubernetes secrets:</p> Text Only<pre><code>kubectl create secret -n kube-system tls etcd-ca --cert=etcd/ca.crt --key=etcd/ca.key\nkubectl create secret -n kube-system tls etcd-client-for-core-dns --cert=etcd/healthcheck-client.crt --key=etcd/healthcheck-client.key\n</code></pre>"},{"location":"op-manual/external-dns/#physical-network-adapter-dns-configuration","title":"Physical Network Adapter DNS Configuration","text":"<p>At the end of <code>k2s start</code>, we change the DNS Server of all physical network interfaces to use the <code>dnsproxy</code> DNS service running on the host. At the end of <code>k2s stop</code> we reset the DNS Configuration of these adapters.</p>"},{"location":"op-manual/external-dns/#links","title":"Links","text":"<ul> <li>ExternalDNS:   project overview</li> <li>CoreDNS etcd plugin:   extends CoreDNS to answers DNS queries using data in SkyDNS format found in etcd.</li> <li>ExternalDNS coredns plugin:   extends ExternalDNS and saves all hosts in SkyDNS format to etcd. Configuration Env. Variables:   this will help us setting up the connection to a secured etcd.</li> </ul>"},{"location":"op-manual/getting-k2s/","title":"Getting K2s","text":""},{"location":"op-manual/getting-k2s/#getting-k2s","title":"Getting K2s","text":"<p>K2s can be acquired in two different ways, depending on the intended use:</p> <ul> <li>Option 1: Cloning Git Repository for development of K2s or making use of the latest (potentially unstable) features. All dependencies get downloaded during the installation process.</li> <li>Option 2: Downloading Official Release Package for e.g. use in development environments, test systems or production scenarios.</li> </ul> <p>Note</p> <p>The target installation folder must fulfill the following requirements:</p> <ul> <li> <p>Folder name contains only:</p> <ul> <li>Letters of the English alphabet (uppercase and lowercase)</li> <li>Digits of the decimal system</li> <li>Spaces</li> <li>Special characters: <code>+</code>, <code>-</code>, <code>_</code> and <code>.</code></li> </ul> </li> <li> <p>No special folders (e.g. symbolic links) are allowed</p> </li> </ul> <p>Tip</p> <p>Due to legal/license considerations, K2s cannot provide a full offline installation package for e.g. air-gap scenarios out-of-the-box, but you can create one yourself locally, see Creating an Offline Package.</p>"},{"location":"op-manual/getting-k2s/#option-1-cloning-git-repository","title":"[Option 1] Cloning Git Repository","text":"<p>To clone the Git repository into a new folder of your choice, run: Bash Session<pre><code>mkdir c:\\myFolder; cd c:\\myFolder\ngit clone https://github.com/Siemens-Healthineers/K2s .\ngit checkout tags/v1.4.0\n</code></pre> The repo is now ready to be used. Proceed with the installation, see Installing K2s.</p>"},{"location":"op-manual/getting-k2s/#option-2-downloading-official-release-package","title":"[Option 2] Downloading Official Release Package","text":"<p>Download the latest released and officially cleared K2s version from K2s Releases. Please move the package to a folder on your drive from the windows downloads folder. </p> <p>Tip</p> <p>Please make sure to check Unblock in the file properties dialog before extracting the zip file (if this option is available): </p> <p>Extract the zip file to a target folder of your choice (e.g. <code>c:\\target-dir</code>). Remove the read-only attributes on the entire folder in an recursive way. Proceed with the installation, see Installing K2s.</p> <p>Warning</p> <p>It is recommended to install K2s to the Windows system drive (most likely <code>C:\\</code>), because some 3rd-party components might assume that <code>C:\\</code> is the Windows host's system drive, e.g. Windows-based containers running in host mode.</p>"},{"location":"op-manual/installing-k2s/","title":"Installing K2s","text":""},{"location":"op-manual/installing-k2s/#installing-k2s","title":"Installing K2s","text":""},{"location":"op-manual/installing-k2s/#prerequisites","title":"Prerequisites","text":"<ul> <li>K2s folder being available locally, see Getting K2s</li> <li>The Windows host must match one of the Supported OS Versions</li> <li>Local admin permissions are currently needed in order to be able to create virtual switches, VMs, etc.</li> <li>Please try to install from an folder which is available on <code>C:\\</code> drive, since most open-source components assume this. We are testing the solution also on other drives, but cannot guarantee that the cluster will work fully.</li> <li>Hardware: The system should offer at least 2GB RAM free, as well as 10GB disk space free. Recommended are at least 6 CPU cores, but less are possible.</li> <li>CPU virtualization must be enabled in the BIOS. To verify, open the Task Manager and check the Virtualization property on the Performance tab: If you run the setup inside a VM, enable nested virtualization (e.g. when using Hyper-V: PowerShell<pre><code>Set-VMProcessor -VMName $Name -ExposeVirtualizationExtensions $true\n</code></pre>  , see Configure Nested Virtualization for details).</li> <li>Docker (Desktop) must not be running. Either stop Docker and set it to start manually or uninstall it completely</li> <li>PowerShell execution policy must be RemoteSigned or less restrictive. To set the policy, run:   PowerShell<pre><code>Set-ExecutionPolicy RemoteSigned -Force\n</code></pre></li> <li>curl.exe: the installed version in the Windows host must be at least 7.71.0 (to check it call <code>curl.exe --version</code> from the command shell).</li> <li>Optional: ssh.exe: the installed version in the Windows host must be at least major version 8 to prevent the installation from hanging in certain situations (to check it call <code>ssh.exe -V</code> from the command shell). Normally, only Windows Server 2019 does not fulfill this requirement from the supported operating systems.</li> <li>Optional: Enable required Windows Features beforehand (they will get enabled during the installation anyways, but would require a system restart and installation re-run):</li> <li>Windows 10/11 PowerShell<pre><code>Enable-WindowsOptionalFeature -Online -FeatureName $('Microsoft-Hyper-V-All', 'Microsoft-Hyper-V', 'Microsoft-Hyper-V-Tools-All', 'Microsoft-Hyper-V-Management-PowerShell', 'Microsoft-Hyper-V-Hypervisor', 'Microsoft-Hyper-V-Services', 'Microsoft-Hyper-V-Management-Clients', 'Containers', 'VirtualMachinePlatform') -All -NoRestart\n</code></pre></li> <li>Windows Server OSs     PowerShell<pre><code>Enable-WindowsOptionalFeature -Online -FeatureName $('Microsoft-Hyper-V', 'Microsoft-Hyper-V-Management-PowerShell', 'Containers', 'VirtualMachinePlatform') -All -NoRestart\n</code></pre></li> <li> <p>Hyper-V configuration: after the enabling of Hyper-V on your host using Set-VMHost different settings can be configured for Hyper-V, for example in some cases it makes sense to have new default locations for virtual hard disks on that host. Please checkout all possibilities and configure Hyper-V on your host as wanted before doing an install of k2s !</p> </li> <li> <p>Installing in WSL mode: Enable the WSL 2 feature on Windows. For detailed instructions, see Configure WSL or Manual install (older WSL versions) PowerShell<pre><code>Enable-WindowsOptionalFeature -Online -FeatureName $('Microsoft-Windows-Subsystem-Linux', 'VirtualMachinePlatform') -All\n</code></pre></p> </li> <li> <p>VC Runtime 140: please install the VC runtime dlls, either with choco</p> </li> </ul> <p><code>choco install vcredist140 -y</code></p> <p>or download them from Microsoft directly and install the appropriate VC runtime.</p> <p>Tip</p> <p>Environment variables HTTP_PROXY and HTTPS_PROXY shall not be used in Windows when creating a cluster. Usage of an HTTP proxy shall be configured in <code>control panel</code> at the <code>network and internet</code> section. K2s will always take the proxy automatically from the Windows proxy configuration and will use that setting (in this case also local networks can be addressed).</p>"},{"location":"op-manual/installing-k2s/#installation-via-k2s-cli","title":"Installation via k2s CLI","text":"<p>The K2s setup provides a variety of installation options. Based on the Hosting Variants, select one of the following setup variants:</p> <ul> <li>Option 1: Host (Default, Windows host acts as a worker node).</li> <li>Option 2: Development-Only (no K8s cluster, for building and testing containers only)</li> </ul> <p>To inspect the different install options, run: Bash Session<pre><code>&lt;repo&gt;\\k2s.exe install -h\n</code></pre></p> <p>Warning</p> <p>If the installer detects more than one <code>k2s.exe</code> in your system <code>PATH</code>, installation will fail. Please review the error message for all detected <code>k2s.exe</code> locations and remove any outdated or duplicate directories from your <code>PATH</code> environment variable before retrying installation.</p> <p>Info</p> <p>By default, the installation assumes 6 CPU cores to be available on the host system. If less cores are available, reduce the number of virtual cores used by K2s according to the actual amount, e.g. when 4 cores are available, assign max. 4 virtual cores to K2s: Bash Session<pre><code>&lt;repo&gt;\\k2s.exe install --master-cpus 4\n</code></pre></p> <p>Tip</p> <p>If you acquired K2s via Cloning the Git repository, you might want to checkout a specific version first, e.g.: Bash Session<pre><code>git checkout tags/v1.4.0\n</code></pre></p> <p>Note</p> <p>K2s will start automatically after the installation has finished.</p>"},{"location":"op-manual/installing-k2s/#installing-using-config-files","title":"Installing Using Config Files","text":"<p>Instead of assembling many command-line parameters/flags to customize the installation, you can also pass a YAML file to the <code>k2s install</code> command configuring install parameters like node resource definitions (e.g. CPU, RAM or size of the hard drive): Bash Session<pre><code>&lt;repo&gt;\\k2s.exe install [-c|--config] &lt;path-to-config-file&gt;\n</code></pre></p> <p>Example</p> <p>Create a custom install config: my_config.yaml<pre><code>kind: k2s\napiVersion: v1\nnodes:\n  - role: control-plane\n    resources:\n      cpu: 8\n      memory: 7GB\n      disk: 60GB\nenv:\n  httpProxy: 192.168.178.100:8765\ninstallBehavior:\n  showOutput: true\n</code></pre> Start the installation passing this config: Bash Session<pre><code>&lt;repo&gt;\\k2s.exe install -c c:\\temp\\my_config.yaml\n</code></pre></p> <p>To create a user-defined configuration for any of the hosting variants, take one of the corresponding Base Configuration Files as a template.</p>"},{"location":"op-manual/installing-k2s/#online-vs-offline","title":"Online vs. Offline","text":"<p>Downloading all dependencies (i.e. binaries) on-the-fly is referred to as online installation, whereas offline refers to an installation package containing parts of or all the dependencies. If K2s was acquired via Downloading the Official Release Package, parts of the dependencies are already available locally. If an offline package was create according to Creating Offline Package, all dependencies are available offline.</p> <p>As per default, the k2s CLI keeps downloaded files as well as the Linux-based control-plane image and reuses them. To change this behavior, use the following CLI flags (they apply to all installation variants<sup>1</sup>).</p> <p>To delete all downloaded binaries and the control-plane image after installation, run: Bash Session<pre><code>&lt;repo&gt;\\k2s.exe install -d\n</code></pre></p> <p>To force the download of all binaries and the re-creation of the control-plane image regardless of their local presence, run: Bash Session<pre><code>&lt;repo&gt;\\k2s.exe install -f\n</code></pre></p> Offline vs. Online Installation Diagram <pre><code>graph TD\n    CallScript[\"Installation scripts\\n (Default, BuildOnlySetup)\\n\\n with\\n [-DeleteFilesForOfflineInstallation]\\n [-ForceOnlineInstallation]\"] --&gt; if_force_online_installation{\"Switch\\n ForceOnlineInstallation\\n used ?\"}\n    if_force_online_installation --&gt; |yes| BuildAndProvisionKubemasterBaseImage\n    if_force_online_installation --&gt; |no| if_base_image_available{\"c\\k\\bin\\Kubemaster-Base.vhdx\\n available?\"}\n    if_base_image_available --&gt; |yes| CopyBaseImage\n    if_base_image_available --&gt; |no| BuildAndProvisionKubemasterBaseImage\n    BuildAndProvisionKubemasterBaseImage(\"Build and provision base image\") --&gt; PublishBaseImage(\"Publish base image as\\n c\\k\\bin\\Kubemaster-Base.vhdx\")\n    PublishBaseImage --&gt; CopyBaseImage(\"Copy published base image to\\n C\\Users\\Public\\Documents\\Hyper-V\\Virtual hard disks\")\n    CopyBaseImage --&gt; InstallLinuxNode(\"Install Linux node\")\n    InstallLinuxNode --&gt; if_delete_files_for_offline_installation{\"Switch\\n -DeleteFilesForOfflineInstallation\\n used ?\"}\n    if_delete_files_for_offline_installation --&gt; |yes| DeleteBaseImage(\"Delete file c\\k\\bin\\Kubemaster-Base.vhdx\")\n    if_delete_files_for_offline_installation --&gt; |no| End\n    DeleteBaseImage --&gt; End</code></pre>"},{"location":"op-manual/installing-k2s/#option-1-host-default","title":"[Option 1] Host (Default)","text":"<p>Simply run: Bash Session<pre><code>&lt;repo&gt;\\k2s.exe install\n</code></pre></p>"},{"location":"op-manual/installing-k2s/#wsl","title":"WSL","text":"<p>To install the control-plane in WSL 2 instead of a dedicated Linux VM, run: Bash Session<pre><code>&lt;repo&gt;\\k2s.exe install --wsl\n</code></pre></p>"},{"location":"op-manual/installing-k2s/#option-2-development-only","title":"[Option 2] Development-Only","text":"<p>To build and test containers without a K8s cluster, run: Bash Session<pre><code>&lt;repo&gt;\\k2s.exe install buildonly\n</code></pre></p> <ol> <li> <p>Creating of and installing from an offline package is currently supported for Host Variant and Development-Only only.\u00a0\u21a9</p> </li> </ol>"},{"location":"op-manual/networking-architecture/","title":"Networking Architecture","text":""},{"location":"op-manual/networking-architecture/#networking-architecture-for-k2s","title":"Networking Architecture for K2s","text":""},{"location":"op-manual/networking-architecture/#core-principles-and-architecture-simplicity-and-maximum-performance","title":"Core Principles and Architecture: simplicity and maximum performance","text":"<p>In alignment with K2s' foundational design principles of operational simplicity and maximum performance, our networking architecture is built upon Flannel CNI configured in host-gateway mode. This provides a transparent, high-throughput, and low-latency data plane that is ideal for demanding workloads and facilitates straightforward network analysis. For production-grade security, K2s integrates the security addon which uses Linkerd to establish a zero-trust environment for all TCP-based traffic through transparent mTLS and fine-grained policy enforcement.</p>"},{"location":"op-manual/networking-architecture/#the-broader-strategic-value-of-simplicity-and-performance","title":"The Broader Strategic Value of Simplicity and Performance","text":"<p>The commitment to a simple and performant networking foundation provides strategic advantages that extend far beyond enabling zero-trust features. This architecture directly translates into tangible value for both operators and developers running workloads on K2s.</p> <p>Accelerated Diagnostics and Troubleshooting: The transparent host-gateway data plane avoids complex encapsulation (like VXLAN or IP-in-IP). Network traffic remains directly observable on the host, allowing operators to use standard, universal tools like tcpdump and Wireshark for rapid, intuitive debugging. This dramatically reduces the mean time to resolution (MTTR) for network-related issues compared to debugging opaque overlay networks.</p> <p>Maximized Resource Efficiency and Throughput: By minimizing the CPU and memory overhead of the networking stack, more resources are available for the applications themselves. This near-bare-metal network performance is critical for the high-throughput and low-latency requirements of data-intensive workloads, such as medical imaging, AI/ML data pipelines, and transactional databases.</p> <p>Reduced Operational Overhead and Increased Reliability: A simpler architecture with fewer moving parts inherently reduces the system's attack surface and the potential for component failure or misconfiguration. This lean operational model lowers the cognitive load on platform teams, making the cluster easier to manage, secure, and upgrade, thereby increasing overall system reliability.</p> <p>Enhanced Developer and Operator Experience: The intuitive networking model empowers development teams to deploy and manage their applications without needing to become experts in complex network virtualization. This clarity fosters a stronger sense of ownership and accelerates the development lifecycle, as teams can reason about network communication in a straightforward manner.</p>   ![Overview](assets/networksimplicity.png)"},{"location":"op-manual/networking-architecture/#alternative-solutions-considered-network-policy-controllers-same-applies-for-more-complex-cnis-like-calico","title":"Alternative Solutions Considered: Network Policy Controllers (same applies for more complex CNIs like Calico)","text":"<p>During our evaluation, we analyzed solutions designed to enable native Kubernetes NetworkPolicy support on platforms where the CNI does not enforce it. A notable example is the windows-network-policy-controller from the Kubernetes SIGs community, which translates NetworkPolicy objects into rules for the Windows Filtering Platform.</p> <p>Potential Advantage: The primary benefit of such a controller is the ability to use the standard Kubernetes NetworkPolicy API. This provides a familiar, powerful abstraction for defining granular, label-based traffic rules between pods, which is highly desirable from a user-experience perspective.</p> <p>Reasons for Rejection: Despite this advantage, we concluded that this approach was not aligned with the core K2s tenets for the following reasons:</p> <p>Increased Complexity: It introduces another active controller into the cluster's critical path. This component must be installed, managed, and monitored, adding operational overhead. Its logic for translating policies into host rules creates a layer of abstraction that can be difficult to debug when unexpected network behavior occurs.</p> <p>Performance and Scalability Concerns: A network policy controller must continuously watch the Kubernetes API for changes to pods (e.g., label changes, scaling events) and policies. In dynamic clusters, this can trigger frequent and numerous updates to the host's firewall ruleset, potentially leading to performance degradation, rule conflicts, or transient connectivity issues. This dynamic management layer adds computational overhead compared to the static, highly-performant rules applied by our chosen DaemonSet approach. In addition, these solutions introduce packet-processing overhead and extra CPU cost from kernel/user space transitions\u2014latency increases of 100 microseconds up to 2 ms per packet, throughput reductions of 20%\u201380%, and additional CPU overhead of +20%\u2013200%. Packet drops may also occur under high load.</p> <p>Deviation from Simplicity: The goal of K2s is to provide a transparent and easily understandable system. A dynamic controller that generates a complex and ever-changing set of host firewall rules moves away from this principle, making it harder for operators to reason about the state of the network at any given moment. </p> <p>OS support Many of the analyzed solutions were not working under Windows, they provided only for Linux nodes a viable solution.</p>"},{"location":"op-manual/networking-architecture/#governing-non-tcp-traffic","title":"Governing Non-TCP Traffic","text":"<p>A critical consideration in this chosen architecture is the governance of non-TCP protocols, primarily UDP. As Linkerd's service mesh capabilities are focused on L4/L7 TCP traffic, UDP communication operates outside its security perimeter. This necessitates a robust and performant solution to control UDP traffic flows without compromising our core design goals of simplicity and speed. While alternative CNIs like Calico offer integrated policy enforcement, they introduce significant operational complexity and potential performance overhead, which runs counter to the K2s philosophy.</p>"},{"location":"op-manual/networking-architecture/#hostprocess-legacy-windows-application-isolation","title":"HostProcess &amp; Legacy Windows Application Isolation","text":"<p>For scenarios where existing native Windows applications must be integrated into the cluster with compartmentalized networking and optional service mesh capabilities, K2s supports a HostProcess + network compartment pattern. This allows unmodified executables to run with per-instance (or shared) compartment isolation while still benefiting from Linkerd (for TCP) and host-level policy controls (for UDP / non-meshed flows).</p> <p>See: Running Native Windows Applications with HostProcess + Network Compartments</p> <p>Key advantages of this pattern within the broader networking model: * Preserves the simplicity of the Flannel host-gateway data plane. * Avoids introducing opaque overlays when isolating legacy processes. * Leverages Linkerd for encrypted / observable TCP while keeping direct compartment routing transparent. * Enables per-workload or per-tenant segmentation without complex CNI changes.</p> <p>This complements the host-level firewall DaemonSets by layering process-level isolation (compartment) with node-level enforcement.</p>"},{"location":"op-manual/networking-architecture/#the-selected-strategy-host-level-firewall-enforcement-via-a-kubernetes-daemonset","title":"The Selected Strategy: Host-Level Firewall Enforcement via a Kubernetes DaemonSet","text":"<p>To address this gap, we have adopted a strategy of leveraging the native, kernel-level firewalls of the host operating systems (Linux iptables and the Windows Filtering Platform). The application and lifecycle of these firewall rules are managed declaratively from within the cluster using a privileged Kubernetes DaemonSet.</p>"},{"location":"op-manual/networking-architecture/#rationale-and-strategic-benefits-for-k2s","title":"Rationale and Strategic Benefits for K2s","text":"<p>This decision reinforces our commitment to performance and simplicity through the following key advantages:</p> <p>Upholding Peak Performance: By delegating UDP filtering to the highly-optimized packet processing engines within the host kernel, we ensure that security policies are enforced with negligible latency or throughput degradation. This preserves the performance integrity of the K2s data plane, which is paramount for data-intensive applications.</p> <p>Maintaining Architectural Simplicity: This approach avoids introducing a complex secondary networking stack. We retain the lean, understandable Flannel CNI and sidestep the steep learning curve and operational burden associated with more intricate CNI solutions. The control plane remains minimalist and easy to manage.</p> <p>Declarative and Scalable Management: While the enforcement mechanism is at the host level, its management is fully integrated into the Kubernetes control plane. The DaemonSet ensures that every node\u2014present and future\u2014automatically and consistently receives the correct security posture. This prevents configuration drift and provides a scalable, \"GitOps-friendly\" method for managing node security.</p> <p>Robust and Mature Technology: We are building upon the most stable, battle-tested components of the operating systems themselves. iptables and the Windows Firewall are mature, reliable, and well-understood technologies, minimizing the risk of introducing new bugs or unpredictable behaviors into the networking stack.</p>"},{"location":"op-manual/networking-architecture/#implementation-example-node-firewall-daemonset","title":"Implementation Example: Node Firewall DaemonSet","text":"<p>The following DaemonSet manifest provides a reference implementation for applying firewall rules on all Linux nodes. A corresponding DaemonSet using a Windows container image and PowerShell commands would be deployed for Windows nodes.</p> Text Only<pre><code>apiVersion: apps/v1\nkind: DaemonSet\nmetadata:\n  name: k2s-node-firewall-configurator\n  namespace: kube-system\n  labels:\n    app.kubernetes.io/name: k2s-node-firewall\nspec:\n  selector:\n    matchLabels:\n      app.kubernetes.io/name: k2s-node-firewall\n  template:\n    metadata:\n      labels:\n        app.kubernetes.io/name: k2s-node-firewall\n    spec:\n      # Target Linux nodes specifically\n      nodeSelector:\n        kubernetes.io/os: linux\n      # Allow this pod to run on any node, including control-plane\n      tolerations:\n      - operator: Exists\n      # Use the host's namespaces to modify its settings\n      hostNetwork: true\n      hostPID: true\n      containers:\n      - name: iptables-configurator\n        image: docker.io/library/alpine:latest # A minimal, secure base image\n        # This pod requires elevated privileges to modify host iptables\n        securityContext:\n          privileged: true\n        command: [\"/bin/sh\", \"-c\"]\n        args:\n        - |\n          # Ensure iptables is available\n          apk add --no-cache iptables\n\n          # IPTABLES RULESET FOR UDP RESTRICTION\n\n          # 1. Allow established and related traffic to pass. This is crucial for return packets.\n          iptables -A INPUT -m state --state ESTABLISHED,RELATED -j ACCEPT || true\n          iptables -A OUTPUT -m state --state ESTABLISHED,RELATED -j ACCEPT || true\n\n          # 2. Specifically allow outbound DNS requests (UDP to port 53)\n          iptables -A OUTPUT -p udp --dport 53 -j ACCEPT || true\n\n          # 3. Specifically allow inbound DNS responses (UDP from port 53)\n          iptables -A INPUT -p udp --sport 53 -j ACCEPT || true\n\n          # 4. Drop all other UDP traffic attempting to be forwarded between network interfaces (e.g., pod-to-pod across nodes)\n          iptables -A FORWARD -p udp -j DROP || true\n\n          # 5. Drop all other inbound and outbound UDP traffic from the node itself\n          iptables -A INPUT -p udp -j DROP || true\n          iptables -A OUTPUT -p udp -j DROP || true\n\n          echo \"K2s UDP firewall rules applied successfully.\"\n\n          # Keep the container alive indefinitely\n          sleep infinity\n</code></pre>"},{"location":"op-manual/networking-architecture/#implementation-example-node-firewall-daemonset-for-windows","title":"Implementation Example: Node Firewall DaemonSet for Windows","text":"Text Only<pre><code># Filename: windows-node-firewall-daemonset.yaml\napiVersion: apps/v1\nkind: DaemonSet\nmetadata:\n  name: k2s-windows-node-firewall\n  namespace: kube-system\n  labels:\n    app.kubernetes.io/name: k2s-node-firewall\nspec:\n  selector:\n    matchLabels:\n      app.kubernetes.io/name: k2s-windows-node-firewall\n  template:\n    metadata:\n      labels:\n        app.kubernetes.io/name: k2s-windows-node-firewall\n    spec:\n      nodeSelector:\n        kubernetes.io/os: windows\n      tolerations:\n      - operator: Exists\n      securityContext:\n        windowsOptions:\n          hostProcess: true\n          runAsUserName: \"System\"\n      hostNetwork: true\n      containers:\n      - name: powershell-configurator\n        image: mcr.microsoft.com/powershell:lts-nanoserver-1809\n        command:\n        - \"powershell.exe\"\n        - \"-Command\"\n        args:\n        - |\n          # Define a unique group name for our rules\n          $group = 'K2s-UDP-Policy'\n\n          # Remove any pre-existing rules in this group to ensure a clean state\n          Get-NetFirewallRule -Group $group | Remove-NetFirewallRule\n\n          # Rule 1: Block all inbound UDP traffic by default.\n          New-NetFirewallRule -DisplayName 'Block All UDP Inbound' -Group $group -Direction Inbound -Action Block -Protocol UDP -Profile Any\n\n          # Rule 2: Explicitly allow inbound DNS responses (overrides the block rule).\n          New-NetFirewallRule -DisplayName 'Allow DNS Inbound (UDP)' -Group $group -Direction Inbound -Action Allow -Protocol UDP -LocalPort 53 -Profile Any\n\n          # Rule 3: Block all outbound UDP traffic by default.\n          New-NetFirewallRule -DisplayName 'Block All UDP Outbound' -Group $group -Direction Outbound -Action Block -Protocol UDP -Profile Any\n\n          # Rule 4: Explicitly allow outbound DNS requests.\n          New-NetFirewallRule -DisplayName 'Allow DNS Outbound (UDP)' -Group $group -Direction Outbound -Action Allow -Protocol UDP -RemotePort 53 -Profile Any\n\n          Write-Host \"K2s Windows UDP firewall rules applied.\"\n\n          # Keep the container alive\n          Start-Sleep -Seconds 2147483647\n</code></pre> <p>Conclusion</p> <p>By implementing UDP security policies via a host-firewall DaemonSet, K2s strikes an optimal balance. We secure the cluster by closing the UDP gap while staying true to our core tenets: delivering a Kubernetes distribution that is exceptionally fast, operationally simple, and ready for the most demanding production workloads.</p>"},{"location":"op-manual/os-support/","title":"Supported OS Versions","text":""},{"location":"op-manual/os-support/#supported-os-versions","title":"Supported OS Versions","text":"Windows Version Build Windows 10, Server 2019 1809 <code>10.0.17763.xxxx</code> Windows 10 20H2 <code>10.0.19042.xxxx</code> Windows 10 21H2 <code>10.0.19044.xxxx</code> Windows 10 22H2 <code>10.0.19045.xxxx</code> Windows Server 2022 21H2 <code>10.0.20348.xxxx</code> Windows 11 21H2 <code>10.0.22000.xxxx</code> Windows 11 22H2 <code>10.0.22621.xxxx</code> Windows 11 23H2 <code>10.0.22631.xxxx</code> Windows 11, Server 2025 24H2 <code>10.0.26100.xxxx</code> Windows 11 25H2 <code>10.0.26200.xxxx</code>"},{"location":"op-manual/running-apps-as-hostprocess/","title":"Running Native Windows Apps (HostProcess & Compartments)","text":""},{"location":"op-manual/running-apps-as-hostprocess/#running-native-windows-applications-with-hostprocess-network-compartments","title":"Running Native Windows Applications with HostProcess + Network Compartments","text":""},{"location":"op-manual/running-apps-as-hostprocess/#overview","title":"Overview","text":"<p>Running existing (often legacy or closed\u2011source) native Windows applications in Kubernetes can be challenging when you need modern platform capabilities (service mesh, observability, scaling) but the binaries were never built for container awareness or multi\u2011instance coexistence. On Windows, network compartments provide a logical isolation boundary for network configuration (interfaces, routes, policies, DNS) similar in spirit to a network namespace on Linux, but they are not automatically created for HostProcess containers (which execute directly in the host context). Bringing these native Windows applications into Kubernetes as HostProcess containers and isolating them to run in a specific pod network compartment lets you reuse these platform capabilities (service mesh, observability, scaling) with minimal or no code change.</p>   ![Overview](assets/compartments.png)  <p>This pattern enables you to:</p> <ul> <li>Place an unmodified native Windows process into an isolated network compartment</li> <li>Assign the process a stable per-instance IP (via the anchor pod's compartment networking)</li> <li>Inject mesh sidecars / data-plane capabilities at the compartment boundary (via the anchor)</li> <li>Scale to multiple parallel instances\u2014each with its own compartment/IP\u2014without port conflicts</li> <li>Gradually migrate or encapsulate legacy services without rewriting them for container semantics</li> </ul> <p>We achieve this by combining:</p> <ol> <li>An ordinary Windows (non-HostProcess) \"anchor\" pod that the kubelet / CNI associates with a compartment.</li> <li>A HostProcess container that runs a privileged launcher which switches into the anchor's compartment before starting the legacy (or new) executable.</li> </ol> <p>This guide shows how to run an existing (possibly legacy / closed\u2011source) Windows application inside Kubernetes while giving it its own isolated network context (a Windows network compartment) and a stable IP address, without modifying the binary. The isolation is achieved by pairing:</p> <ol> <li>An anchor pod (ordinary Windows container) which the Windows CNI stack places into a compartment and wires with an interface + IP.</li> <li>A HostProcess container that launches the real application after switching its thread into the anchor's compartment using the helper launcher <code>cplauncher</code>.</li> </ol> <p>This pattern preserves compatibility (run any EXE), improves multi\u2011instance scalability (no port collisions), and enables advanced platform add\u2011ons (service mesh, traffic capture, zero\u2011downtime rotation) around software that cannot be easily containerized in the traditional sense.</p>"},{"location":"op-manual/running-apps-as-hostprocess/#why-this-pattern","title":"Why This Pattern?","text":"<p>Windows HostProcess containers execute directly on the host and can start arbitrary processes with elevated permissions. However, binding those processes to a different compartment than the default host compartment requires explicit movement to a new compartment before listening sockets are opened. The pattern here externalizes the compartment selection logic to a launcher tool that:</p> <ul> <li>Discovers the target compartment by locating a labeled anchor pod.</li> <li>Extracts and validates required network context (e.g. IP addresses, annotations, labels).</li> <li>Sets the thread's network compartment.</li> <li>Starts the desired executable while streaming logs.</li> <li>Exits with a meaningful status for observability.</li> </ul> <p>Tool is available under the K2s installation: Text Only<pre><code>K2S-INSTALLATION-FOLDER\\bin\\cni\\cplauncher.exe\n</code></pre></p>"},{"location":"op-manual/running-apps-as-hostprocess/#benefits","title":"Benefits","text":"Theme Value Detail Service Mesh Sidecar / proxy enablement Anchor pod can host or trigger mesh injection; your legacy EXE traffic is transparently managed. Per\u2011Instance IP No port conflicts Each replica gets its own compartment + IP; multiple instances can all listen on the same port (e.g. 8080). Gradual Modernization No code changes needed Keep shipping the old binary while layering on Kubernetes services, probes, policies. Traffic Governance Fine\u2011grained routing/shaping Compartment boundaries + HNS policies restrict blast radius of misconfiguration. Security &amp; Isolation Network surface reduction Only the intended interface/routes are visible to the process after compartment switch. Scaling &amp; Rollouts Safer blue/green Stand up a new anchor+HostProcess pair, cut over Service selector, retire old pair. Observability Consistent log path Launcher streams child stdout/stderr; you can attach log collectors at host or compartment scope. Multi\u2011Tenancy Logical segmentation Multiple teams share a node but remain partitioned at network compartment level. Compliance &amp; Audit Deterministic bootstrap log Launcher emits parameters (anchor label, namespace, target exe); auditable trail. Troubleshooting Predictable mapping Label -&gt; anchor -&gt; compartment -&gt; process chain simplifies root cause analysis. <p>NOTE: While HostProcess containers run with elevated host privileges, the network compartment switch confines network presence of the launched process to the intended virtual environment derived from the anchor.</p>"},{"location":"op-manual/running-apps-as-hostprocess/#high-level-flow","title":"High-Level Flow","text":"<ol> <li>Deploy (or already have) a namespace.</li> <li>Create anchor pod with distinct label (e.g. <code>app=my-anchor-1</code>).</li> <li>Deploy HostProcess object referencing that label via <code>cplauncher -label app=my-anchor-1 -namespace &lt;ns&gt; -- &lt;your.exe&gt; &lt;args&gt;</code>.</li> <li><code>cplauncher</code> resolves anchor pod -&gt; extracts compartment -&gt; switches thread -&gt; launches application.</li> <li>(Optional) Expose via a Service with selector <code>app=my-legacy-app</code>.</li> <li>Scale by repeating (anchor, HostProcess pair) or using a Deployment (1:1 pods) where each new replica references a unique anchor label (pattern generation or pre-created anchors).</li> <li>(Optional) Reuse a single anchor for multiple HostProcess instances (shared compartment/IP) if safe\u2014but prefer 1:1 mapping for isolation and distinct IPs.</li> </ol>"},{"location":"op-manual/running-apps-as-hostprocess/#full-generic-example","title":"Full Generic Example","text":"<p>Below is a generalized manifest (anchor + HostProcess) based on <code>cplauncher.example.yaml</code>. Adjust label values, paths, and image versions to fit your environment.</p> YAML<pre><code>---\napiVersion: v1\nkind: Pod\nmetadata:\n  name: myapp-compartment-anchor\n  namespace: apps\n  labels:\n    app: myapp-anchor-1    # label used by cplauncher discovery\n  annotations:\n    linkerd.io/inject: enabled   # enables Linkerd proxy injection if mesh is installed and auto-inject is permitted\nspec:\n  nodeSelector:\n    kubernetes.io/os: windows\n  containers:\n    - name: pause\n      image: shsk2s.azurecr.io/pause-win:v1.5.0\n      imagePullPolicy: IfNotPresent\n  restartPolicy: Always\n---\napiVersion: apps/v1\nkind: Deployment\nmetadata:\n  name: myapp-hostprocess\n  namespace: apps\n  labels:\n    app: myapp\nspec:\n  replicas: 1\n  selector:\n    matchLabels:\n      app: myapp\n  template:\n    metadata:\n      labels:\n        app: myapp\n    spec:\n      nodeSelector:\n        kubernetes.io/os: windows\n      securityContext:\n        windowsOptions:\n          hostProcess: true\n          runAsUserName: \"NT AUTHORITY\\\\SYSTEM\"\n      hostNetwork: true\n      containers:\n        - name: cplauncher\n          image: mcr.microsoft.com/oss/kubernetes/windows-host-process-containers-base-image:v1.0.0\n          imagePullPolicy: IfNotPresent\n          command:\n            - \"cmd.exe\"\n            - \"/c\"\n            - \"K2S-INSTALLATION-FOLDER\\\\bin\\\\cni\\\\cplauncher.exe\"  # replace placeholder with actual path or env var\n            - \"-label\"; \"app=myapp-anchor-1\"\n            - \"-namespace\"; \"apps\"\n            - \"--\"\n            - \"C:\\\\apps\\\\legacy\\\\myapp.exe\"; \"--config\"; \"C:\\\\apps\\\\config\\\\prod.json\"\n          volumeMounts:\n            - name: host-apps\n              mountPath: C:/apps\n      volumes:\n        - name: host-apps\n          hostPath:\n            path: C:/apps\n            type: Directory\n</code></pre>"},{"location":"op-manual/running-apps-as-hostprocess/#parameter-breakdown","title":"Parameter Breakdown","text":"Flag / Element Purpose Notes <code>-label app=myapp-anchor-1</code> Selects anchor pod Must uniquely identify one running anchor. <code>-namespace apps</code> Scopes pod lookup Avoid cross-namespace ambiguity. <code>--</code> Separator Everything after is the target process + its args. <code>myapp.exe --config ...</code> Target workload Unmodified native binary. Host mount <code>C:/apps</code> Binary + config injection Could be replaced with projected CSI / SMB if desired."},{"location":"op-manual/running-apps-as-hostprocess/#adding-a-service","title":"Adding a Service","text":"YAML<pre><code>apiVersion: v1\nkind: Service\nmetadata:\n  name: myapp\n  namespace: apps\nspec:\n  selector:\n    app: myapp   # target the HostProcess deployment label\n  type: ClusterIP\n  ports:\n    - port: 80\n      targetPort: 8080   # assuming binary listens on 8080\n      protocol: TCP\n  clusterIP: 172.21.1.222\n</code></pre>"},{"location":"op-manual/running-apps-as-hostprocess/#scaling-strategies","title":"Scaling Strategies","text":"Approach Description Trade\u2011Off One anchor per replica (static) Pre-create anchors (myapp-anchor-1..N) and pass different label per HostProcess pod Higher YAML management overhead Controller-generated labels Custom controller creates anchor + HP pair Requires controller development StatefulSet with deterministic labels Use ordinal to form anchor label (e.g. <code>myapp-anchor-$(ordinal)</code>) Needs deterministic anchor provisioning logic"},{"location":"op-manual/running-apps-as-hostprocess/#mesh-sidecar-considerations","title":"Mesh / Sidecar Considerations","text":"<p>If your service mesh supports Windows injection, target only the anchor pod for injection so traffic is compartment\u2011scoped before proxy handling. Ensure <code>cplauncher</code> waits until the anchor is Ready (consider a readiness annotation gate).</p>"},{"location":"op-manual/running-apps-as-hostprocess/#using-linkerd-with-hostprocess-compartments","title":"Using Linkerd with HostProcess Compartments","text":"<p>Linkerd can provide mutual TLS, latency metrics, policy enforcement, and traffic shaping for legacy Windows workloads launched via HostProcess + compartment binding.</p>"},{"location":"op-manual/running-apps-as-hostprocess/#injection-path","title":"Injection Path","text":"<ol> <li>Install Linkerd with Windows support features enabled (control plane on Linux nodes; data plane proxy supports Windows anchors).</li> <li>Annotate the anchor pod (or label the namespace) with <code>linkerd.io/inject: enabled</code>.</li> <li>The proxy sidecar is injected into the anchor pod only (HostProcess pods cannot host conventional sidecars).</li> <li><code>cplauncher</code> switches the HostProcess-launched application into the same compartment; traffic now traverses the proxy transparently.</li> </ol>"},{"location":"op-manual/running-apps-as-hostprocess/#traffic-identity","title":"Traffic &amp; Identity","text":"Aspect Detail mTLS Identity Derived from the anchor pod's ServiceAccount; all processes sharing the compartment inherit that trust domain. Multiple Processes If multiple HostProcess workloads share one anchor, they also share identity\u2014use separate anchors for isolation. Policy Objects Use <code>Server</code> / <code>ServerAuthorization</code> (or <code>Policy</code> in newer Linkerd) referencing labels on the HostProcess Service. Outbound Control Leverage <code>linkerd viz edges</code> to confirm encrypted edges; restrict egress with NetworkPolicy + Linkerd policy."},{"location":"op-manual/running-apps-as-hostprocess/#observability","title":"Observability","text":"Tool Usage <code>linkerd viz stat</code> Verify success/latency for the Service selecting HostProcess pods. <code>linkerd viz tap</code> Inspect live requests; confirm compartment-switched process traffic is visible. <code>linkerd viz edges</code> Confirm mTLS (identity established) between consumers and the workload."},{"location":"op-manual/running-apps-as-hostprocess/#recommended-sequence","title":"Recommended Sequence","text":"Text Only<pre><code>1. k2s addons enable security --type enhanced --omitHydra --omitKeycloak --omitOAuth2Proxy \n4. Deploy anchor (pause image) + wait for Ready\n5. Deploy HostProcess deployment with cplauncher referencing anchor label\n6. kubectl port-forward or curl via a meshed client to validate traffic\n7. linkerd viz stat deploy -n apps\n8. linkerd viz tap deploy/myapp -n apps (optional)\n</code></pre>"},{"location":"op-manual/running-apps-as-hostprocess/#best-practices","title":"Best Practices","text":"Practice Reason One anchor per identity-sensitive workload Limits blast radius and clarifies metrics ownership. Health gating in launcher Prevents proxy receiving traffic before process is ready. Structured launcher logs Facilitates correlation with Linkerd tap output. Explicit port documentation Helps avoid conflicts and clarifies expected interception."},{"location":"op-manual/running-apps-as-hostprocess/#security-notes","title":"Security Notes","text":"<p>Because HostProcess runs with elevated rights, restrict file system exposure (mount only what you need) and sign the launcher &amp; target binaries. Use per\u2011namespace RBAC limiting list/get permissions strictly to Pods.</p>"},{"location":"op-manual/running-apps-as-hostprocess/#references","title":"References","text":"<ul> <li>Kubernetes Windows HostProcess Containers: https://kubernetes.io/docs/concepts/windows/intro/#hostprocess-containers</li> <li>Windows Network Compartments (Microsoft Docs): https://learn.microsoft.com/windows/win32/api/netioapi/nf-netioapi-setcurrentthreadcompartmentid</li> </ul>"},{"location":"op-manual/secure-host-access/","title":"Secure Host Access","text":""},{"location":"op-manual/secure-host-access/#secure-host-access","title":"Secure Host Access","text":"<p>K2s provides three addons which can be used to expose the functionality implemented inside the Kubernetes cluster outside of it: <code>ingress nginx</code>, <code>ingress traefik</code>.</p> <p>However, because the whole K2s solution relies on a private network, the exposed endpoints are only available inside this private network, running behind the Windows host - regardless which Hosting Variant is used.</p> <p>In this document, we will assume you have enabled the K2s addon <code>dashboard</code>, so it is usable on your local host at <code>http://k2s.cluster.local/dashboard/</code>, and we further more assume you have an own product configured in one of the K2s ingress, reachable locally under <code>http://my-product.local</code>.</p> <p>If we want to expose the ingress / gateway endpoints outside of the Windows host in a secure manner, we need to configure a reverse proxy on the Windows host. The following picture shows this schematically for one of the variants:</p> <p></p> <p>We describe here two ways to do that: using the windows firewall and using IIS.</p>"},{"location":"op-manual/secure-host-access/#option-1-using-the-windows-firewall","title":"[Option 1] Using the Windows firewall","text":"<p>One way to expose the functionality outside of the Windows host is to use the Windows firewall. Use the Windows netsh command to create a port proxy that forwards external traffic to your ingress controller:</p> <p><code>netsh interface portproxy add v4tov4 listenport=8443 listenaddress=YOUR-HOST-IP connectport=443 connectaddress=172.19.1.100</code></p> <p>This command creates a tunnel that:</p> <p>Listens on port 8443 (or choose another free port on your host) at address YOUR-HOST-IP (your host interface IP, in most cases your Ethernet adapter) and  forwards traffic to port 443 at 172.19.1.100 (likely your ingress controller's service), by this the traffic will flow to the K8s cluster. </p> <p>Result: External clients can now access your Kubernetes services by connecting to YOUR-HOST-IP:8443. The traffic flows through the Windows port proxy to your ingress controller, which then routes it to the appropriate service based on your ingress rules (hostname, path, etc.). This setup is commonly used in local development environments where the Kubernetes cluster runs on the host.</p> <p>Please check out other helpfull commands regarding portproxy:</p> <p><code>netsh interface portproxy show all</code> - shows all port forwardings settings</p> <p><code>netsh interface portproxy reset</code>    - cleans them all, for testing very usefull </p>"},{"location":"op-manual/secure-host-access/#option-2-using-iis","title":"[Option 2] Using IIS","text":"<p>Another way to expose the functionality outside of the Windows host is to use the Application Request Routing module for IIS and the URL Rewrite IIS Module to configure a reverse proxy to the services exposed by the K2s ingress or gateway addon.</p> <p>Using the IIS will ease up integration in the site network environment regarding secure communication and user management, as the IIS can be configured for SSL using the existing host certificate and the NTLM authentication can be configured in IIS.</p> <p>The example below shows again how to make the same two applications available outside your host over <code>https</code>, and this time also making sure that the user is authenticated against the local host (i.e. he would also be allowed to log in on your local host):</p> <ul> <li><code>https://my-host.my-domain.com/dashboard</code> -&gt; <code>http://k2s.cluster.local/dashboard/</code></li> <li><code>https://my-host.my-domain.com/my-product</code> -&gt; <code>http://my-product.local</code></li> </ul> <p>Follow these steps:</p> <ol> <li>Install the IIS Module URL Rewrite</li> <li>Install the IIS Module Application Request Routing</li> <li>In IIS Manager, navigate to your default site and select <code>bindings</code> in the <code>Actions pane</code> on the right.</li> </ol> <p>Activate SSL binding for your default site in IIS. You need a server certificate to do that.</p> <p></p> <ol> <li>In IIS Manager, navigate to your default site and select <code>Authentication</code> in the <code>IIS</code> section of the <code>Features View</code>.</li> </ol> <p>Enable <code>Windows Authentication</code>:</p> <p></p> <ol> <li>In IIS Manager, select your computer (root node) and then select <code>Application Request Routing Cache</code> in the <code>IIS</code> section of the <code>Features View</code>. Then select <code>Server Proxy Settings...</code> in the <code>Actions pane</code>, and enable the proxy:</li> </ol> <p></p> <p>Also activate the <code>Reverse rewrite host in response headers</code>.</p> <ol> <li>Finally, in IIS Manager, navigate to your default site again, select <code>URL Rewrite</code>, and create your inbound and outbound rules. Alternatively, update the configuration file under <code>C:\\inetpub\\wwwroot\\web.config</code> and restart the site in IIS.</li> </ol> <p>The example below shows how to forward requests to two different ingress endpoints, one of them being the K2s dashboard also used in the previous section.</p> XML<pre><code>&lt;?xml version=\"1.0\" encoding=\"UTF-8\"?&gt;\n&lt;configuration&gt;\n  &lt;system.webServer&gt;\n    &lt;rewrite&gt;\n      &lt;rules&gt;\n        &lt;rule name=\"k2s-dashboard\" stopProcessing=\"true\"&gt;\n          &lt;match url=\"^dashboard/?(.*)\" /&gt;\n          &lt;serverVariables&gt;\n            &lt;set name=\"HTTP_ACCEPT_ENCODING\" value=\"\" /&gt;\n          &lt;/serverVariables&gt;\n          &lt;action type=\"Rewrite\" url=\"http://k2s.cluster.local/dashboard/{R:1}\" logRewrittenUrl=\"true\" /&gt;\n        &lt;/rule&gt;\n        &lt;rule name=\"my-product\" stopProcessing=\"true\"&gt;\n          &lt;match url=\"^my-product/?(.*)\" /&gt;\n          &lt;action type=\"Rewrite\" url=\"http://my-product.local/{R:1}\" logRewrittenUrl=\"true\" /&gt;\n        &lt;/rule&gt;\n      &lt;/rules&gt;\n      &lt;outboundRules&gt;\n        &lt;rule name=\"my-product-out\" preCondition=\"isHTML\" stopProcessing=\"true\"&gt;\n          &lt;match filterByTags=\"Base\" pattern=\"^/?(.*)$\" negate=\"false\" /&gt;\n          &lt;action type=\"Rewrite\" value=\"/my-product/{R:1}\" /&gt;\n          &lt;conditions&gt;\n            &lt;add input=\"{URL}\" pattern=\"/my-product.*\" /&gt;\n          &lt;/conditions&gt;\n        &lt;/rule&gt;\n        &lt;preConditions&gt;\n          &lt;remove name=\"isHTTP\" /&gt;\n          &lt;preCondition name=\"isHTML\"&gt;\n            &lt;add input=\"{RESPONSE_CONTENT_TYPE}\" pattern=\"^text/html\" /&gt;\n          &lt;/preCondition&gt;\n        &lt;/preConditions&gt;\n      &lt;/outboundRules&gt;\n    &lt;/rewrite&gt;\n    &lt;security&gt;\n      &lt;authentication&gt;\n        &lt;windowsAuthentication enabled=\"true\" /&gt;\n      &lt;/authentication&gt;\n    &lt;/security&gt;\n  &lt;/system.webServer&gt;\n&lt;/configuration&gt;\n</code></pre> <p>Open Point</p> <p>It seems that IIS Application Request Routing has an issue with URLs ending with a space character (as this is forbidden) - although NGINX is tolerant with this.</p> <p>The dashboard web application makes calls to APIs, and in many of them the namespace is used as REST API resource ID, e.g. all Pods of namespace <code>kubernetes-dashboard</code> are retrieved with this API call:</p> <p><code>http://k2s.cluster.local/dashboard/api/v1/pod/kubernetes-dashboard?query=value&amp;...</code></p> <p>But when the user selects <code>All Namespaces</code> in the User Interface, the same URL is invoked with a space character (<code>%20</code>) as the name of the resource - it seems as this is the convention the developers of the Dashboard made:</p> <p><code>http://k2s.cluster.local/dashboard/api/v1/pod/%20?query=value&amp;...</code></p> <p>The HTTP specs forbid to have a space at the end on an URL, but it works for some reasons. However, when the rewrite rules kick in, it seems they drop the space and the application is not working with <code>All Namespaces</code> selected.</p> <p>This line in the Kubernetes dashboard sources is causing the issue (the space character):</p> <p><code>return this.namespace_.isMultiNamespace(currentNamespace) ? ' ' : currentNamespace;</code></p>"},{"location":"op-manual/secure-host-access/#base-href","title":"Base <code>href</code>","text":"<p>When configuring reverse proxies, special attention and test effort must be spent to ensure that URLs are properly handled, in case they are pointing to the services being re-directed to.</p> <p>In our example above, the <code>my-product.local</code> app makes several calls to APIs using relative URLs. The app is designed to work e.g. at <code>my-product.local/</code>, and encodes the <code>&lt;base href=\"/\"&gt;</code>. But when the application is accessed through the secure URL at e.g. <code>my-host.my-domain.com/my-product</code>, the base URL must be rewritten to <code>&lt;base href=\"/my-product/\"&gt;</code>.</p> <p>This is solved for <code>my-product</code> by outbound rules, which inspects the responses and make the necessary changes for the <code>&lt;base href.../&gt;</code>.</p> <p>For the dashboard, no change is necessary, because it detects and sets the base <code>href</code> dynamically, see the code.</p>"},{"location":"op-manual/signcatalog-k2s/","title":"Sign K2s package","text":""},{"location":"op-manual/signcatalog-k2s/#signing-of-k2s-artifacts","title":"Signing of K2s artifacts","text":""},{"location":"op-manual/signcatalog-k2s/#what-use-case-to-consider","title":"What use case to consider","text":"<p>Enterprises using Device Guard or Windows Defender Application Control (WDAC) or having an Installer Packages with Signed Components.</p>"},{"location":"op-manual/signcatalog-k2s/#solution-used","title":"Solution used","text":"<p>A .cat file (catalog file) can be used to sign multiple files collectively without signing each binary individually. For the entire k2s distribution such an catalog file will be created always in sync with all the artifacts included (exe, ps1, ... files). The catalog file is always located under: <code>\\build\\catalog\\k2s.cat</code></p>"},{"location":"op-manual/signcatalog-k2s/#sign-the-catalog-file","title":"Sign the catalog file","text":"<p>To sign a catalog file (.cat) in Windows, you use the signtool.exe utility, which is included in the Windows SDK.  Signing a catalog file is essential when complying with Windows Code Integrity Policies, or publishing via Windows Update. </p> <p>Best is to have an certificate from an official certificate issuer (also called Certificate Authorities (CAs)).  These are trusted organizations that issue digital certificates for code signing. Examples are: DigiCert, Sectigo, Globalsign, ...</p> <p>In case that you don't have such an certificate from an official certificate issuer, you could also use an self-signed certificate:</p> Text Only<pre><code>$cert = New-SelfSignedCertificate -Type CodeSigningCert -Subject \"CN=K2sCatalogCertificate\" -KeyAlgorithm RSA -KeyLength 2048 -HashAlgorithm SHA256 -CertStoreLocation \"Cert:\\LocalMachine\\My\" -NotAfter (Get-Date).AddYears(10)\n</code></pre> <p>After creating such an certificate, you can export it to a file:</p> Text Only<pre><code>Export-PfxCertificate -Cert $cert -FilePath \"C:\\Path\\To\\Your\\Certificates\\MyCatalogSigningCert.pfx\" -Password $password\n</code></pre> <p>Also the public key can be export to a file:</p> Text Only<pre><code>Export-Certificate -Cert $cert -FilePath \"C:\\Path\\To\\Your\\Certificates\\MyCatalogSigningCert.cer\"\n</code></pre> <p>At the end, either the certificate from an official certificate issuer or the self signed one can be used to sign the catalog file:</p> Text Only<pre><code>signtool.exe sign /f \"C:\\Path\\To\\Your\\Certificates\\MyCatalogSigningCert.pfx\" /p \"YourStrongPassword!\" /fd SHA256 /v \".\\build\\catalog\\k2s.cat\"\n</code></pre> <p>Please don't forget to import the public key into the local store:</p> Text Only<pre><code>$CertificatePath = \"C:\\Path\\To\\Your\\Certificates\\MyCatalogSigningCert.cer\"\nImport-Certificate -FilePath $CertificatePath -CertStoreLocation Cert:\\LocalMachine\\Root\nImport-Certificate -FilePath $CertificatePath -CertStoreLocation Cert:\\LocalMachine\\TrustedPublisher\n</code></pre>"},{"location":"op-manual/starting-k2s/","title":"Starting K2s","text":""},{"location":"op-manual/starting-k2s/#starting-k2s","title":"Starting K2s","text":"<p>To start the K8s cluster and all accompanying services, run: Bash Session<pre><code>k2s start\n</code></pre></p> <p>Note</p> <p>K2s will start automatically after the installation has finished.</p>"},{"location":"op-manual/starting-k2s/#additional-options","title":"Additional Options","text":""},{"location":"op-manual/starting-k2s/#skip-starting-if-already-running","title":"Skip Starting if Already Running","text":"<p>To skip starting the K2s cluster if it is already running, use the <code>--ignore-if-running</code> flag or its shortcut <code>-i</code>: Bash Session<pre><code>k2s start --ignore-if-running\n</code></pre> or Bash Session<pre><code>k2s start -i\n</code></pre></p> <p>Note</p> <p>This option is useful to avoid unnecessary restarts of the cluster when it is already running.  </p>"},{"location":"op-manual/stopping-k2s/","title":"Stopping K2s","text":""},{"location":"op-manual/stopping-k2s/#stopping-k2s","title":"Stopping K2s","text":"<p>To stop the K8s cluster and all accompanying services, run: Bash Session<pre><code>k2s stop\n</code></pre></p> <p>Danger</p> <p>It is highly recommended to stop K2s before (shutting down | suspending | hibernating) the Windows host system to avoid Windows networking issues on the next host system startup!</p> <p>This is a known root cause for issues occurring while running Windows-based workloads after K8s cluster start.</p>"},{"location":"op-manual/uninstalling-k2s/","title":"Uninstalling K2s","text":""},{"location":"op-manual/uninstalling-k2s/#uninstalling-k2s","title":"Uninstalling K2s","text":"<p>To uninstall K2s, run: Bash Session<pre><code>&lt;repo&gt;\\k2s.exe uninstall\n</code></pre></p> <p>To delete downloaded binaries and the control-plane VM image as well, run: Bash Session<pre><code>&lt;repo&gt;\\k2s.exe uninstall -d\n</code></pre></p> <p>See Online vs. Offline for more information.</p>"},{"location":"op-manual/upgrading-k2s/","title":"Upgrading K2s","text":""},{"location":"op-manual/upgrading-k2s/#upgrading-k2s","title":"Upgrading K2s","text":"<p>This guide explains how to upgrade an existing K2s cluster in-place to a newer released version using the <code>k2s system upgrade</code> command.</p>"},{"location":"op-manual/upgrading-k2s/#versioning","title":"Versioning","text":"<p>K2s release versions follow semantic versioning: <code>MAJOR.MINOR.PATCH</code> (see the Releases page).</p> <p>Supported upgrade path: - Standard path: upgrade only from <code>MINOR-1</code> to the next <code>MINOR</code> within the same <code>MAJOR</code> (e.g. <code>1.4.x</code> \u2192 <code>1.5.y</code>). - Skipping multiple minor versions: perform sequential upgrades through each intermediate minor release. - Using <code>--force</code> (or <code>-f</code> if supported): attempts a direct upgrade between any two versions, but only a subset of combinations are continuously tested.</p> <p>Recommendation: If the currently installed version is several minor releases behind, back up persistent data (application volumes, etc.) before proceeding or use a staging environment to validate.</p> <p>Upgrade support is available starting from K2s <code>v1.1.0</code>.</p> K2s Cluster Upgrade Versioning Semantics"},{"location":"op-manual/upgrading-k2s/#upgrade-procedure","title":"Upgrade Procedure","text":"<p>\u2139\ufe0f Info: The upgrade process re-installs the cluster binaries, migrates (exports/imports) Kubernetes resources, and re-enables previously enabled addons. It does not also upgrade existing addons, this needs to be done separatly using the <code>k2s addons ...</code> commands.</p> <p>\u26a0\ufe0f Warning: Addon data/persistence is also not automatically restored during upgrade. To backup and restore addon data, use <code>k2s addons export</code> before upgrade and <code>k2s addons import</code> after upgrade.</p> <ol> <li>Extract the new K2s release package into a directory (e.g. <code>C:\\k2s\\v1.5.0</code>).</li> <li>Open an elevated (Administrator) PowerShell or command prompt in that directory.</li> <li>Run the upgrade command:    Bash Session<pre><code>k2s system upgrade\n</code></pre></li> </ol>"},{"location":"op-manual/upgrading-k2s/#common-flags-please-check-all-possible-flags-on-the-cli","title":"Common Flags (please check all possible flags on the cli)","text":"Flag Purpose <code>-d</code> Delete previously cached artifacts after upgrade (cleans local cache). <code>-c &lt;file&gt;</code> Supply a new configuration file to override existing cluster settings (memory, CPU, storage\u2026). <code>-p &lt;http-proxy&gt;</code> Use the specified HTTP proxy for any required network access during the upgrade. <code>--force</code> Attempt upgrade even if skipping multiple minor versions. Use with caution; take a backup first. <p>Examples: Bash Session<pre><code># Override settings using a new config\nk2s system upgrade -c my-settings.yaml\n\n# Use proxy and remove cached artifacts after success\nk2s system upgrade -p http://proxy.local:8080 -d\n\n# Force upgrade across multiple minor jumps\nk2s system upgrade --force\n</code></pre></p>"},{"location":"op-manual/upgrading-k2s/#configuration-override","title":"Configuration Override","text":"<p>If you omit <code>-c</code>, the previous cluster's effective settings (memory, CPU, storage paths) are reused. To change them during an upgrade, provide a config file as described in Installing Using Config Files.</p>"},{"location":"op-manual/upgrading-k2s/#what-the-command-does","title":"What the Command Does","text":"<p>Internally the following high\u2011level steps are performed: 1. Export all existing workloads (cluster\u2011scoped resources and namespaced resources). 2. Capture the list of currently enabled addons. 3. Uninstall the existing cluster components. 4. Install the new version from the extracted package. 5. Import previously exported workloads. 6. Re-enable previously enabled addons. 7. Verify workload health (basic readiness checks). 8. Final cluster availability validation.</p>"},{"location":"op-manual/upgrading-k2s/#rollback-considerations","title":"Rollback Considerations","text":"<p>There is no automatic rollback. If an upgrade fails: - Review logs under the K2s log directory. - Re-run with increased verbosity (if supported) or <code>--force</code> only after assessing the cause. - If recovery is not feasible, you can reinstall the previous version then import a backup (if you captured one beforehand) or re-run your deployment manifests.</p>"},{"location":"op-manual/upgrading-k2s/#backups-recommended","title":"Backups (Recommended)","text":"<p>Before upgrading across more than one minor version, back up: - Application persistent volumes (if external, ensure snapshots exist). - Custom configuration files and secrets (outside of version-controlled items).</p>"},{"location":"op-manual/upgrading-k2s/#proxy-usage","title":"Proxy Usage","text":"<p>If your environment requires HTTP(S) proxy access, specify it with <code>-p</code>. Ensure the proxy allows access to any required artifact repositories; otherwise offline packages should include all needed assets.</p>"},{"location":"op-manual/upgrading-k2s/#upgrade-hooks-full-upgrade-only","title":"Upgrade Hooks (Full Upgrade Only)","text":"<p>The full upgrade process supports custom backup and restore hooks for cluster resources that need special handling during upgrade (e.g., SMB shares, external configurations).</p> <p>\u2139\ufe0f Note: Hooks are only executed during full upgrades. Delta updates preserve cluster state in place and do not execute hooks.</p> <p>Hook Locations:</p> <ol> <li>Default location: <code>&lt;K2s-install-dir&gt;\\bin\\LocalHooks\\</code></li> <li>Additional location: Specify via the <code>--additional-hooks-dir</code> flag</li> </ol> <p>Hook Naming Convention:</p> <ul> <li>Backup hooks: <code>&lt;name&gt;.Backup.ps1</code> \u2014 executed before cluster uninstall</li> <li>Restore hooks: <code>&lt;name&gt;.Restore.ps1</code> \u2014 executed after cluster install</li> </ul> <p>Hook Script Parameters:</p> <p>Each hook script receives the following parameters:</p> Parameter Description <code>-BackupDir</code> Directory where backup data should be stored/retrieved <code>-ShowLogs</code> Whether to display verbose logging <p>Example Hook Script: PowerShell<pre><code># MyResource.Backup.ps1\nparam(\n    [string]$BackupDir,\n    [switch]$ShowLogs\n)\n\n# Backup custom resource\n$backupPath = Join-Path $BackupDir \"my-resource\"\nNew-Item -ItemType Directory -Path $backupPath -Force | Out-Null\n# ... backup logic here\n</code></pre></p> <p>Usage: Bash Session<pre><code># Use additional hooks directory\nk2s system upgrade --additional-hooks-dir \"C:\\MyHooks\"\n</code></pre></p>"},{"location":"op-manual/upgrading-k2s/#after-upgrade","title":"After Upgrade","text":"<p>Validate cluster: Bash Session<pre><code>kubectl get nodes\nkubectl get pods -A\n</code></pre></p> <p>Check addon status (addons are automatically re-enabled during upgrade): Bash Session<pre><code>k2s addons status\n</code></pre></p> <p>If you exported addon data before upgrade, restore it now: Bash Session<pre><code>k2s addons import\n</code></pre></p> <p>If any workload fails readiness, inspect its namespace events and logs before proceeding with further changes.</p>"},{"location":"op-manual/upgrading-k2s/#delta-updates","title":"Delta Updates","text":"<p>For bandwidth-constrained environments or large-scale deployments, K2s supports delta packages that contain only the files changed between two specific versions.</p> <p>\u2139\ufe0f Info: Delta updates perform an in-place update without uninstalling/reinstalling the cluster. The cluster is stopped, files are updated, and the cluster is restarted. This means workloads, addons, and persistent data remain intact.</p>"},{"location":"op-manual/upgrading-k2s/#when-to-use-delta-updates","title":"When to Use Delta Updates","text":"<ul> <li>Upgrading between adjacent minor versions (e.g., 1.4.x \u2192 1.5.x)</li> <li>Applying patch releases (e.g., 1.4.0 \u2192 1.4.1)</li> <li>Environments with limited bandwidth or storage</li> <li>When you want to preserve running workloads and addon state</li> </ul>"},{"location":"op-manual/upgrading-k2s/#what-delta-update-does","title":"What Delta Update Does","text":"<p>Unlike full upgrades, delta updates:</p> <ol> <li>Detect delta package root (current directory with <code>delta-manifest.json</code>)</li> <li>Detect target installation folder (from <code>setup.json</code>)</li> <li>Stop the cluster if running</li> <li>Update Windows executables and scripts from delta to target installation</li> <li>Update Debian packages on the Linux VM (if applicable)</li> <li>Update container images from delta</li> <li>Restart the cluster</li> </ol> <p>Key Differences from Full Upgrade:</p> Aspect Full Upgrade Delta Update Cluster state Uninstalled and reinstalled Stopped and restarted Workloads Exported and re-imported Preserved in place Addons Re-enabled after install Remain enabled Addon data Not preserved (use export/import) Preserved Upgrade hooks Executed (backup/restore) Not executed Package size Full installation (~GB) Only changed files (~MB)"},{"location":"op-manual/upgrading-k2s/#applying-a-delta-package","title":"Applying a Delta Package","text":"<ol> <li>Verify your current version matches the delta's source version</li> <li>Extract the delta package:    Bash Session<pre><code>Expand-Archive k2s-delta-v1.5.0-to-v1.6.0.zip -Destination .\\delta\n</code></pre></li> <li>Navigate to the extracted directory and run the upgrade:    Bash Session<pre><code>cd .\\delta\n.\\k2s.exe system upgrade\n</code></pre></li> <li>Validate the cluster as described above</li> </ol> <p>\u26a0\ufe0f Note: The <code>k2s system upgrade</code> command automatically detects whether to perform a full upgrade or delta update based on the presence of <code>delta-manifest.json</code> in the package directory.</p> <p>For complete documentation on creating and applying delta packages, see Delta Packages.</p>"},{"location":"quickstart/","title":"Quick Start","text":""},{"location":"quickstart/#quick-start","title":"Quick Start","text":"<ol> <li>Get K2s</li> <li>Verify that the Prerequisites are fulfilled</li> <li>Run as administrator in the installation/repository folder:     Bash Session<pre><code>k2s.exe install\n</code></pre></li> <li>Check K2s cluster health:     Bash Session<pre><code>k2s.exe status\n</code></pre></li> <li>Deploy your workloads </li> </ol> <p>See k2s CLI and CLI Shortcuts for more means to interact with the K2s cluster.</p> <p>Optionally, install one or more K2s Addons for additional functionality.</p> <p>To create an offline installer first, check out Creating Offline Package.</p>"},{"location":"troubleshooting/diagnostics/","title":"Diagnostics","text":""},{"location":"troubleshooting/diagnostics/#diagnostics","title":"Diagnostics","text":""},{"location":"troubleshooting/diagnostics/#k2s-system-status","title":"K2s System Status","text":"<p>To inspect the full K2s system status, run: Bash Session<pre><code>k2s status -o wide\n</code></pre></p>"},{"location":"troubleshooting/diagnostics/#disruption-in-networking","title":"Disruption in networking","text":"<p>When there is no internet access on the host machine or when container images cannot be pulled, it is recommended to restart the cluster networking in the following scenarios:</p> <ul> <li>The host machine is switched between networks (e.g. remote or office).</li> <li>The host machine experiences an unintended crash.</li> <li>After booting the host machine from hibernation, or following a reboot or shutdown.</li> <li>The VPN on the host machine is turned on or off (e.g., Zscaler).</li> </ul> Bash Session<pre><code>k2s stop\nk2s start\n</code></pre>"},{"location":"troubleshooting/diagnostics/#log-files","title":"Log Files","text":"<p>To analyze the log files, browse the directory <code>&lt;install-drive&gt;\\var\\log</code>. The main log file is <code>k2s.log</code>.</p>"},{"location":"troubleshooting/diagnostics/#dumping-k2s-debug-information","title":"Dumping K2s Debug Information","text":"<p>To dump K2s system information, run: Bash Session<pre><code>k2s system dump\n</code></pre></p>"},{"location":"troubleshooting/diagnostics/#listing-all-pvcs","title":"Listing ALL PVCs","text":"<p>Get the list of all mounted volumes, their size and their namespace: Bash Session<pre><code>kg pv\n</code></pre></p> <p>Get the list of all mounted volume claims and their current usage: Bash Session<pre><code>kg pvc -A\n</code></pre></p>"},{"location":"troubleshooting/known-issues/","title":"Known Issues","text":""},{"location":"troubleshooting/known-issues/#known-issues","title":"Known Issues","text":""},{"location":"troubleshooting/known-issues/#secret-issue-when-loading-via-kustomize","title":"Secret Issue When Loading via Kustomize","text":"Bash Session<pre><code>kubectl apply -k &lt;folder&gt;\nerror: rawResources failed to read Resources: Load from path ../secrets failed: '../secrets' must be a file (got d='..\\kubernetes\\secrets')\n</code></pre> <p>=&gt; kubectl might be outdated, please us a newer version.</p>"},{"location":"troubleshooting/known-issues/#disk-pressure","title":"Disk Pressure","text":"<p>You may suddenly find that Kubernetes cannot start a large number of Pods. This is often due to Disk Pressure meaning that you are lacking available space on your hard disk.</p> <p>For diagnostics, either inspect the K2s System Status or use kubectl directly: Bash Session<pre><code>kubectl describe nodes\n</code></pre></p> <p>Additionally, on Linux, you can run: Bash Session<pre><code>kubectl describe nodes | less\n</code></pre></p> <p>Be aware that the disk pressure may occur on your physical Windows system as well as inside the Linux VM.</p> <p>If you have a large number of Pods stopped than the problem is probably on the Linux side since most of the containers run there. If the problem is on your local Windows system, use the standard tools to win space on the drives, (e.g. TreeSize utility on <code>C\\</code> and <code>D:\\</code>).</p> <p>You need a least 10 GB free on both disks.</p> <p>If the problem is on your Linux VM, you need following commands to find and fix the problem (get an overview of the disk space consumption):</p> <ul> <li><code>k2s node connect -i 172.19.1.100 -u remote</code> to open a shell on the Linux machine</li> <li><code>df</code> and look at /dev/sda1 percentage</li> </ul> <p>Then go to the very top directory with <code>cd ../..</code> and with <code>sudo du -d1 -x -h</code> you can look in each directory and subdirectory to localize the high space consumption.</p> <p>You may have too many data in your couch data and can remove them under <code>/mnt/&lt;folder&gt;</code> with <code>sudo rm -r -d shards/</code>.</p> <p>The problem comes most probably from the Docker registry and you can clean it up with <code>docker system prune</code> or <code>crictl rmi --prune</code> if you do not have Docker installed.</p> <p>Warning</p> <p>If you are currently using some locally built containers, Kubernetes will not be able to reload them automatically.</p> <p>You must rebuild them locally on your system with the <code>k2s image build</code> command.</p>"},{"location":"troubleshooting/known-issues/#volume-access-problem","title":"Volume Access Problem","text":"<p>TP remove unbound volumes, run: Bash Session<pre><code>k delete pvc &lt;pvc-name&gt; -n &lt;namespace&gt; --f\nk delete pv  &lt;pv-name&gt; -n &lt;namespace&gt;\n</code></pre></p> <p>Then re-apply the volumes: Bash Session<pre><code>ka -f &lt;manifest-containing-pv&gt;.yaml\n</code></pre></p> <p>Then re-apply the manifest of the service consuming the volumes: Bash Session<pre><code>kubectl -k .\\&lt;manifest-folder&gt;\n</code></pre></p>"},{"location":"troubleshooting/known-issues/#no-cbr0-switch-being-created-during-start","title":"No <code>cbr0</code> Switch Being Created During Start","text":"<p>When starting K2s, you run into an error (e.g. timeout) while the script is waiting for the <code>cbr0</code> switch to be created by flannel:</p> Example Output<pre><code>    [10:19:22] waiting for cbr0 switch to be created by flanneld...\n    Be prepared for several seconds of disconnected network!\n    [10:19:25] State of services (checkpoint 1): All running\n    No cbr0 switch created so far...\n    [10:19:27] State of services (checkpoint 2): All running\n    PID for flanneld service: 20256\n    No cbr0 switch created so far...\n    [10:19:29] State of services (checkpoint 3): All running\n    No cbr0 switch created so far...\n    [10:19:31] State of services (checkpoint 4): All running\n    No cbr0 switch created so far...\n    [10:19:33] State of services (checkpoint 5): All running\n    PID for flanneld service: 5260  (restarted after failure)\n    No cbr0 switch created so far...\n    [10:19:35] State of services (checkpoint 6): All running\n    PID for flanneld service: 14488  (restarted after failure)\n    No cbr0 switch created so far...\n    [10:19:37] State of services (checkpoint 7): All running\n    PID for flanneld service: 2236  (restarted after failure)\n    No cbr0 switch created so far...\n</code></pre> <p>There are several reasons which can cause this. Basically the flanneld process is waiting for a new virtual switch to be created which has the same IP as the original, physical ethernet adapter. </p>"},{"location":"troubleshooting/known-issues/#networking-problems","title":"Networking Problems","text":"<p>If you face network errors especially between Linux and Microsoft services, you may need to reset your networking.</p>"},{"location":"troubleshooting/known-issues/#minor-workaround","title":"Minor Workaround","text":"<ul> <li>Run <code>k2s stop</code></li> <li>Run <code>ipconfig</code></li> <li>Run: PowerShell<pre><code>get-hnsnetwork | remove-hnsnetwork\n</code></pre></li> <li>Run <code>ipconfig</code> to check cleanup result</li> <li>Run <code>k2s start</code></li> </ul>"},{"location":"troubleshooting/known-issues/#major-workaround","title":"Major Workaround","text":"<p>Warning</p> <p>This workaround resets the networking on Windows.</p> <ul> <li>Run <code>netcfg -d</code></li> <li>Reboot the host system</li> </ul>"},{"location":"troubleshooting/known-issues/#microsoft-apipa-link-local-address","title":"Microsoft APIPA / Link-Local Address","text":"<p>Another reason could be the Windows Automatic Private IP Addressing (APIPA). It is enabled by default in Windows 10 and depending on the speed of the physical adapter, the CPU and the DHCP server, it may happen that Windows decides to use an \"automatic APIPA address\".</p> <p>There is a reserved IPv4 address block <code>169.254.0.0/16</code> (<code>169.254.0.0</code> \u2013 <code>169.254.255.255</code>) for link-local addressing. If such an address is chosen by Microsoft, it will no longer be overwritten by the DHCP server (depending on OS version). This will make the flanneld approach unusable. Such APIPA addresses are detected during the K2s start routine. A workaround is also provided the script FixAutoconfiguration.ps1.</p> <p></p> <p>Bug</p> <p>After applying this fix, the APIPA system is completely disabled on the machine. Nevertheless, Microsoft does not indicate that properly when you issue the <code>ipconfig /all</code> command. You will still see lines that state <code>Autoconfiguration Enabled . . . . : Yes</code> but that is not true. Don't believe it, it's just a bug in the output. Autoconfiguration is really disabled.</p> <p>More information on this topic:</p> <ul> <li>What is APIPA</li> <li>Wikipedia on APIPA</li> <li>Microsoft on APIPA</li> </ul>"},{"location":"troubleshooting/known-issues/#unable-to-mount-file-share-between-nodes","title":"Unable to Mount File Share Between Nodes","text":""},{"location":"troubleshooting/known-issues/#problem","title":"Problem","text":"<p>Mounting errors like the following occurred: <pre><code>mount: /mnt/k8s-smb-share: can't read superblock on //172.x.x.x/k8s-smb-share.\n</code></pre></p>"},{"location":"troubleshooting/known-issues/#solution","title":"Solution","text":"<p>Respective user must have local permissions to use file shares in order to host/mount SMB shares.</p>"},{"location":"troubleshooting/known-issues/#k2sexe-missing-k2s-command-not-found","title":"<code>k2s.exe</code> Missing / k2s Command Not Found","text":""},{"location":"troubleshooting/known-issues/#problem_1","title":"Problem","text":"<p>If the <code>k2s.exe</code> is missing in the install folder, most likely the Windows Virus &amp; thread protection identified it as a thread and moved it to quarantine. Despite all exclusion lists this file was added to by the K2s maintainers, this can happen from time to time.</p>"},{"location":"troubleshooting/known-issues/#solution_1","title":"Solution","text":"<ul> <li>If the Windows Virus &amp; thread protection asks for the appropriate action, allow the <code>k2s.exe</code> file on your system.</li> <li>To restore the file, go to <code>Windows Virus &amp; thread protection</code> -&gt; <code>Protection history</code> and restore <code>k2s.exe</code>. The result should look similar to this:</li> </ul>"},{"location":"troubleshooting/known-issues/#unable-to-run-windows-container-on-a-hardened-machine-applocker-rules","title":"Unable to Run Windows Container on a Hardened Machine (AppLocker Rules)","text":""},{"location":"troubleshooting/known-issues/#problem_2","title":"Problem","text":"<p>If the K2s cluster is installed on a machine where security hardening is applied using AppLocker rules, then running Windows containers normally will be blocked. If you describe the Windows container Pod then you might see the following error, where the application is blocked by group policy: <pre><code>Warning  FailedCreatePodSandBox  0s    kubelet            Failed to create pod sandbox: rpc error: code = Unknown desc = failed to start sandbox container task \"459fe28ca0da5a154964c80e1b5d74de3abefc83cf7ad77418a5d6cd9a7e5605\": hcs::System::CreateProcess 459fe28ca0da5a154964c80e1b5d74de3abefc83cf7ad77418a5d6cd9a7e5605: This program is blocked by group policy. For more information, contact your system administrator.: unknown\n</code></pre></p> <p>You can check the existing AppLocker rules by opening <code>Local Group Policy Editor</code> by running <code>gpedit.msc</code>. You can find the rules as shown below:</p> <p></p> <p>If Applocker is activated within K2s usage, the the rule need to be added manually:</p> Text Only<pre><code>        $appLockerRules = '.\\cfg\\applocker\\applockerrules.xml'\n        Set-AppLockerPolicy -XmlPolicy $appLockerRules -Merge\n</code></pre> <p>By this, windows containers will not be blocked by Applocker.</p>"},{"location":"troubleshooting/known-issues/#solution_2","title":"Solution","text":"<p>Warning</p> <p>This is not an ideal solution, rather a workaround.</p> <p>Change registry setting under <code>Computer\\HKEY_LOCAL_MACHINE\\SOFTWARE\\Policies\\Microsoft\\Windows\\SrpV2\\EXE</code>, <code>AllowsWindows - 1</code>, <code>EnforcementMode - 1</code> (both are decimals). Next, we should disable the rules in AppLocker and restart the machine.</p> <p>Although, this is just a hack to continue working, we should allow Windows containers execution specifically <code>CMD.exe</code> in a secured way.</p> <p>Warning</p> <p>Please review the <code>AppLocker</code> rules with your security experts.</p>"},{"location":"troubleshooting/known-issues/#unable-to-run-windows-hyper-v-on-host-machine","title":"Unable to Run Windows Hyper-V on Host Machine","text":""},{"location":"troubleshooting/known-issues/#problem_3","title":"Problem","text":"<p>Hyper-V Manager unable to connect to Virtual Machine Management service on host machine. To reproduce, run: PowerShell<pre><code>Get-VM\n</code></pre> If there is no error, the command should return a list of VMs (or an empty list).</p> <p>If an error occurs, it might look like: <pre><code>Hyper-V encountered an error trying to access an object on computer \u2018localhost\u2019 because the object was not found. The object might have been deleted. Verify that the Virtual Machine Management service on the computer is running. If the service is running, try to perform the task again by using Run as Administrator.\n</code></pre></p>"},{"location":"troubleshooting/known-issues/#solution_3","title":"Solution","text":"<p>This is due to a prior uninstall which has deleted a MOF file which is required for HyperVisor. In order to regenerate this file, run the following command from an elevated (administrator) command prompt: Bash Session<pre><code>MOFCOMP %SYSTEMROOT%\\System32\\WindowsVirtualization.V2.mof\n</code></pre></p>"},{"location":"troubleshooting/known-issues/#unable-to-run-windows-containers-on-host-machine","title":"Unable to Run Windows Containers on Host Machine","text":""},{"location":"troubleshooting/known-issues/#problem_4","title":"Problem","text":"<p>Windows containers are unable to run due to failure in <code>hcs::CreateComputeSystem</code>: Error Log from Pod<pre><code>Failed to create pod sandbox: rpc error: code = Unknown desc = failed to create containerd task: failed to create shim task: hcs::CreateComputeSystem 9f078e725c4f6b36dc2647d6323bc214da46fa24ba88d3d5652bc687993c27ed: The request is not supported.: unknown\n</code></pre> General Error<pre><code>Error response from daemon: hcsshim::CreateComputeSystem 70b6cf806eef813a8a93b40780c32e43f5406f0cbec10b922d3bd35ecc677b6c: The request is not supported.\n</code></pre></p>"},{"location":"troubleshooting/known-issues/#solution_4","title":"Solution","text":"<ol> <li>Run <code>k2s stop</code></li> <li>Run: PowerShell<pre><code>Disable-WindowsOptionalFeature -Online -FeatureName Microsoft-Hyper-V-All\n</code></pre></li> <li>Restart host machine</li> <li>Run: PowerShell<pre><code>Enable-WindowsOptionalFeature -Online -FeatureName Microsoft-Hyper-V-All\n</code></pre></li> <li>Restart host machine</li> <li>Run <code>k2s start</code></li> <li>Re-deploy Windows containers</li> </ol>"},{"location":"user-guide/adding-container-registry/","title":"Adding a Container Registry","text":""},{"location":"user-guide/adding-container-registry/#adding-a-container-registry","title":"Adding a Container Registry","text":"<p>This page describes how to add a container registry for pulling and pushing container images.</p>"},{"location":"user-guide/adding-container-registry/#registry-options-of-the-k2s-cli","title":"Registry Options of the k2s CLI","text":"<p>The k2s CLI provides an option to add a registry. You can find the help for registry options with following command:</p> Bash Session<pre><code>k2s image registry -h\n</code></pre>"},{"location":"user-guide/adding-container-registry/#adding-a-registry","title":"Adding a Registry","text":"<p>In the following example you can see how to add a registry:</p> Bash Session<pre><code>k2s image registry add shsk2s.azurecr.io\n</code></pre> <p>You will be asked for username and password. Container runtimes on Windows and Linux node will be automatically configured to get access to the added registry. Credentials are stored so that you can switch easily between configured registries.</p>"},{"location":"user-guide/adding-container-registry/#listing-configured-registries","title":"Listing Configured Registries","text":"<p>The following command shows how to display all configured registries:</p> Bash Session<pre><code>k2s image registry ls\n</code></pre>"},{"location":"user-guide/building-container-image/","title":"Building a Container Image","text":""},{"location":"user-guide/building-container-image/#building-a-container-image","title":"Building a Container Image","text":"<p>This page describes how to build a container image using K2s.</p> <p>K2s internally uses Buildah (on Linux) and Docker (on Windows) for building container images.</p>"},{"location":"user-guide/building-container-image/#container-runtime-and-build-tool","title":"Container Runtime and Build Tool","text":"<p>Windows node:</p> <ul> <li>containerd - Used as the container runtime for the Windows node.</li> <li>Docker - Used only for building container images on Windows.</li> </ul> <p>Linux node:</p> <ul> <li>CRI-O - Used as the container runtime on Linux.</li> <li>Buildah - Used only for building container images on Linux.</li> </ul> <p>Usage: Bash Session<pre><code>k2s image build [flags]\n</code></pre></p>"},{"location":"user-guide/building-container-image/#dockerfile","title":"Dockerfile","text":"<p>The steps and methods to build a container are numerous. Containers can be build in different languages, they can need different compilers with different options and typically, each container needs a specific basis (Windows/Linux, etc.) and a specific amount of data to be packed in the container.</p> <p>This specification is defined in a unified manner in a Dockerfile (and this is also the real name of the file). This ASCII file has a standard content originally defined by Docker, but grown to an implicit standard and therefore reused by other building infrastructure like the containerd.</p> <p>To build a container, you must provide such a Dockerfile and store it beside your code. The tooling described below will use this file to build the container by default. Additionally, you can use also use a Dockerfile present in a different location than your code by using <code>--dockerfile</code> parameter.</p>"},{"location":"user-guide/building-container-image/#building-a-windows-container-image","title":"Building a Windows Container Image","text":"<p>If you need to build a Windows-based application (e.g. a .NET application), you might have the following project structure:</p> <p></p> Bash Session<pre><code>k2s image build --input-folder C:\\s\\examples\\albums-netcore --windows --image-name local/example.albums-win --image-tag 99 -o\n</code></pre> <p>In the above example, k2s CLI is being used with <code>build</code> option to build a .NET application under a particular folder with image name and tag accordingly. It is important to mention the  <code>--windows</code> flag while building Windows-based container images.</p> Example output<pre><code>\u23f3 [12:11:00] Successfully built ec44caa68e5e\n\u23f3 [12:11:00] Successfully tagged local/example.albums-win:99\n\u23f3 [12:11:00] Output of checking if the image local/example.albums-win:99 is now available in docker:\n\u23f3 [12:11:00] REPOSITORY                 TAG       IMAGE ID       CREATED                  SIZE\n\u23f3 [12:11:00] local/example.albums-win   99        ec44caa68e5e   Less than a second ago   361MB\n\u23f3 [12:11:00] C:\\ws\\k2s\\Temp\\ExportedImages\n\u23f3 [12:11:00] Saving image local/example.albums-win:99 temporarily as C:\\ws\\k2s\\Temp\\ExportedImages\\BuiltImage.tar to import it afterwards into containerd...\n\u23f3 [12:11:16] ...saved.\n\u23f3 [12:11:16] Importing image local/example.albums-win:99 from C:\\ws\\k2s\\Temp\\ExportedImages\\BuiltImage.tar into containerd...\n\u23f3 [12:11:19] unpacking docker.io/local/example.albums-win:99 (sha256:6a4c30f6f25f7ba959e904fbbf3d1193fd1a1ba8027cbf414f456704bb3ec4b9)...\n\u23f3 [12:11:20] Loaded image: local/example.albums-win:99\n\u23f3 [12:11:20] ...imported\n\u23f3 [12:11:20] Removing temporarily created file C:\\ws\\k2s\\Temp\\ExportedImages\\BuiltImage.tar...\n\u23f3 [12:11:20] ...removed\n\u23f3 [12:11:21] The built image 'local/example.albums-win:99' is available in the containerd's local repository.\n\u23f3 [12:11:21] Total duration: 00:00:59\n\u23f3 [12:11:21] Converting message of type 'CmdResult' to JSON..\n\u23f3 [12:11:21] message converted\n\u23f3 [12:11:21] JSON compressed\n\u23f3 [12:11:21] JSON base64 encoded\n\u23f3 [12:11:21] message sent via CLI\n SUCCESS  'image build' completed in 1m6.2240613s\nPlease see 'C:\\var\\log\\k2s.log' for more information\n</code></pre> <p>As we are building container images using Docker, built images should be available for containerd and this is achieved via import of built images to the containerd repository.</p> <p>After a successful build command, the image should be available in the containerd repository and can be queried with k2s CLI:</p> <pre><code>k2s image ls\n\nAvailable Images\n\u250c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2510\n| ImageId       | Repository                                              | Tag      | Node        | Size   |\n| ec44caa68e5e6 | docker.io/local/example.albums-win                      | 99       | imw1026986c | 204MB  |\n\u2514\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2518\n</code></pre> <p>For running Windows Pods in K8s, please always specify the Node selector for Windows, as well as a specific Toleration in your YAML file: <pre><code>      nodeSelector:\n        kubernetes.io/os: windows\n      tolerations:\n        - key: \"OS\"\n          operator: \"Equal\"\n          value: \"Windows\"\n          effect: \"NoSchedule\"\n</code></pre></p>"},{"location":"user-guide/building-container-image/#building-a-linux-container-image","title":"Building a Linux Container Image","text":"<p>If you need to build a Linux-based application (e.g. a Go-based application), you might have the following project structure:</p> <p></p> Bash Session<pre><code>k2s image build --input-folder C:\\s\\examples\\albums-golang --image-name local/example.albums-golang --image-tag 99 -o\n</code></pre> <p>In the above example, the k2s CLI is used with <code>build</code> command to build a Go-based application under a particular folder with image name and tag set accordingly.</p>"},{"location":"user-guide/building-container-image/#pushing-to-a-registry","title":"Pushing to a Registry","text":"<p>In order to push your container image, you need to label it with the appropriate version number and push it to the registry:</p> Bash Session<pre><code>k2s image build --input-folder C:\\s\\examples\\albums-netcore --windows --image-name local/example.albums-win --image-tag 99 -p -o\n</code></pre> <p>Note</p> <p>Make sure the registry you want to push to is configured (see Adding a Container Registry).</p> <p>The <code>--push</code> or <code>-p</code> option is required for pushing container image to the configured registry.</p> <p>Then, you need to update the YAML file with the newly published version:</p> <pre><code>   spec:\n      imagePullSecrets:\n        - name: regcred\n      containers:\n        - name: albums-win\n          image: docker.io/local/example.albums-win:99\n          args: [\"--v\", \"4\"]\n</code></pre>"},{"location":"user-guide/building-container-image/#specifying-the-dockerfile-explicitly","title":"Specifying the Dockerfile Explicitly","text":"<p>It is possible to specify a Dockerfile that is not present in the same location as your source to build the container image. This can be achieved by specifying the path to the Dockerfile with the <code>--dockerfile</code> or <code>-f</code> parameter:</p> Bash Session<pre><code>k2s image build --input-folder C:\\s\\examples\\albums-golang --dockerfile C:\\Dockerfile --image-name local/example.albums-golang --image-tag 99 -o\n</code></pre> <p>If the file <code>C:\\Dockerfile</code> does not exist, the build command will fallback to the Dockerfile beside your code, if present. If it is missing, the command will fail.</p> <p>Note</p> <p>When specifying the Dockerfile, it is possible to use relative paths:</p> Bash Session<pre><code>k2s image build --input-folder C:\\s\\examples\\albums-golang --dockerfile ..\\..\\Dockerfile --image-name local/example.albums-golang --image-tag 99 -o\n</code></pre> <p>In this case, the path to the Dockerfile is resolved to the current working directory. If the Dockerfile is not found after the path is resolved, the the Dockerfile, if present, beside your code is used. Otherwise, the command fails.</p>"},{"location":"user-guide/building-container-image/#specifying-build-arguments","title":"Specifying Build Arguments","text":"<p>Build arguments are a great way to add flexibility to your container image builds. You can pass build argument at build-time and a default value can be specified to be used as a fallback:</p> Example Dockerfile with Arguments<pre><code>ARG BaseImage=alpine:latest\n\nFROM ${BaseImage}\nCOPY servicelin /bin\nRUN [\"chmod\",  \"777\", \"./bin/servicelin\"]\nENTRYPOINT [\"/bin/servicelin\"]\n</code></pre> <p>Above is a Dockerfile which has the build argument <code>BaseImage</code>. If the build argument is not set via  <code>k2s image build</code>, the default value <code>alpine:latest</code> is used.</p> <p>You can specify the build argument using <code>--build-arg</code> parameter. In this example, the base image can be set to a Debian version:</p> Bash Session<pre><code>k2s image build -n k2s.io/servicelin -t 1 --build-arg=\"BaseImage=debian:latest\"\n</code></pre>"},{"location":"user-guide/building-container-image/#multiple-build-arguments","title":"Multiple Build Arguments","text":"<p>It is also possible to supply multiple build arguments. </p> <p>For example, if your Dockerfile has two build arguments <code>BaseImage</code> and <code>CommitId</code>:</p> <pre><code>ARG BaseImage=alpine:latest\nARG CommitId=latest\n\nFROM ${BaseImage}\n\nLABEL \"Commit-Id\"=${CommitId}\n\nCOPY servicelin /bin\nRUN [\"chmod\",  \"777\", \"./bin/servicelin\"]\nENTRYPOINT [\"/bin/servicelin\"]\n</code></pre> <p>Then, we can supply the values to these build arguments using the following command:</p> Bash Session<pre><code>k2s image build -n k2s.io/servicelin -t 1 --build-arg=\"BaseImage=debian:latest\" --build-arg=\"CommitId=a5e04dafb1d235a81d3332a6535b63e7\"\n</code></pre> <p>Here, we use the parameter <code>--build-arg</code> twice to supply the values of both the build arguments.</p> <p>For running Linux Pods in K8s please always specify the Node selector for Linux: <pre><code>      nodeSelector:\n        kubernetes.io/os: linux\n</code></pre></p>"},{"location":"user-guide/building-container-image/#k2s-build-internals","title":"<code>k2s build</code> Internals","text":"<p>Under the hood of <code>k2s build</code> is the PowerShell script Build-Image.ps1 (and its batch-wrapper, both part of the K2s setup) to automate the container build. A container image will be created in your local repository.</p> <p>In general, <code>k2s build</code> supports Linux (default) as well as Windows containers. There are also two types of a Dockerfile supported:</p> <ul> <li><code>Dockerfile</code> - The entire build chain is executed as part of the image build process resulting in a container image.</li> <li><code>Dockerfile.Precompile</code> - The content of the working directory is being build first and the container image is created afterwards (which is the default behavior if both are files are available).</li> </ul>"},{"location":"user-guide/cli-shortcuts/","title":"CLI Shortcuts","text":""},{"location":"user-guide/cli-shortcuts/#cli-shortcuts","title":"CLI Shortcuts","text":"<p>To interact with the K2s cluster, the following shortcuts can be used:</p> Shortcut Command Description <code>c</code> <code>crictl</code> Client for CRI <code>d</code> <code>docker</code> A self-sufficient runtime for containers <code>k</code> <code>kubectl</code> kubectl controls the Kubernetes cluster manager <code>ka</code> <code>kubectl apply</code> Apply something to cluster <code>kaf</code> <code>kubectl apply -f</code> Apply specified YAML manifest <code>kcp</code> <code>kubectl delete pod --field-selector=status.phase==Succeeded,Evicted -A</code> Cleanup of all succeeded Pods <code>kd</code> <code>kubectl describe</code> Describe Kubernetes resource <code>kdp</code> <code>kubectl describe pod</code> Describe Pod <code>kdpn</code> <code>kubectl describe pod -n</code> Describe all Pods inside the specified namespace <code>kg</code> <code>kubectl get</code> Get Kubernetes resource <code>kgn</code> <code>kubectl get nodes -o wide</code> Get all cluster nodes <code>kgp</code> <code>kubectl get pods -o wide -A</code> Get all Pods of all namespaces <code>kl</code> <code>kubectl logs</code> Show logs of Kubernetes resource <code>krp</code> <code>kubectl delete pod</code> Remove specified Pod <code>ks</code> <code>k2s status -o wide</code> Inspect K2s system health"},{"location":"user-guide/cluster-ip-addresses/","title":"Assignment of Cluster IP Addresses for Services","text":""},{"location":"user-guide/cluster-ip-addresses/#assignment-of-cluster-ip-addresses-for-services","title":"Assignment of Cluster IP Addresses for Services","text":""},{"location":"user-guide/cluster-ip-addresses/#linux-based-workloads","title":"Linux-based workloads","text":"<p>In case of services on Linux side please use the subnet <code>172.21.0.0/24</code> starting from <code>172.21.0.50</code> (K2s reserves addresses up to <code>172.21.0.49</code>).</p> <p>Example</p> example-service-manifest.yaml<pre><code>apiVersion: v1\nkind: Service\nmetadata:\nname: Linux-example\nspec:\nselector:\n    app: Linux-example\nports:\n    - protocol: TCP\n    port: 80\n    targetPort: 80\nclusterIP: 172.21.0.210\n</code></pre>"},{"location":"user-guide/cluster-ip-addresses/#windows-based-workloads","title":"Windows-based workloads","text":"<p>In case of services on Windows side please use the subnet <code>172.21.1.0/24</code> starting from <code>172.21.1.50</code> (K2s reserves addresses up to <code>172.21.1.49</code>).</p> <p>Example</p> example-service-manifest.yaml<pre><code>apiVersion: v1\nkind: Service\nmetadata:\nname: Windows-example\nspec:\nselector:\n    app: Windows-example\nports:\n    - protocol: TCP\n    port: 80\n    targetPort: 80\nclusterIP: 172.21.1.210\n</code></pre>"},{"location":"user-guide/hosting-variants/","title":"Hosting Variants","text":""},{"location":"user-guide/hosting-variants/#hosting-variants","title":"Hosting Variants","text":""},{"location":"user-guide/hosting-variants/#host-default","title":"Host (Default)","text":"<p>On the Windows host, a single VM is exclusively utilized as the Linux control-plane node while the Windows host itself functions as the worker node.</p> <p>This variant is also the default, offering efficient and very low memory consumption. The VM's memory usage starts at 2GB. </p>"},{"location":"user-guide/hosting-variants/#development-only","title":"Development-Only","text":"<p>In this variant, the focus is on setting up an environment solely for building and testing Windows and Linux containers without creating a K8s cluster. </p>"},{"location":"user-guide/k2s-cli/","title":"k2s CLI","text":""},{"location":"user-guide/k2s-cli/#k2s-cli","title":"k2s CLI","text":"<p>The k2s CLI is a tool shipped with K2s to completely manage a K2s cluster, providing features like:</p> <ul> <li>install/uninstall/upgrade K2s</li> <li>start/stop/check status of K2s</li> <li>manage addons</li> <li>manage container images</li> <li>maintain host system and K8s cluster</li> </ul> <p>It also provides an extensive help for all available commands and parameters/flags. Simply run: Bash Session<pre><code>&lt;repo&gt;\\k2s.exe -h\n</code></pre></p> <p>Tip</p> <p>When K2s is installed, the executables including k2s CLI have been added to <code>PATH</code>, so that the CLI can be called by using its name only: Bash Session<pre><code>k2s -h\n</code></pre></p> <p>Note</p> <p>Most of the k2s CLI commands require administrator privileges.</p>"}]}